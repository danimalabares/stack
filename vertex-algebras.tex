\input{preamble}

\begin{document}

\title{Vertex Algebras}
\maketitle

\phantomsection
\label{section-phantom}
\hfill
\href{http://github.com/danimalabares/vertex-algebras}
{github.com/danimalabares/vertex-algebras}

\tableofcontents

\section{Cartan subalgebra, Cartan matrix and Serre relations}
\label{section-Cartan-subalgebra}

Kac-Moody algebras are Lie algebras, whose definition is motivated by the
structure of finite-dimensional simple Lie algebras over $\mathbb{C}$.

Let $\mathfrak{g}$ be a finite-dimensional semisimple Lie algebra over
$\mathbb{C}$. Then $\mathfrak{g}$ has a {\it Cartan subalgebra} 
$\mathfrak{h}\subset \mathfrak{g}$ (abelian + …). 
Fixing $\mathfrak{h}\subset\mathfrak{g}$ gives a 
{\it root space decomposition}
$$
\mathfrak{g}=\mathfrak{h}\oplus \bigoplus_{\alpha \in \Delta}\mathfrak{g}_\alpha
$$
where $\Delta \subset \mathfrak{h}^*$ linear dual, and, by definition
$$
\mathfrak{g}_\alpha=\{X \in \mathfrak{g}|
[H,X]=\alpha(H)X\; \forall H \in \mathfrak{h}\}
$$
Turns out the $\mathfrak{g}_\alpha$ are all 1-dimensional, 
though this property is lost when we go to Kac-Moody algebras.
$$
[\mathfrak{g}_\alpha,\mathfrak{g}_\beta] \subset \mathfrak{g}_{\alpha+\beta}
$$
The Killing form  $\kappa:\mathfrak{g} \times \mathfrak{g} \to \mathbb{C}$,
 $\kappa(x,y)=\text{Tr}_\mathfrak{g}\text{ad}(x)\text{ad}(y)$ is nondegenerate. 
``This is kind of the definition of semisimple.'' 
(Think of $\mathfrak{h}$ as $\mathfrak{g}_0$, btw.)

$\kappa |_{\mathfrak{g}_\alpha \times \mathfrak{g}_\beta}\neq 0$ only when 
$\beta=-\alpha$. $\kappa |_{\mathfrak{h}\times \mathfrak{h}}$ is non-degenerate. 
 This gives a linear isomorphism 
$\mathfrak{h} \xrightarrow{\nu} \mathfrak{h}$ via 
$\nu(H)(H') = \kappa(H,H')$.

\medskip\noindent
So, $\mathfrak{h}^*$ comes with a non-degenerate bilinear form.

The {\it reflection} $r_\alpha:\mathfrak{h}\to \mathfrak{h}^*$ in 
$\alpha \in \mathfrak{h}^*$ (usually a root) is 
$r_\alpha(\lambda)=\lambda- 2\frac{(\lambda,\alpha)}{(\alpha,\alpha)}
\cdot \alpha.$

``Classify root systems […] classify semisimple Lie algebras'' 
It is a fact that $r_\alpha (\Delta)=\Delta$ for all $\alpha \in \Delta$, 
which motivates the definition of {\it root system} 
and permits classification.

\begin{example}
\label{example-root-system-sl2}
$\mathfrak{g}=\mathfrak{sl}_2$, $\mathfrak{h}=$ diagonal matrices
$$
\begin{pmatrix}
1&&\\ 
&-1&\\
& & 0
\end{pmatrix}
\qquad 
\begin{pmatrix}
0&&\\ 
&1&\\
& & -1
\end{pmatrix}
$$
is a basis of $\mathfrak{h}$. There are 6 roots vectors
$$
E_{12}=
\begin{pmatrix}
0 & 1 & 0\\
0 & 0 & 0\\
0 & 0 & 0
\end{pmatrix}
$$
$E_{23},E_{13}$, etc.
\end{example}

\begin{exercise}
\label{exercise-basis-of-h}
$[H_1,E_{12}]=2E_{12}$, $[H_2,E_{12}]=-E_{12}$, $\alpha_{12}=(2,-1)$.
\end{exercise}

[Drawing of roots]

Notions of {\it positive roots} and {\it simple roots} 
(set of $\text{rank}\mathfrak{g}$ simple roots has $\ell$ elements,
 where $\ell=\dim(\mathfrak{h}^*)$.  
This will also fail for Kac-Moody algebras more generally). 
Next write the {\it Cartan matrix}
$$
A=(a_{ij}),\qquad  a_{ij}=2\frac{(\alpha_i,\alpha_j)}{(\alpha_i,\alpha_i)}
$$
for $1\leq i,j \leq \ell$.

\begin{example}
\label{example-Cartan-matrix-sl3}
$\mathfrak{sl}_3$. [Picture, hexagonal pattern]. 
$(\alpha_1,\alpha_1)=(\alpha_2,\alpha_2)=2,(\alpha_1,\alpha_2)=-1$, so
$$
A=\begin{pmatrix}
2&-1\\ 
-1&2
\end{pmatrix}
$$
\end{example}

\begin{example}
\label{example-Cartan-matrix-sl5}
$\mathfrak{sl}_5$. [Picture, square pattern]. $|\alpha_2|=1$, $|\alpha_1|=2$,
$(\alpha_1,\alpha_2)=-2$, so
$$
A=\begin{pmatrix}
2&-1\\ 
-2&2
\end{pmatrix}
$$
\end{example}

\begin{remark}
\label{remark-}
Since $\mathfrak{g}_\alpha$ is 1-dimensional, set
$\mathfrak{g}_\alpha=\mathbb{C}E_\alpha$ and 
$E_i=E_{\alpha_i}$, $i=1,2,\ldots,\ell$ (simple root vectors). 
It turns out that 
$$
\text{ad}(E_i)^{1-a_{ij}}E_j=0.
$$
This is called a {\it Serre relation}.
\end{remark}

\section{Some infinite dimensional Lie algebras}
\label{section-some-infinite-dimensional-Lie-algebras}
Let $\mathfrak{g}$ be a finite-dimensional semisimple Lie algebra, and define
the {\it loop algebra} 
\begin{align*}
L\mathfrak{g}&=\mathfrak{g}[t,t^{-1}],\text{ (with basis 
$at^m|\substack{\text{$a \in $ a basis of $\mathfrak{g}$} \\ m \in \mathbb{Z}}$
)}\\
&=\mathfrak{g} \otimes _{\mathbb{C}}\mathbb{C}[t,t^{-1}]
\end{align*}
with the Lie bracket
$$
[at^m,bt^n]=[a,b]t^{m+n}.
$$
``This construction is absurdely general --- we don't need $\mathfrak{g}$ to be
semisimple […]''

\medskip\noindent
Take $\mathfrak{g}=\mathfrak{sl}_2$. Recall that
$$
E=\begin{pmatrix}
0&1\\ 
0&0
\end{pmatrix},\quad 
H=\begin{pmatrix}
1&0\\ 
0&-1
\end{pmatrix},\quad 
F=\begin{pmatrix}
0&0\\ 
1&0
\end{pmatrix}
$$
[Picture with $F,H,E,Ft,Ht,Et,Et^2$…]
$E$ was a root vector, corresponding to the unique root in $\mathfrak{sl}_2$,
call it $\alpha_1$. We seem to have a second simple root $\alpha_0$,
 corresponding to $Ft$.

This looks like it wants to have a Cartan matrix
 $$
A=\begin{pmatrix}
2&-2\\ 
-2&2
\end{pmatrix}
$$
We will indeed recover (a variant of) $L\mathfrak{g}$ as a Lie algebra 
``built from'' $A=\begin{pmatrix}
2&-2\\ 
-2&2
\end{pmatrix}$,
 a Kac-Moody algebra. 
But note first, $\mathfrak{h}=\mathbb{C}H$ is too small.
``Problem with $\alpha_0$ and $\alpha_1$ being linearly independent  …''

\begin{exercise}
\label{exercise-Lie-algebra-d}
Consider $L\mathfrak{g}\oplus\mathbb{C}d$, and set 
$[d,at^m]=mat^m$, $[d,d]=0$. Check this defines a Lie algebra.
\end{exercise}

\begin{proof}
Skew-commutativity, i.e. for all $x \in L\mathfrak{g}\oplus\mathbb{C}d$,
\begin{equation}
\label{equation-skew-commutativity}
[x,x]=0,
\end{equation}
is immediate from 
skew commutativity in $L\mathfrak{g}$ and 
the hypothesis that $[d,d]=0$.

To confirm Jacobi identity, i.e. that for all 
$x,y,z \in L\mathfrak{g}\oplus\mathbb{C}d$
\begin{equation}
\label{equation-Jacobi-algebra-d-identity}
[x,[y,z]]+[y,[z,x]]+[z,[x,y]]=0,
\end{equation}
notice that since this is a cyclic sum on $x,y,z$ 
we only need to consider three elements in
$L\mathfrak{g} \oplus \mathbb{C}d$ up to cyclic permutation.
The cases in which the three elements are either in $L\mathfrak{g}$ or in
$\mathbb{C}d$ are obvious, so that there
are only two interesting possibilities:
\begin{align}
x=d,\qquad y&=at^m,\qquad z=bt^n
\label{equation-Jacobi-algebra-d-case-1}\\
x=d,\qquad y&=d,\qquad z=at^n
\label{equation-Jacobi-algebra-d-case-2}
\end{align}
Case \ref{equation-Jacobi-algebra-d-case-1} gives
\begin{align*}
& [d,[at^m,bt^n]]+[at^m,[bt^n,d]]+[bt^n,[d,at^m]]\\
&=[d,[a,b]t^{m+n}]+[at^m,-nbt^n]+[bt^n,mat^m]\\
&=(m+n)[a,b]t^{m+n}-n[a,b]t^{m+n}+m[b,a]t^{m+n}\\
&=(m+n)[a,b]t^{m+n}-n[a,b]t^{m+n}-m[a,b]t^{m+n}\\
&=(m+n)[a,b]t^{m+n}-(m+n)[a,b]t^{m+n}=0.
\end{align*}
Case \ref{equation-Jacobi-algebra-d-case-2} gives
\begin{align*}
&[d,[d,at^m]]+[d,[at^m,d]]+[at^m,[d,d]]\\
&=[d,mat^m]+[d,-mat^m]=0.
\end{align*}

\end{proof}

The Kac-Moody algebra turns out to be, not quite this, but slightly larger
still.

Recall that an {\it invariant bilinear form} $(\cdot,\cdot)$ on a Lie algebra
$\mathfrak{g}$ is a bilinear form such that
\begin{equation}
\label{equation-invariant-bilinear-form}
([a,b],c)=(a,[b,c])\qquad \forall a,b,c \in \mathfrak{g}.
\end{equation}

\begin{exercise}
\label{exercise-invariant-bilinear-form-on-simple-Lie-algebra-is-symmetric}
Prove that an invariant bilinear form on a simple Lie algebra must in fact be
symmetric.
\end{exercise}

\begin{proof}
It's enough to show that $\mathfrak{g}$ is
{\it perfect}, i.e. that $[\mathfrak{g},\mathfrak{g}]=\mathfrak{g}$. In this
case, let $a,b \in \mathfrak{g}$ and suppose that $b=[x,y]$. Then
\begin{align*}
(a,b)&=(a,[x,y])=(a,-[y,x])=(-[a,y],x)=([y,a],x)\\
&=(y,[a,x])=(y,-[x,a])=(-[y,x],a)=([x,y],a)=(b,a)
\end{align*}
To confirm that $\mathfrak{g}$ is perfect just observe that
$[\mathfrak{g},\mathfrak{g}]$ is a nontrivial ideal of $\mathfrak{g}$.
\end{proof}

\begin{definition}
\label{definition-affine-Lie-algebra}
Given $\mathfrak{g}$ simple, with 
$(\cdot,\cdot):\mathfrak{g} \times \mathfrak{g} \to \mathbb{C}$ 
invariant bilinear form, the {\it affine Lie algebra} is 
$$
\hat{\mathfrak{g}}=L\mathfrak{g} \oplus \mathbb{C}K,
$$
with $[K,\hat{\mathfrak{g}}]=0$, and 
$[at^m,bt^n]=[a,b]t^{m+n}+m(a,b)\delta_{m,-n}K$.
\end{definition}

``For the construction to work it doesn't actually have to be nondegenerate.''

\begin{exercise}
\label{exercise-affine-Lie-algebra-is-Lie-algebra}
Check that the affine Lie algebra $\hat{\mathfrak{g}}$ is a Lie algebra.
\end{exercise}

\begin{proof}
(Skew-commutativity.) 
Since $[K,\hat{\mathfrak{g}}]=0$ and $K \in \hat{\mathfrak{g}}$, 
it is immediate that $[K,K]=0$. 
For the case of an element in $L\mathfrak{g}$, we see that
$[at^m,at^m]=0$ by skew-commutativity of the bracket in $\mathfrak{g}$ 
and the Kronecker delta.
 
(Jacobi identity.) As in Exercise \ref{exercise-Lie-algebra-d}, 
any choice of $x,y,z$ involving $K$ is immediate by $[K,\hat{\mathfrak{g}}]=0$.
Thus the only interesting case is
for Jacobi identity consider the cases
\begin{align*}
& [at^m,[bt^n,ct^\ell]]+[bt^n,[ct^\ell,at^m]]+[ct^\ell,[at^m,bt^n]]\\
&=[at^m,[b,c]t^{n+\ell}+n(b,c)\delta_{n,-\ell}K]\\
&+[bt^n,[c,a]t^{\ell+m}+\ell(c,a)\delta_{\ell,-m}K]\\
&+[ct^\ell,[a,b]t^{m+n}+m(a,b)\delta_{m,-n}K]\\
&=[at^m,[b,c]t^{n+\ell}]+[at^m,n(b,c)\delta_{n,-\ell}K]\\
&+[bt^n,[c,a]t^{\ell+m}]+[bt^n,\ell(c,a)\delta_{\ell,-m}K]\\
&+[ct^\ell,[a,b]t^{m+n}]+[ct^\ell,m(a,b)\delta_{m,-n}K]\\
&=[a,[b,c]]t^{m+(n+\ell)}+m(a,[b,c])\delta_{m,-(n+\ell)}K\\
&+[b,[c,a]]t^{n+(\ell+m)}+n(b,[c,a])\delta_{n,-(\ell+m)}K\\
&+[c,[a,b]]t^{\ell+(m+n)}+\ell(c,[a,b])\delta_{\ell,-(m+n)}K=0
\end{align*}
It is clear that we obtain a Jacobi equation on $\mathfrak{g}$. To see that the
remaining terms vanish, notice that the condition on
the Kronecker delta in its three appearances is the same,
namely, $m+n+\ell=0$. In this case, we only need to check
that $(a,[b,c])=(b,[c,a])=(c,[a,b])$ to conclude.
This follows from the invariance of $(\cdot,\cdot)$
and the fact that $\mathfrak{g}$ simple using Exercise 
\ref{exercise-invariant-bilinear-form-on-simple-Lie-algebra-is-symmetric}.
\end{proof}

We also have
\begin{definition}
\label{definition-extended-affine-Lie-algebra}
The {\it extended affine Lie algebra} is 
$$
\tilde{\mathfrak{g}}=L\mathfrak{g} \oplus \mathbb{C}K \oplus \mathbb{C}d,
$$ 
with $[d,at^m]=m a t^m$ as before, and 
$[K,d]=0$.
\end{definition}

The extended affine Lie algebra is an example of a Kac-Moody algebra.

\begin{exercise}[For those who like geometry]
\label{exercise-for-those-who-like-geometry}
Let $R=\mathbb{C}[t,t^{-1}]$. 
If $D \in \text{Der}(R)$, then
$L\mathfrak{g} \oplus \mathbb{C}d$ is a Lie algebra with 
$[d,a \otimes r]=a\otimes D(r)$. 
Is $(\mathfrak{g}\otimes R)\oplus \text{Der}(R)$ a Lie algebra? (The Lie alegra
$L\mathfrak{g} \oplus \mathbb{C}d$ from Exercise \ref{exercise-Lie-algebra-d} is
a particular case, for $D=t\frac{d}{dt}$.)
\end{exercise}

\begin{proof}
Checking that $L\mathfrak{g} \oplus \mathbb{C}d$ is a Lie algebra with 
$[d,a\otimes r]=a \otimes D(r)$ is similar to Exercise
\ref{exercise-Lie-algebra-d}: skew-commutativity is immediate from
skew-commutativity in each of the components, while 
Jacobi identity is verified in two cases. For $x=y=d$ and $z=a \otimes r$ 
we quickly obtain
\begin{align*}
&[x,[y,z]]+[y,[z,x]]+[z,[x,y]]\\
&=[d,[d,a \otimes r]]+[d,[a \otimes r,d]]+[a \otimes r,[d,d]]\\
&=[d,a \otimes D(r)]+[d,-a \otimes D(r)]=0.
\end{align*}

And for $x=d$, $y=a \otimes r$ and $z=b \otimes s$, we get
\begin{equation}
\label{equation-Jacobi-derivation}
\begin{aligned}
&[x,[y,z]]+[y,[z,x]]+[z,[x,y]]\\
&=[d,[a\otimes r,b \otimes s]]+[a\otimes r,[b \otimes s,d]]
+[b \otimes s,[d,a\otimes r]]\\
&=[d,[a,b]\otimes rs]+[a\otimes r,-b\otimes D(s)]
+[b\otimes s,a\otimes D(r)]\\
&=[a,b]\otimes D(rs)-[a,b]\otimes rD(s)+[b,a]\otimes sD(r)=0.
\end{aligned}
\end{equation}

\medskip\noindent
To check whether $(\mathfrak{g}\otimes R)\oplus\text{Der}(R)$ is a Lie algebra 
first put the Lie bracket on $\text{Der}(R)$ as
$[D,D_1]=DD_1-D_1D$. It is clear that this bracket is skew-commutative. 
Jacobi identity reads
\begin{align*}
&[D,[D_1,D_2]]+[D_1,[D_2,D]]+[D_2,[D,D_1]]\\
&=[D,D_1D_2-D_2D_1]+[D_1,D_2D-DD_2]+[D_2,DD_1-D_1D]\\
&=D(D_1D_2-D_2D_1)-(D_1D_2-D_2D_1)D+D_1(D_2D-DD_2)\\
&-(D_2D-DD_2)D_1+D_2(DD_1-D_1D)-(DD_1-D_1D)D_2\\
&=DD_1D_2-DD_2D_1-D_1D_2D+D_2D_1D+D_1D_2D-D_1DD_2\\
&-D_2DD_1+DD_2D_1+D_2DD_1-D_2D_1D-DD_1D_2+D_1DD_2=0.
\end{align*}
Now put the bracket on $(\mathfrak{g} \otimes  R)\oplus\text{Der}(R)$ as
$[D,a \otimes  r]=a \otimes D(r)$. Skew-commutativity is immediate. 
Jacobi identity for $x=D,y=a\otimes r$ and $z=b\otimes s$ is identical to the
computation \ref{equation-Jacobi-derivation}. In the case
$x=D$, $y=D_1$ and $z=a\otimes r$, we get
\begin{align*}
&[D,[D_1,a\otimes r]]+[D_1,[a\otimes r,D]]+[a\otimes r,[D,D_1]]\\
&=[D,a\otimes D_1(r)]+[D_1,-a\otimes D(r)]+[a\otimes r,[D,D_1]]\\
&=a\otimes DD_1(r)-a\otimes D_1D(r)-a\otimes [D,D_1](r)=0
\end{align*}
\end{proof}

\section{Kac-Moody algebras}
\label{section-Kac-Moody-algebras}

Recall the notion of the free Lie algebra on a 
vector space $V$ of generators 
(or a set $X$, think of $V$ as a vector space with basis $X$):

\begin{definition}
\label{definition-free-Lie-algebra}
The {\it free Lie algebra} on $V$ is characterized by the universal property
$$
\xymatrix{
V\ar[rr]^f\ar[dr]_i&&\mathfrak{g}\\
& F(V)\ar[ur]_{\exists !\tilde{f}}
}
$$
That is, for any linear map $f:V \to \mathfrak{g}$ with $\mathfrak{g}$ Lie
algebra, there exists a unique $\tilde{f}$ homomorphism of Lie algebras 
$F(V)\to \mathfrak{g}$ such that $\tilde{f} \circ i=f$.
$$
\Hom_{\text{Lie}}(F(V),\mathfrak{g})=\Hom_{\text{Vec}}(V,\mathfrak{g})
$$
naturally.
\end{definition}

That is, $F$ and the 
forgetful functor $G:\underline{\text{Lie}}\to \underline{\text{Vec}}$
are adjoint:
$$
\Hom_{\underline{\text{Lie}}}(F(V),\mathfrak{g})
\xrightarrow{\simeq }
\Hom_{\underline{\text{Vec}}}(V,G(\mathfrak{g}))
$$

\medskip\noindent
{\bf A realisation of $F(V)$.} Let 
$$
T(V)=\mathbb{C} \oplus V \oplus V^{\otimes 2}\oplus V^{\otimes 3}\oplus\ldots
$$
be the tensor algebra of $V$. 

Then inside $T(V)$ consider $F(V)$ the span of iterated commutators of elements
of  $V$.

\begin{proposition}
\label{proposition-this-realises-the-free-Lie-algebra}
This realises the free Lie algebra.
\end{proposition}

\begin{proof}
In online notes.
\end{proof}

\medskip\noindent
In the finite dimensional simple case, we had
$$
a_{ij}=\frac{2(\alpha_i,\alpha_j)}{(\alpha_i,\alpha_i)},
$$
which we think also as $\alpha_i,\alpha_j \in \mathfrak{h}^*$, 
and $\alpha_i^\vee=\frac{2}{(\alpha_i,\alpha_i)}\nu^{-1}(\alpha_i) 
\in \mathfrak{h}.$

Clearly, $\alpha_{ii}=2$ for all $i$. 
$a_{ij}$ might not equal $a_{ji}$, but certainly $a_{ij}=0 \iff a_{ji}=0$. 
And $\forall  i \neq j$, $a_{ij} \leq 0$.

\medskip\noindent
{\bf One further property.} Set
$$
\varepsilon_i=\frac{2}{(\alpha_i,\alpha_i)},\quad \text{and}\quad 
D=\substack{\text{diagonal matrix} \\ \text{with entries }\varepsilon_i}
$$
Then $A=DB$, where $B=((\alpha_i,\alpha_j))$ is symmetric. 
If a matrix $A$ is equal to $(\text{diag})(\text{symm})$, we call it
 {\it symmetrizable}.

\begin{definition}
\label{definition-generalized-Cartan-matrix}
A {\it generalized Cartan matrix} is an integer matrix $A=(a_{ij})$ 
which is
\begin{itemize}
\item symmetrizable,
\item $a_{ii}=2$ for all $i$,
\item $a_{ij}=0 \iff a_{ji}=0$,
\item $a_{ij}\leq 0$ for $i \neq j$.
\end{itemize}
\end{definition}

\begin{definition}
\label{definition-realisation}
A {\it realisation} of a generalized Cartan matrix is a complex vector space
 $\mathfrak{h}$, and two sets
\begin{align*}
\Pi^\vee&=\{\alpha_1^\vee, \alpha_2^\vee,\ldots,\alpha_n^\vee\},\quad
\text{and},\\
\Pi&=\{\alpha_1,\alpha_2,\ldots,\alpha_n\}
\end{align*}
such that $\left<\alpha_i^\vee,\alpha_j\right>=a_{ij}$, $1\leq i,j\leq n$.
\end{definition}

\begin{exercise}
\label{exercise-realisation}
$\dim(\mathfrak{h})\geq 2n-\text{rank}(A)$.
\end{exercise}

\begin{proof}
For $A=\begin{pmatrix}
2&-2\\ 
-2&2
\end{pmatrix}$, a realisation is given by
$$
\Pi^\vee=\{H_1,H_0\},\qquad \Pi=\{\alpha_0,\alpha_1\}
$$
\begin{align*}
\mathfrak{h}&=\mathbb{C}H\oplus\mathbb{C}d\oplus\mathbb{C}K,\\
\mathfrak{h}^*&=\mathbb{C}\alpha_1\oplus\mathbb{C}\delta
\oplus\mathbb{C}\Lambda_0
\end{align*}
(Canonical dual, $\left<\alpha_1,H\right>=2$, 
$\left<\delta,d\right>=1=\left<\Lambda_0,K\right>$, every other pairing $0$.)

Then
$$
\begin{cases}
\alpha_1=\alpha_1\\
\alpha_0=\delta-\alpha_1
\end{cases}\qquad 
\begin{cases}
\alpha_1^\vee=H \\
\alpha_0^\vee = K-H
\end{cases}
$$
So we obtain
\begin{align*}
\left<\alpha_0^\vee,\alpha_1\right>&=\left<K-H,\alpha_1\right>=2\\
\left<\alpha_1^\vee,\alpha_0\right>&=\left<H,\delta-\alpha_1\right>=-2\\
\left<\alpha_0^\vee,\alpha_0\right>&=\left<K-H,\delta-\alpha_1\right>=+2
\end{align*}

\end{proof}

\medskip\noindent
Finally let's define Kac-Moody algebras.

Let $A$ be a generalized Cartan matrix. Let 
$$
\tilde{\mathfrak{n}}_+=F(e_1,\ldots,e_n),
$$ 
the free Lie algebra on $n$ generators, and similarly
$$
\tilde{\mathfrak{n}}_-=F(f_1,\ldots,f_n).
$$
Let $\mathfrak{h}$ be a realisation of $A$. 
Set $\tilde{\mathfrak{g}}(A)
=\tilde{\mathfrak{n}}_- \oplus \mathfrak{h} \oplus \tilde{\mathfrak{n}}_+$.

Make $\tilde{\mathfrak{g}}(A)$ a Lie algebra by defining
\begin{itemize}
\item $[\mathfrak{h},\mathfrak{h}]=0$,
\item $\forall  H \in \mathfrak{h}$, $[H,e_i]=\left<\alpha_i,H\right>e_i
=\alpha_i(H)e_i$. And similarly, $[H,f_i]=-\alpha_i(H)f_i$.
\item $[e_i,f_j]=\delta_{ij}\alpha_i^\vee$.
\end{itemize}
Then $\tilde{\mathfrak{g}}(A)$ is a Lie algebra (though not yet the Kac-Moody
algebra). See Kac, \cite[Thorem 1.2]{IDLA}.

\begin{remark}
\label{remark-lattice}
In $\mathfrak{h}$ we have a lattice
\begin{align*}
Q^\vee&=\mathbb{Z}\alpha_1^\vee+\ldots+\mathbb{Z}\alpha_n^\vee,\quad
\text{and}\\
Q&=\mathbb{Z}\alpha_1+\ldots+\mathbb{Z}\alpha_n\text{ in }\mathfrak{h}^*
\end{align*}
(root and coroot lattices). $\tilde{\mathfrak{g}}(A)$ is naturally $Q$-graded,
with 
$$
\tilde{\mathfrak{g}}(A)_\beta=\text{span}\{
\text{commutators of $e_i$ with $\sum \alpha_i=\beta$}\}.
$$
$\tilde{g}(A)=\mathfrak{h}$.

\begin{theorem}[Gabber-Kac]
\label{theorem-Gabber-Kac}
Denote by $I \subset \tilde{\mathfrak{g}}(A)$ the maximal $Q$-graded ideal, such
that $I \cap\mathfrak{h}=\{0\}$. 
Then $I$ is generated by the Serre relations 
$$
\text{ad}(e_i)^{1-a_{ij}}e_j\qquad \text{and}\qquad 
\text{ad}(f_i)^{1-a_{ij}}f_j,\; i\neq j.
$$
\end{theorem}

\begin{proof}
\cite[Theorem 9.11]{IDLA}.
\end{proof}

(The existence of the ideal $I$ does not need the theorem; 
the importance of the theorem is providing an
expression for the generators.)

\begin{definition}
\label{definition-Kac-Moody-algebra}
The {\it Kac-Moody algebra} $\mathfrak{g}(A)$ is $\tilde{\mathfrak{g}}(A)/I$.
\end{definition}

\end{remark}

\section{Affine Kac-Moody algebras}
\label{section-affine-Kac-Moody-algebras}

Let $\mathfrak{g}$ be a finite-dimensional simple Lie algebra, 
with $(\cdot,\cdot):\mathfrak{g} \times \mathfrak{g} \to \mathbb{C}$ 
invariant bilinear form,
$$
([x,y],z)=(z,[y,z])\qquad \forall x,y,z \in \mathfrak{g}
$$
(Eg. the Killing form  
$\kappa(x,y)=\text{Tr}_\mathfrak{g}\text{ad}(x)\text{ad}(y)$ is invariant.)

Typically we normalise $(\cdot,\cdot)$ so that $(\alpha,\alpha)=2$ for the long
roots of $\mathfrak{g}$.

Then $\hat{\mathfrak{g}}=\mathfrak{g}[t,t^{-1}]\oplus\mathbb{C}K$ 
(affine Lie algebra),
$$
[at^m,bt^n]=[a,b]t^{m+n}+m\delta_{m,-n}(a,b)K,\qquad [K,\hat{\mathfrak{g}}]=0
$$
and $\tilde{\mathfrak{g}}=\hat{\mathfrak{g}}\oplus\mathbb{C}d$, 
$[d,K]=0$,  $[d,at^m]=mat^m$, 
(affine Kac-Moody algebra or ``extended affine Lie algebra'')

\begin{theorem}
\label{theorem-gtilde-is-a-Kac-Moody-algebra}
$\tilde{\mathfrak{g}}$ is a Kac-Moody algebra.
\end{theorem}

Let $\mathfrak{g}=\mathfrak{h}\oplus \bigoplus_{\alpha \in
\Delta}\mathfrak{g}_\alpha$, ($\mathfrak{g}_\alpha=\mathbb{C}E_\alpha$.)

{\bf The simple roots and coroots.}
$\tilde{\mathfrak{h}}=\mathfrak{h}\oplus\mathbb{C}K\oplus\mathbb{C}d$. 
We identify $\tilde{\mathfrak{h}}^*$ with 
 $\mathfrak{h}^*\oplus\mathbb{C}\Lambda_0\oplus\mathbb{C}\delta$ where
\begin{align*}
\Lambda_0(\mathfrak{h})&=\delta(\mathfrak{h})=0\\
\Lambda_0(d)&=\delta(K)=0\\
\Lambda_0(K)&=\delta(d)=1
\end{align*}
The {\it real coroots} are
$$
\hat{\Delta}^{V,re}=\{E_\alpha t^m|\alpha \in \Delta, m \in \mathbb{Z}\}
$$
and there are also imaginary roots and coroots
$$
\hat{\Delta}^{V,im}=\{Ht^m|H \in \mathfrak{h}, m \in \mathbb{Z}\setminus\{0\}\}
$$
Roots:
\begin{align*}
\hat{\Delta}^{re}&=\{\alpha+m\delta|\alpha \in \Delta, m \in \mathbb{Z}\}\\
\hat{\Delta}^{im}&=\{m\delta|m \neq 0\}
\end{align*}
$Xt^m$:
\begin{align*}
[H,Xt^m]&=[H,x]t^m,\qquad H \in \mathfrak{h}\\
[K,xt^m]&=0\\
[d,xt^m]&=m x t^m
\end{align*}
so it $x \in \mathfrak{g}_\alpha$, $x t^m \in 
\tilde{\mathfrak{g}}_{\alpha+m\delta}$.

\medskip\noindent
The invariant bilinear form $(\cdot,\cdot)$ from $\mathfrak{g} \times
\mathfrak{g}$ extends uniquely to
$(\cdot,\cdot):\tilde{\mathfrak{g}}\times\tilde{\mathfrak{g}}\to \mathbb{C}$.

$(d,d)=(K,K)=0$, $(d,K)=1$ and $(d,\mathfrak{h})=(K,\mathfrak{h})=0$.

\medskip\noindent
So, in $\tilde{\mathfrak{h}}^*$:
\begin{align*}
(\Lambda_0,\Lambda_0)&=(\delta,\delta)=0\\
(\Lambda_0,\mathfrak{h}^*)&=(\delta,\mathfrak{h}^*)=0\\
(\Lambda_0,\delta)&=1.
\end{align*}
Hence, $|\alpha+m \delta|^2=|\alpha|^2$, $|m \delta|^2=0$.

\begin{example}
\label{example-sl2hat}
$\widetilde{\mathfrak{sl}_2}, \tilde{\mathfrak{h}}^*
=\text{span}\{\alpha,\Lambda_0,\delta\}$ with Gram matrix …
\end{example}

We can make a choice of positive roots,
$$
\hat{\Delta}_+=\{\alpha+m \delta |\alpha \in \Delta, m>0\}
\cup \{m \delta|m>0\} \cup \Delta_+
$$
Obviously, if $\alpha \in \Delta_+$ is simple, 
$\alpha \in \hat{\Delta}_+$ is simple.

\medskip\noindent
{\bf Notation.} Let $\theta \in \Delta_+$ be a the highest root. ($\not \exists
\alpha \in \Delta_+$ such that $\alpha-\theta \in \mathbb{Z}_+ \Delta_+$.) and
 $\alpha=\delta-\theta$.

Then $\alpha_0 \in \hat{\Delta}_+$ is simple and the set of simple roots is
$\hat{\Pi}=\{\alpha_0,\underbrace{\alpha_1,\ldots,\alpha_\ell}
_{\substack{\text{the finite} \\ \text{simple roots}}} \}.$
where $\ell=\text{rank}(\mathfrak{g})$.

The coroot corresponding to $\alpha_0$ is 
$$
\alpha^\vee_0=K-\theta^\vee, \qquad
\theta^\vee=\frac{2}{(\theta,\theta)}\nu^{-1}(\theta) \in \mathfrak{h} 
$$
$$
\text{ and }\qquad E_{\alpha_0}=E_{-\theta}t.
$$

\section{Weyl group}
\label{section-Weyl-group}

\medskip\noindent
{\bf Upshot.} The Weyl group is a semidirect product of 
pseudoreflections and translations.

\medskip\noindent
In any Kac-Moody algebra, we have
\begin{align*}
\text{roots }\qquad \Pi&=\{\alpha_1,\ldots,\alpha_\ell\}\subset\mathfrak{h}^* \\
\text{coroots}\qquad  \Pi^\vee&=\{\alpha_1^\vee,\ldots,\alpha_\ell^\vee\}\subset
\mathfrak{h},
\end{align*}
and {\it reflections} $r_i \in \text{GL}(\mathfrak{h}^*)$,
defined by 
$$
r_i(\lambda)=\lambda-\left<\lambda,\alpha_i^\vee\right>\alpha_i.
$$

One can check that
$$
(r_i\lambda,r_i\mu)=(\lambda,\mu)\qquad \forall \lambda,\mu \in \mathfrak{h}^*
$$
The {\it Weyl group} $W$ is $\left<r_i|i=1,\ldots,\ell\right>\subset 
\text{GL}(\mathfrak{h}^*)$.

\begin{example}
\label{example-Weyl-group-sl2tilde}
For $\widetilde{\mathfrak{sl}_2}$, $r_1$ is easy,
\begin{align*}
r_1(\alpha)&=-\alpha \qquad \text{(as in $\mathfrak{sl}_2$)}\\
r_1(\delta)&=\delta,\qquad r_1(\Lambda_0)=\Lambda_0.
\end{align*}
To compute $r_0$ take an arbitrary element $m \alpha_1+k\Lambda_0+f\delta$ and
do:
\begin{align*}
r_0(m \alpha_1+k\Lambda_0+f\delta)&=m\alpha_1+k\Lambda_0+f\delta
-\left<\alpha_0^\vee,m\alpha_1+k\Lambda_0+f\delta\right>\alpha_0\\
\alpha_0=\delta-\alpha_1,\qquad & \alpha_0^\vee=K-\alpha^\vee
\end{align*}
so we obtain
$$
=m\alpha_1+k\Lambda_0+f\delta-(k-2m)(\delta-\alpha_1)
$$
$$
(k-m)\alpha_1+k\Lambda_0+(f-k+2m)\delta.
$$
Relative to basis $\{\alpha_1,\Lambda_0,\delta\}$.
$$
r_1=\begin{pmatrix}
-1&0&0\\
0&1&0\\
0&0&1
\end{pmatrix},
r_0=\begin{pmatrix}
-1&1&0\\
0&1&0\\
2&-1&1
\end{pmatrix}
\begin{pmatrix}
m\\
k\\
f
\end{pmatrix}
$$
$$
t=r_1r_0=\begin{pmatrix}
1&-1&0\\
0&1&0\\
2&-1&1
\end{pmatrix}
$$
Notice that $\delta$ is fixed by all $r_i$. Also 
$m \alpha+k \Lambda_0 +f\delta$, the {\it coefficient} of $\Lambda_0$ is fixed
by all $r_i$.

Then
\begin{align*}
t(m\alpha_1+&k\Lambda_0+f\delta)=(m-k)\alpha_1+k\Lambda_0+(f-k+2m)\delta.
\end{align*}
Think of $t$ as a translation.

The number $k$ in 
 $$
\mathfrak{h}^* \ni \hat{\lambda}=\lambda+k\Lambda_0+f\delta
$$
is called the {\it level} of $\hat{\lambda}$.

$\hat{\mathfrak{h}}=$ union of (hyper)planes of constant level which are stable
under $W$. The roots $\alpha$ are all of level $0$.

[Picture] 
``$r_1$ changes the sign of the finite path''. And $t=r_1r_0$ is a sort of
translation. Indeed, in general we can consider 
$t_{\alpha_i}=r_{\alpha_i}\circ r_0 \in W$,

$$
t_\alpha(\beta+m\delta)=\beta+(m+(\beta,\alpha_i))\delta
$$
\end{example}
One can describe the action of $t_\alpha$ on $\hat{\lambda}$ in general 
(e.g. see \cite[Chapter 6]{IDLA})

\begin{proposition}
\label{proposition-Weyl-group-of-affine-Kac-Moody-algebra}
For the affine Kac-Moody algebra $\hat{\mathfrak{g}}$
 with $\hat{W}=\left<r_0,r_1,\ldots,r_\ell\right>$ its Weyl group 
(and $W=\left<r_1,\ldots,r_\ell\right>\subset \hat{W}$ the Weyl group of
$\mathfrak{g}$), then $\hat{W} \simeq W\times t_{Q^\vee}$ (where it should be
semidirect product instead of $\times$…) where $Q^\vee$ is the
coroot lattice of $\mathfrak{g}$.
\end{proposition}

\begin{remark}
\label{remark-Weyl-groups-are-large-for-other-Kac-Moody-algebras}
For general Kac-Moody algebras, the Weyl groups are much larger, hyperbolic
reflection groups.
\end{remark}

In the affine case, $\hat{W}$ fixes level $k$, and $|\hat{\lambda}|$. One gets,
in the intersection, paraboloids [Picture of section of hyperboloid that is a
parabola].

\section{Weyl character formula}
\label{section-Weyl-character-formula}
Highest weight representations of Kac-Moody algebras. 
Let $\lambda \in \mathfrak{h}^*$, where
$\mathfrak{g}(A)=\mathfrak{n}_-\oplus\mathfrak{h}\oplus \mathfrak{n}_+$ 
is a Kac-Moody algebra. We define a {\it Verma module} 
$$
M(\Lambda)
=U(\mathfrak{g}) \otimes_{U(\mathfrak{h}+\mathfrak{n}_+)}\mathbb{C}v_\Lambda
$$
where $\mathfrak{h}+\mathfrak{n}_+$ acts on $V_\Lambda$ by:
\begin{align*}
\begin{aligned}
Xv_\Lambda&=0,\qquad &\forall x &\in \mathfrak{n}_+,\\
Hv_\Lambda&=\Lambda(H)v_\Lambda,\qquad &\forall H &\in \mathfrak{h}
\end{aligned}
\end{align*}
So $\mathbb{C} v_\Lambda$ is a $U(\mathfrak{h}+\mathfrak{n}_+)$-module,
$$
\xymatrix{
U(\mathfrak{h}+\mathfrak{n}_+)\ar[d]\\
U(\mathfrak{g})
}
$$
By the PBW theorem, $M(\Lambda)$ has a linear $\mathbb{C}$-basis.

Let $\{F_{\alpha,i}:i = 1,\ldots, \dim \mathfrak{g}_\alpha\}$ be a basis of
$\mathfrak{g}_{-\alpha}$, $\forall \alpha \in \Delta_+$. 
Also choose a total order on $\Delta_+$. (Some sort of lexicographical order
that takes longer to write than to say.)
$$
F_{\alpha_1,i_1},F_{\alpha_2,i_2},\ldots,F_{\alpha_s,i_s},v_\Lambda
$$
$$
\alpha_1\leq \alpha_2\leq \ldots \leq \alpha_2\text{ and if }
\alpha_p=\alpha_{p+1}, i_p \leq  i_{p+1}
$$
We have $M(\Lambda)_\lambda=\{m|Hm=\lambda(H)m\}$ weight spaces.
$$
M(\Lambda)=\bigoplus_{\lambda \in \mathfrak{h}^*}M(\Lambda)_\lambda
$$
The vector $v_{\Lambda}$ is in $M(\Lambda)_\Lambda$ by definition,
\begin{align*}
F_{\alpha,i}V_\Lambda &\in M(\Lambda)_{\Lambda-\alpha}\\
H(Fv_\Lambda)&=\underbrace{[H,F]v_\Lambda}_{=-\alpha(H)Fv_\Lambda}
+\underbrace{FHv_\Lambda}_{=\Lambda(H)FV_\Lambda}
\end{align*}
So $\chi_{M(\Lambda)}=\sum_{\lambda \in \mathfrak{h}^*}\dim M(\Lambda)_\lambda
e^{\lambda}$
is computed by counting monomials $y$ with fixed $\sum_{i}\alpha_i$.

\begin{equation}
\label{equation-character-of-Verma-module}
\chi_{M(\Lambda)}=e^{\Lambda}\prod_{\alpha \in \Delta_+}
\frac{1}{(1-e^{-\alpha})^{\dim \mathfrak{g}_\alpha}}.
\end{equation}
The product on Eq. \ref{equation-character-of-Verma-module} is called 
{\it Weyl denominator}.
\begin{exercise}
\label{exercise-convince-yourself}
Convince yourself of this.
\end{exercise}

\begin{example}
\label{example-sl2-character}
$\mathfrak{g}=\mathfrak{sl}_2$, [Picture]
\begin{align*}
\chi_{M(\Lambda)}&=e^{\Lambda}+e^{\Lambda-\alpha}+e^{\Lambda-2\alpha}+\ldots\\
&=e^{\Lambda}(1+e^{-\alpha}+e^{-2\alpha}+\ldots\\
&=e^{\Lambda}\frac{1}{1-e^{-\alpha}}.
\end{align*}
\end{example}

\medskip\noindent
For certain $\Lambda$, $M(\Lambda)$ is {\it reducible} (i.e. there exists
a submodule $0 \neq N \subset M(\Lambda)$ (with proper contention).

\begin{lemma}
\label{lemma-}
For any submodule $N$,
$$
N=\bigoplus_{\mu \in \mathfrak{h}^*}N \cap M(\Lambda)_\mu.
$$
\end{lemma}

{\bf Corollary.} The sum of all  \underline{proper} submodules 
of  $M(\Lambda)$ is proper, in particular
there is a maximal proper submodule.

{\bf Notation.} $L(\Lambda)=M(\Lambda)\Big/\left(\substack{
\text{max. proper} \\ \text{submodule}}\right)$

\begin{example}
\label{example-}
$\mathfrak{sl}_2$. $\Lambda=3\omega$ ($\omega$: fundamental weight,
$\alpha=2\omega$.) 
$L(3\omega)=\mathbb{C}\left<e^{3\omega},e^{-\omega},e^{-3\omega}\right>$.

[Picture]
\end{example}

\begin{definition}
\label{definition-integrable-g-module}
A $\mathfrak{g}$-module is {\it integrable} if
\begin{itemize}
\item $V=\bigoplus_{\mu \in \mathfrak{h}^*}V_\mu$ (weight module).
\item For all simple roots $\alpha_i$; $e_i$ and $f_i$ are
locally nilpotent on $V$ (i.e. for all $v \in V$
there exists $N$ such that
$e_i^Nv=f_i^Nv=0$.)
\end{itemize}
\end{definition}

\begin{remark}
\label{remark-integrability}
\begin{itemize}
\item Vermas are not integrable.
\item $\dim V< \infty \implies V$ integrable.
\item $\mathfrak{g}$ itself (Kac-Moody) is integrable.
\end{itemize}
\end{remark}

\medskip\noindent
{\bf Dominant integrable weights.} 
Let $\{\alpha_1^\vee,\ldots,\alpha_\ell^\vee\}\subset\mathfrak{h}$ be the simple
coroots.

\begin{definition}
\label{definition-dominant-integral-weights}
The {\it dominant integral weights} are the weights that pair with the coroots
to give integers:
$$
P_+=\{\lambda \in \mathfrak{h}^* :
\left<\lambda,\alpha_i^\vee\right>\in\mathbb{Z}_{\geq 0,1},
i=1,\ldots,\ell\}.
$$
\end{definition}

For $L(\Lambda)$ to be integrable, it is necessary that $\Lambda \in P_+$.

Indeed, suppose $L(\Lambda)$ is integrable.
Then $f_i^Nv_\Lambda=0$ in $L(\Lambda)$,
or rather 
$$
\underbrace{e_if_i^{N+1}v_\Lambda}
_{Kf_i^N=0} \in M(\Lambda),
$$
and $K$ can only be zero if $\left<\Lambda,\alpha_i^\vee\right>
\in \mathbb{Z}_{\geq 0}$. Applying for all $i$, we find
$\Lambda \in P_+$ is necessary.

\begin{proposition}
\label{proposition-integrable-iff-dominant-integral-weight}
$L(\Lambda)$ is integrable if and only if $\Lambda \in P_+$.
\end{proposition}

\begin{proof}
For the converse, use induction and Serre relations 
(we know the result for the highest weight, and want
to prove for others).
\end{proof}

\begin{example}
\label{example-sl3-integrability}
$\mathfrak{sl}_3$. [Picture]
\end{example}

\begin{example}
\label{example-sl_2hat-integrability}
$\widehat{\mathfrak{sl}_2}$. [Picture, $P_+$ looks like diagonal lines.]
$$
\alpha_0^\vee=K-H,\qquad \alpha_1^\vee=H\in\mathfrak{sl}_2,
\qquad \left<\delta,\alpha_i^\vee\right>=0,\quad i=0,1
$$
\end{example}

\begin{remark}
\label{remark-Verma-for-affine-Kac-Moody-algebras-
the-coefficient-of-K-is-super-important}
For affine Kac-Moody algebras, almost nothing about the structure of 
$M(\Lambda)$ depends on the coefficient of $\delta$ in $\Lambda$. 
So it's common to consider
$$
M(\Lambda)=M_k(\lambda)=M(k\Lambda_0+\lambda),\qquad \lambda \in \mathfrak{h}^*
$$
where $k$, the level of $\Lambda$, is super important.
\end{remark}

Then
$$
\underbrace{\hat{P}_+}_{
\substack{\delta\text{-coef.} \\ =0}}
=\bigcup_{k \in \mathbb{Z}_{\geq 0}}
\{k\Lambda_0+\lambda|\lambda \in P_+^k\}
\{k\Lambda_0+\lambda|\lambda \in P_+^k\}.
$$
$$
P_+^k=\{\lambda \in P_+|
\left<\lambda,\theta\right>\leq k\}\subset P_+ \text{ for }\mathfrak{g}.
$$

\medskip\noindent
Consider $V= \bigoplus_{\mu \in \mathfrak{h}^*}V_\mu$ integrable,
and $V_\lambda \neq 0$.
Let $i \in \{1,\ldots,\ell\}$.
Consider $U=\bigoplus_{n \in \mathbb{Z}}V_{\lambda+n\alpha_i}\subset V$,
and the action of $e_i,f_i$ and $h_i=[e_i,f_i]$.

$\mathfrak{sl}_2\mathbb{y}U$, locally integrable. By structure of
$\mathfrak{sl}_2$-represenations, $U$ must be finite-dimensional
with ``symmetrical'' weight space multiplicities, i.e.,
\begin{align*}
\{\lambda+n\alpha_i|n\in\mathbb{Z}\}\cap \{\text{weights of }V\}
&=\{\lambda+n\alpha_i|-p\leq n\leq q\}.
\end{align*}
and
$$
\left<\lambda-p\alpha_i,h_i\right>=-\left<\lambda+q\alpha_i,h_i\right>.
$$
\medskip\noindent
Consequently, the reflection
$r_i(\lambda):=\lambda-\left<\lambda,\alpha_i^\vee\right>\alpha_i$
has the same multiplicity as $\lambda$.

[Picture]

Now consider $M(\lambda)$ and $L(\Lambda)$ for 
$\Lambda \in P_+$.
Actually, for general $\Lambda$, $M(\Lambda)$, while not
necessarilly irreducible, has an
($\Omega$-)composition series$^*$ by 
irreducibles $L(\lambda)$.
$$
M(\Lambda)=V_0 \supset V_1 \supset V_2 \supset \ldots \supset V_n=0,
$$
such that $V_i/V_{i+1}$ is $\simeq L(\lambda_i)$ (i.e. an irreducible highest
weight module) for some $\lambda_i=\Lambda-\beta_i$, $\beta_i \in Q$. For
Kac-Moody algebras we also consider the case that $(V_i/V_{i+1})=0$ for all
$\mu \in \Omega + Q_+$, (which is the $\Omega$-composition series).

[Picture.]

For an $\Omega$-composition series, as above, we have
$$
\text{ch}_{M(\Lambda)}-\sum_{\lambda \geq \Omega}
\underbrace{[M(\Lambda):L(\lambda)]}
_{\substack{\text{\# of times $L(\lambda)$} \\ \text{
appears in the compos. series}}}
\text{ch}_{L(\lambda)}
\in \left<e^{\mu}:\mu \not \geq \Omega\right>
$$
Sending  ``$\Omega \to -\infty$'', the identity
$$
\text{ch}_{M(\Lambda)}=\sum_{\lambda \leq  \Lambda}
[M(\Lambda):L(\lambda)]\text{ch}_{L(\lambda)}
$$
makes sense.

{\bf Notation.} $b_{\Lambda,\lambda}=[M(\Lambda):L(\lambda)]$.

\begin{remark}
\label{remark-total-order-on-hstar}
Recall the partial order on weights that $\lambda \leq \Lambda$ if 
$\Lambda-\lambda \in Q= \sum \mathbb{Z}_+\alpha_i$.
$b_{\Lambda,\lambda}=1$ if $\lambda = \Lambda$ and 
$b_{\Lambda,\lambda}=0$ if not ($\lambda \leq  \Lambda$).

If we choose a total order on $\mathfrak{h}^*$, compatible with $\leq$.
Then $\{b_{\Lambda,\lambda}\}$ is a lower triangular matrix with 1 
on the diagonal.
We an define $\{m_{\Lambda,\lambda}\}$ the {\it inverse matrix}.
It's again lower triangular, 1 on the diagonal, and all
$m_{\Lambda,\lambda}$ are \underline{integers} (maybe negative now). 
And we have
\begin{equation}
\label{equation-character}
\text{ch}_{L(\Lambda)}=\sum_{\lambda \leq  \Lambda}m_{\Lambda,\lambda}
\text{ch}_{M(\lambda)}.
\end{equation}
\end{remark}

\begin{example}
\label{example-sl2-characters}
$\mathfrak{sl}_2$. $M(3)\underset{L(3)}{\supset}M(-5)
\underset{L(-5)}{\supset}0$. Since $M(-5)$ is already irreducible.
[Missing…]
\end{example}

We want to discover $m_{\Lambda,\lambda}$. 
In general massively difficult.
For $\Lambda \in P_+$, $m_{\Lambda,\lambda}$ easy.
Multiply Eq. \ref{equation-character} by  $R$
\begin{align*}
R\text{ch}_{L(\Lambda)}&=\sum_{\lambda \geq  \Lambda} m_{\Lambda,\lambda}
e^{\lambda}.
e^{\rho}R\text{ch}_{L(\Lambda)}=\sum_{\lambda \leq  \Lambda}
m_{\Lambda,\lambda}e^{\lambda+\rho}.
\end{align*}
What's $\rho$? It's $\rho \in \mathfrak{h}^*$ chosen so that
$\left<\rho,\alpha_i^\vee\right>=1$, and it's called 
the {\it Weyl vector}.

\begin{remark}
\label{remark-finite-dimension}
For $\mathfrak{g}$ finite-dimensional, $\rho=\sum_{i=1}^\ell \omega_i$ 
necessarily. (And equals $\frac{1}{2}\sum_{\alpha \in \Delta_+}\alpha$.

For $\mathfrak{g}$ finite dimensional and the affine $\hat{\mathfrak{g}}$,
$\hat{\rho}=h^\vee\Lambda_0+\rho$ works.
\end{remark}

For $w \in W=\left<r_i|i=1,\ldots,\ell\right>$,
define $w(\text{ch}_V)=\sum \dim V_\mu e^{W(\mu)}$.
We saw $w(\text{ch}_V)=\text{ch}_V$ if $V$ integrable.
In particular $w(\text{ch}_{L(\Lambda)}=\text{ch}_{L(\Lambda)}$,
$\Lambda \in P_+$.

\begin{lemma}
\label{lemma-for-Weyl-formula}
$m_{\Lambda,\lambda}=0$ unless
$\lambda+\rho=w(\Lambda+\rho)$ for some $w \in W$
\end{lemma}

\medskip\noindent
{\bf Claim.} $r_i(e^{\rho} R)=-e^\rho R$. 
So $w(e^\rho R)=\det(w)e^\rho R$ for all $w \in W$.

\begin{proof}
$$
R=\prod_{\alpha \in \Delta_+}(1-e^{-\alpha})^{\text{mult}(\alpha)}.
$$
Note that
\begin{enumerate}
\item $\text{mult}(r_i(\alpha))=\text{mult}(\alpha)$ 
for all $\alpha \in \Delta$. (Since $\mathfrak{g}$ is integrable!)
\item $r_i(\Delta_+)=\{-\alpha_i\}\cup (\Delta_+\setminus\{\alpha_i\}$.
\end{enumerate}
Any $\alpha \in \Delta_+$ is of the form
$\alpha = \sum_{i=1}^\ell k_i \alpha_i$.
If $\alpha \neq \alpha_i$, some $k_{j_0}\neq 0$, $j_0 \neq  i$ and
\begin{align*}
r_i(\alpha)&=\sum_{j}k_j \alpha_j
\left<\alpha,\alpha_i^\vee\right>\alpha_i\\
&=\sum k_j' \alpha_j\\
&=e^\rho(e^{-\alpha_i}-1)
\left(\prod_{\alpha \in \Delta_+ \setminus \alpha_i}\right)\\
&=-e^\rho R.
\end{align*}
for $k_{j_0}'=k_{j_0}>0$. Can't have a mixture of signs,
so $r_i(\alpha) \in \Delta_{\perp}$.

So
\begin{align*}
r_i(e^\rho R)&=\prod_{\alpha \in \Delta_+\setminus \alpha_i}
(1-e^{-\alpha})^{\text{mult}(\alpha)}
\cdot (1-e^{t \alpha_i}\cdot e^{\rho-\alpha_i}
\end{align*}
$$
r_i=\rho-\left<\alpha_i^\vee,\rho\right>\alpha_i=\rho-\alpha_i
$$
Hence
$$
\sum_{\lambda \leq  \Lambda}m_{\Lambda,\lambda}e^{\lambda+\rho}
$$
is $W$-skew-invariant. (Lemma \ref{lemma-for-Weyl-formula}.)

Hence
$$
\sum_{\lambda \leq  \Lambda}m_{\Lambda,\lambda}e^{\lambda+\rho}
=\sum_{w \in W}\det(w)\cdot e^{w(\Lambda+\rho)}
$$
In conclusion, the {\it Weyl character formula} 
$$
\text{ch}_{L(\Lambda)}=\sum_{w \in W}\det(w)
\cdot \frac{e^{w(\Lambda+\rho)-\rho}}{R}
$$
\end{proof}

\medskip\noindent
{\bf Corollary (Weyl denominator formula).}
$$
e^{\rho}R=\sum_{w \in W}\det(w)e^{w(\rho)}.
$$
Next time: Affine case, $\theta$-functions. Modular forms (Poisson summation.)

\section{Characters of integrable highest weight for affine Kac-Moody algebras}
\label{section-characters-of-integrable-highest-weight-
for-affine-Kac-Moody-algebras}

Can be calculated using the Weyl character formula.

Recall: $\hat{\mathfrak{g}}=\mathfrak{g}[t,t^{-1}] \oplus \mathbb{C}K
\oplus \mathbb{C}d$.

Dual Cartan $\hat{\mathfrak{h}}^*=\mathfrak{h}^*\oplus\mathbb{C}\Lambda_0
\oplus\mathbb{C}\delta$.

We consider weights $\Lambda=k\Lambda_0+\lambda$, $\lambda \in \mathfrak{h}^*$,
$k \in \mathbb{Z}_+$, $\lambda \in P_+^k$.

Simple roots: $\alpha_0=\delta-\theta$, $\{\alpha_1,\ldots,\alpha_\ell\}
\subset \mathfrak{h}^*$.

The affine Weyl group is (the {\it semidirect} product!)
$$
\widehat{W}=\left<r_0,\ldots,r_\ell\right> \cong W \times T
$$
where $T=\{t_\alpha | \alpha \in Q\}$, where
$t_\alpha$ is the translation
$$
t_\alpha(\Lambda)=\Lambda+k\alpha-\left((\lambda,a)+k
\frac{|\alpha|^2}{2}\right)\delta
$$
$\Lambda=k\Lambda_0+\lambda$.

\medskip\noindent
Let's compute $\chi_{L(\Lambda_0)}$ using the Weyl character formula
$$
\chi_{L(\Lambda)}=\frac{\sum_{w \in \tilde{W}}\varepsilon(w)
e^{W(\Lambda+\rho)-\rho}}{R}
$$
Firstly $R=\prod_{\alpha \in \hat{\Delta}}(1-e^{-\alpha})
^{\text{mult}(\alpha)}$

Recall
\begin{align*}
\hat{\Delta}_+&=\{m\delta | m \in \mathbb{Z}_{\geq 1}\}
\cup \{\alpha_1+m\delta|m \in \mathbb{Z}_{\geq 0}\}
\cup \{-\alpha_1+m \delta |m \in \mathbb{Z}_{\geq 1}\}
\end{align*}
So let's write $e^{m \delta}=q^m$ (i.e. $q = e^{-\delta}$, is a symbol)
and $y=e^{\alpha_1}$.

So
$$
R=\prod_{n=1}^{\infty}\underbrace{(1-y^{-1}q^{n-1})
}_{\alpha+(n-1)\delta
}\underbrace{(1-q^n)
}_{n\delta}\underbrace{(1-yq^n)
}_{-\alpha+n\delta}
$$
Now let's express numerator also in terms of $q$ and $y$

$$
\hat{\rho}=h^\vee\Lambda_0+\rho
$$
$h^\vee$ dual Coxeter number for $\mathfrak{g}$. 
For $\mathfrak{g}=\mathfrak{sl}_2$, $h^\vee=2$.
(For $\mathfrak{g}=\mathfrak{sl}_n$, $h^\vee=n$ and $\mathfrak{g}=E_8$,
$h^\vee=30$.)

For $\mathfrak{sl}_2$, $\rho=\frac{1}{2}\alpha_1=\omega_1$.

$\Lambda=\Lambda_0$, $\Lambda+\rho=3\Lambda_0+\omega_1$.

Using the formula, we find
\begin{align*}
&t_{m \alpha_1}(3\Lambda_0+\omega_1)-(\Lambda_0+\omega_1)=\\
&\ldots,\Lambda_0-3\alpha,-2\delta,\Lambda_0,\Lambda_0+3\alpha_1-4\delta,\ldots
\end{align*}

[Picture]

$\hat{W}=T \cup  T\sigma,$ $\sigma=r_1$ finite reflection.

\medskip\noindent
{\bf Notation.} $w(\Lambda+\rho):=w \circ \Lambda.$

One finds
\begin{align*}
\sum_{w \in \widehat{W}}\varepsilon(w)e^{w \circ \Lambda_0}&=
e^{\Lambda_0}\left(
\underbrace{1+y^3q^4+y^{-3}q^2+\ldots}_{\text{+ signs because $w \in T$}}
\underbrace{-y^{-1}-y^2q^2-\ldots}_{\text{$-$ signs because $w \in T_\sigma$}}
\right)
\end{align*}

We find explicitly
\begin{align*}
\chi_{L(\Lambda_0)}&=e^{\Lambda_0}
\frac{\sum_{m \in \mathbb{Z}}
y^{3m}q^{3m^2+m}-\sum_{m \in \mathbb{Z}}
y^{3m-1}q^{3m^2-m}}
{\prod_{n=1}^\infty(1-y^{-1}q^{n-1})(1-q^n)(1-yq^n)}
\end{align*}

\begin{exercise}
\label{exercise-mathematica}
Put this formula in mathematica and confirm that [Picture]
\begin{align*}
\chi_{L(\Lambda_0)}&=e^{\Lambda_0}
\left(1+q(y^{-1}+1+y)+q^2(y^{-1}+2+y)
+(q^3(2y^{-1}+3+2y)+\ldots\right)
\end{align*}
\end{exercise}

Appears that the central column here are {\it partitions}, i.e. 
$p(n)=$ \# of partitions of $n$. To see why recall the generating function
$\sum_{n=0}^\infty q^np(n)=\prod_{k=1}^\infty\frac{1}{1-q^k}$, and expand.

It would appear that
$$
\chi_{L(\Lambda_0)}=
\prod_{k=1}^\infty\frac{1}{1-q^k}\cdot \sum_{m \in \mathbb{Z}}y^mq^{m^2}
$$
This identity is true, and we will see it has a vertex-algebra interpretation.

\begin{remark}
\label{remark-Jacobi-triple-product-identity}
If we compute $L(0)=1$ using the formula, we obtain
\begin{align*}
\prod_{n=1}^\infty(1-yq^{n-1})(1-q^n)(1-y^{-1}q^n)=\sum(\text{exercise})
\end{align*}
This identity is called the {\it Jacobi triple product identity}.
\end{remark}

These functions
$$
\sum_{n \in \mathbb{Z}}q^{n^2}, \sum_{n \in \mathbb{Z}}y^n q^{n^2},
\sum_{n \in \mathbb{Z}}y^{3n}q^{3n^2+n},\text{ etc…}
$$
are all examples of {\it $\theta$-functions}.

\begin{remark}
\label{remark-}
In the formula for $\chi_{L(\Lambda_0)}(y,q)$, 
we could put $y=1$ to get
\begin{align*}
\chi_{L(\Lambda_0)}(q)&=1+3q+4q^2+7q^3+\ldots\\
&=\prod\frac{1}{1-q^k}\cdot \sum_{m \in \mathbb{Z}}q^{m^2}
\end{align*}
If one looks at $L(\Lambda_0+\omega_1)$ (the other $\Lambda \in P_+^1$),
$$
\chi_{L(\Lambda+\omega_1)}=\prod \frac{1}{1-q^k}
\sum_{m \in \mathbb{Z}}q^{(m+1/2)^2-1/4}
$$
\end{remark}

\section{$\theta$-functions}
\label{section-theta-functions}
Let's consider
$$
\theta(\tau)=\sum_{n \in \mathbb{Z}}q^{n^2/2},\qquad q=e^{2\pi i \tau}
$$
This converges (absolutely on compact regions in) 
the comain $\text{Im}(\tau)>0$.

Consider the Fourier transform
$$
\hat{g}(y)=\int_{-\infty}^\infty g(x)e^{2\pi ixy}dx
$$

\begin{theorem}[Poisson summation]
\label{theorem-Poisson-summation}
 $$
\sum_{n \in \mathbb{Z}}g(n)=\sum_{n \in \mathbb{Z}}\hat{g}(n)
$$
\end{theorem}

Let's take $g(x,t)=e^{-\pi tx^2}$.
Then $\theta(it)=\sum_{n\in \mathbb{Z}}g(n,t)$.

In this case
$$
\hat{g}(y)=\sqrt{t}e^{-\pi y^2/t}
$$
(integral of Gaussian).

So we conclude that
$$
\theta\left(-\frac{1}{\tau}\right)=\sqrt{\frac{\tau}{i}}\theta(\tau)
$$
Note also that
$$
\theta(\tau+2)=\theta(\tau)
$$
because $q^{\frac{1}{2}}=e^{\pi i\tau}$.

So $\theta(\tau)$ is an example of a modular for.

\medskip\noindent
What is a modular form? Let 
$$
\text{SL}_2(\mathbb{Z})=\left\{ 
\begin{pmatrix}
a&b\\ 
c&d
\end{pmatrix}|a,b,c,d \in \mathbb{Z}, \det =1 \right\}, 
$$
which acts on $\mathbb{H}=\{\tau \in \mathbb{C}|\text{Im}(\tau)>0\}$ by
 $$
\begin{pmatrix}
a&b\\ 
c&d
\end{pmatrix}\cdot\tau=\frac{a\tau+b}{c\tau+d}.
$$
\begin{definition}
\label{definition-weak-modular-form}
Let $\Gamma=\text{SL}_2(\mathbb{Z})$ or some subgroup.
A {\it (weak) modular form (of weight $k$)} is $f:\mathbb{H}\to \mathbb{C}$ 
holomorphic such that
\begin{equation}
\label{equation-weak-modular-form}
f\left(\frac{a\tau+b}{c\tau+d}\right)=(c\tau+d)^kf(\tau).
\end{equation}
If we demand that $\Gamma$
 contains $\begin{pmatrix}
1&N\\ 
0&1
\end{pmatrix}$ for some $N\geq 1$,
(so $f(\tau+N)=f(\tau)$, and so $f(\tau)
=\sum_{n=-\infty}^\infty a(n)q^{2\pi in/2}$), for $f:\mathbb{H}\to
\mathbb{C}$ satisfying Eq. \ref{equation-weak-modular-form} and such that
 $f(\tau)$ is ``meromorphic at cusps'', i.e.
$f(\tau)=\sum_{n \geq N_0}a(n)q^{n/N}$, etc.

Finally we would add a factor
$$
f\left(\frac{a\tau+b}{c\tau+d}\right)=
\varepsilon(A)(c\tau+d)^kf(\tau).
$$
\end{definition}

So in particular a weight-0 modular form is a modular function.

Denote $S=\begin{pmatrix}
0&-1\\ 
1&0
\end{pmatrix}$. So $S\tau=-\frac{1}{\tau}$, and denote 
$T=\begin{pmatrix}
1&1\\ 
0&1
\end{pmatrix}$, so $T\tau = \tau+1$.

Then $\Gamma=\left<S,T^2\right>\subset \text{SL}_2(\mathbb{Z})$.

We saw
\begin{align*}
\theta(T^2\tau)&=\theta(\tau)\\
\theta(S\tau)&=\sqrt{\frac{\tau}{i}}\theta(\tau)=i^{-1/2}
(c\tau+d)^{1/2}\theta(\tau).
\end{align*}
So $\theta(\tau)$ is a modular form of weight $1/2$, for the group
$\Gamma=\left<S,T^2\right>$ with multiplier
system $\varepsilon:\Gamma \to \mathbb{C}^\times$ defined by
\begin{align*}
\varepsilon(S)&=i^{-1/2}\\
\varepsilon(T^2)&=1
\end{align*}

\begin{theorem}
\label{theorem-Dedekind-eta-function}
The {\it Dedekind eta function} 
$$
\eta(\tau)=q^{1/24}\prod_{n=1}^\infty (1-q^n),\qquad q=e^{2\pi i \tau}
$$
is also a modular form of weight $1/2$ for
$\text{SL}_2(\mathbb{Z})=\left<S,T\right>$.
\begin{align*}
\eta\left(-\frac{1}{\tau}\right)&=\sqrt{\frac{\tau}{i}}\eta(\tau)\\
\eta(T\tau)&=e^{2\pi i/24}\eta(\tau).
\end{align*}

\end{theorem}

\section{Vertex algebras}
\label{section-vertex-algebras}

\begin{enumerate}
\item Recall $\hat{\mathfrak{a}}=\mathbb{C}K\oplus 
\bigoplus_{n \in \mathbb{Z}}\mathbb{C}h_n$ the {\it Heisenberg Lie algebra},
or {\it oscillator Lie algebra},
$$
[h_m,h_n]=m\delta_{m,-n}K,\qquad [K,\hat{\mathfrak{a}}]=0.
$$
\begin{remark}
\label{remark-Heisenberg-is-affine}
``It's the simplest case of an affine Lie algebra: a 1-dimensional
Lie algebra with a bilinear form''. It's an example of the affine
Lie algebra construction
$\mathfrak{g} \rightsquigarrow \hat{\mathfrak{g}}$,
where now $\mathfrak{a}=\mathbb{C}$,
and
 \begin{align*}
(\cdot,\cdot): \mathfrak{a}\times\mathfrak{a} &\longrightarrow \mathbb{C} \\
(1,1) &\longmapsto 1
\end{align*}
\end{remark}

\item Witt Lie algebra
$$
W=\bigoplus_{n \in \mathbb{Z}}\mathbb{C}D_n,
$$
$$
[D_m,D_n]=(m-n)D_{m+n}.
$$
\end{enumerate}

\medskip\noindent
The oscillator algebra $\hat{\mathfrak{a}}$ 
has a representation which we have seen already:
$$
H=\mathbb{C}[x_1,x_2,\ldots]
$$

\begin{align*}
h_n&\mapsto \begin{cases}
n \frac{\partial }{\partial x_n}\qquad &\text{if }n>0\\
x_{-n}\qquad &\text{if }n<0\\
0\qquad &\text{if }n=0
\end{cases},
\qquad \qquad  K\mapsto \text{Id}
\end{align*}
A picture of $H$ [Picture].

Here I am introducing a \underline{grading} of $H$:
$$
H=\bigoplus_{n \in \mathbb{Z}_{\geq 0}}H_n,
\qquad H_n=\text{span}\{x_{m_1},\ldots,x_{m_s}|
\sum m_s=n\}.
$$

\begin{remark}
\label{remark-dimensions-are-number-of-partitions}
$\dim(H_n)=$\# $\{\text{integer partitions of }n\}=p(n)$ 
and $\sum_{n=0}^\infty \dim(H_n)q^n=\prod_{k=1}^\infty \frac{1}{1-q^k}$.
\end{remark}

\begin{remark}[Verma module style]
\label{remark-Verma-module-style}
$H$ can be presented alternatively as
$$
H=U(\hat{\mathfrak{a}})\otimes_{U(\hat{\mathfrak{a}}_+)}\mathbb{C}1
$$
where $\mathbb{C}1$ is a 1-dimensional representation of
 $$
\hat{\mathfrak{a}}_+=\bigoplus_{n \geq 0}\mathbb{C}h_n \oplus\mathbb{C}K.
$$
$$
h_n \cdot 1=0\qquad \forall n \geq 0,\qquad K\cdot 1=1
$$
\end{remark}

\begin{exercise}
\label{exercise-H-is-irreducible}
$H$ is irreducible.
\end{exercise}

\begin{proof}
We need to prove that there is no
vector subspace $V \subset \mathbb{C}[x_1,x_2,\ldots]=H$
such that $xV \subset V$ for all $x \in \hat{\mathfrak{a}}$.
And then the proof is basically noticing 
that the orbit of the action of $\hat{\mathfrak{a}}$ on $H$ 
is all of $H$. That is, if we had proper subspace
of $H$, we can always find an element of $\hat{\mathfrak{a}}$ 
that takes some element in $V$ to the one of the
elements that is not in $V$. Indeed, by applying
$h_n$ for  different values of positive  $n$ we can take
any element of $V$ to a constant. Then we apply
$h_n$ for different values of negative $n$ to obtain
any monomial. Then we add these monomials and obtain any
polynomial in $H$.
\end{proof}

\noindent
{\bf Notation.} Instead of $1$ let's write $|0\rangle$.

\begin{remark}
\label{remark-generalise-H}
We can easily generalise $H$ to
$$
H^\mu=U(\hat{\mathfrak{a}}) \otimes_{U(\hat{\mathfrak{a}}_+)} \mathbb{C}
|\mu\rangle,
$$
($\mu \in \mathbb{C}$), where $\hat{\mathfrak{a}}_+$ is the same, but now
\begin{align*}
h_n |\mu\rangle&=\begin{cases}
0\qquad &\text{if }n>0 \\
\mu \cdot|\mu\rangle\qquad& \text{if }n=0
\end{cases}\qquad \qquad 
K|\mu\rangle=|\mu\rangle.
\end{align*}
$H^\mu$ is again a (irreducible) $\hat{\mathfrak{a}}$-module.
\end{remark}

\medskip\noindent
Generalise even more: Let $\mathfrak{h}$ be a finite-dimensional
vector space, and 
$(\cdot,\cdot): \mathfrak{h} \times \mathfrak{h} \to \mathbb{C}$
a symmetric bilinear form.
$\hat{\mathfrak{h}}=\mathfrak{h}[t,t^{-1}]\oplus \mathbb{C}K$,
$$
[at^m,bt^n]=m(a,b)\delta_{m,-n}K,\qquad [K,\hat{\mathfrak{h}}]=0.
$$
Let $\mu\in \mathfrak{h}$. Define
$H^\mu=U(\hat{\mathfrak{h}})\otimes_{U(\hat{\mathfrak{h}})}\mathbb{C}|\mu\rangle$ 
, $\hat{\mathfrak{h}}_+=\mathfrak{h}[t]\oplus\mathbb{C}K$, and
$$
at^m\cdot |\mu\rangle=\begin{cases}
(\mu,a)|\mu\rangle\qquad &\text{if } m=0\\
0\qquad &\text{if }m>0.
\end{cases}
$$ 

\medskip\noindent
Returning to $\hat{\mathfrak{a}}\mathbb{y}H=H^0$. Introduce
$$
L_m=\frac{1}{2}\sum_{k \in \mathbb{Z}}h_{m-k}h_k.
$$
If $m \neq 0$, this sum is well-defined in $\text{End}(H)$.

Indeed, $h_{m-k}$ and $h_k$ commute ($m \neq 0$), and 
$\forall  p(\underline{x})\in H$, there exists $N$ 
such that $p(\underline{x})=p(x_1,\ldots,x_{N-1})$,
then $h_k\cdot p(x)=0$ $\forall  k \geq N$,
and $h_{m-k}\cdot p(x)=0$ $\forall m-k \geq N$.

So $(\sum h_{m-k}h_k)p(\underline{x})$ is a \underline{finite} sum.
Of course, the number of terms in the sum depends on $p(x)$ and can be
arbitrarily large.

\begin{exercise}
\label{exercise-hard}
If  $m,n$ and $m+n$ are not zero, then
$$
[L_m,L_n]=(m-n)L_{m+n}
$$
holds in $\text{End}(H)$.

(Trying to be a representation of $W$
 $$
D_n \mapsto L_n \in \text{End}(H).)
$$
\end{exercise}

But $\sum_{k \in \mathbb{Z}}h_{-k}h_k$ is not well-defined.
Indeed,
\begin{align*}
\left(\sum_{k \in \mathbb{Z}}h_{-k}h_k\right)1&=
\sum_{k \geq 1}k\frac{\partial }{\partial x_k}(x_k 1)\\
&=(1+2+3+4+\ldots)1
\end{align*}
!

\medskip\noindent
{\bf Normal ordering idea (``that physicist do'').} Let's cheat
and redefine the product as
$$
\,:\!h_{-k}h_k\!:\,
=\begin{cases}
h_{-k}h_k\qquad & \text{if }k\geq 0\\
h_k h_{-k}\qquad &\text{if }k<0.
\end{cases}
$$
Now $\sum_{k \in \mathbb{Z}}:\!h_{-k}h_k\!:$ is well-defined! 

\medskip\noindent
{\bf Notation.} Let us consider series of the form
$$
a(z)=\sum_{n \in \mathbb{Z}}a_{(n)}z^{-n-1},\qquad a_{(n)}\in \text{End}(V),
$$
where $V$ is a vector space.

\begin{definition}[Most important in the course]
\label{definition-quantum-field}
We say $a(z)$ is a {\it quantum field} on $V$ if,
for every $v \in V$ there exists $N \in \mathbb{Z}$ 
such that $a_{(n)}v=0$ $\forall  n\geq N$.
\end{definition}

\begin{example}
\label{example-quantum-field}
$V=H=\mathbb{C}[x_1,x_2,\ldots]$,
$$
a(z)=h(z)=\sum_{n \in \mathbb{Z}}h_n z^{-n-1}.
$$
$$
h(z)=\ldots+3z^{-4}\frac{\partial }{\partial x_3}
+2z^{-3}\frac{\partial }{\partial x_1}+x_1
+x_2z+x_3z^2+\ldots
$$
Any fixed $v \in H$ is $v=p(x_1,\ldots,x_{N-1})$ for some $N$.
Then $h_Nv=N \frac{\partial }{\partial x_N}v=0$.

So $h(z) \mathbb{y} H$ is a quantum field.
\end{example}

\begin{definition}
\label{definition-creating-annihilating-operators}
For a quantum field
(or any series in fact) $a(z)=\sum_{ n \in \mathbb{Z}}a_{(n)}z^{-n-1}$,
define the {\it creation} and {\it annihilating operators}
$$
a(z)_+=\sum_{n \leq -1}a_{(n)}z^{-n-1},\qquad 
a(z)_-=\sum_{n \geq 0}a_{(n)}z^{-n-1}.
$$
\end{definition}

The quantum field condition solves the problem of the infinite series…

The normally order product of quantum fields 
$a(z)=\sum_{n \in \mathbb{Z}}a_{(n)}z^{-n-1}$, and
$b(z)=\sum_{n \in \mathbb{Z}}b_{(n)}z^{-n-1}$ is.
$$
:\!a(z)b(z)\!:\,=a(z)_+b(z)+b(z)a(z)_-.
$$

\begin{exercise}[Most important of the course]
\label{exercise-most-important}
Show that if $a(z)$ and $b(z)$ are quantum fields,
then $:\!a(z)b(z)\!:\,$ is well-defined, and is a quantum field.
\end{exercise}

\medskip\noindent
Next idea: in our example of $h(z) \mathbb{y} H$,
the coefficients $h_n$ were coming from a Lie algebra,
so we had relations
 $[h_m,h_n]=(\ldots)$.
(Indeed, $[h_m,h_n]=m \delta_{m,-n}\text{Id}_H$ in this case.)
We sould like to interpret such relations at the level of $h(z)$.

\begin{align*}
[h(z),h(z)]&=h(z)h(z)-h(z)h(z)\\
&=\sum_{p}\sum_{m+n=p}h_mh_nz^{-(m+n)-2}
-\sum_{m+n=p}h_nh_mz^{-(m+n)-2}\\
&=\sum_p z^{-p-2}\left(\underbrace{\sum_{m+n=p}[h_m,h_n]}_{\text{infinite?}}
\right)
\end{align*}
which is a bad idea, since that sum can be infinite.
Better idea: change a variable:
$$
[h(z),h(w)]=\sum_{m,n \in \mathbb{Z}}[h_m,h_n]z^{-m-1}w^{-n-1}.
$$
In this example,
\begin{align*}
[h(z),h(w)]&=\sum_{m,n \in \mathbb{Z}}m \delta_{m,-n}z^{-m-1}
w^{-n-1}I_H\\
&=\sum_{m \in \mathbb{Z}}z^{-m-1}w^{m-1}I_H.
\end{align*}

Observe (geometric series):
\begin{align*}
\frac{1}{z-w}&=\sum_{k \geq 0}z^{-k-1}w^k\qquad 
\text{(convergent for $|z|>|w|$)}\\
\frac{1}{z-w}&=-\sum_{k \geq 0}w^{-k-1}z^k\\
&=-\sum_{k<0}z^{-k-1}w^k\qquad \text{(convergent for $|z|<|w|$)}
\end{align*}
So, in a sense
$$
\sum_{k \in \mathbb{Z}}z^{-k-1}w^k\text{``$=$''}\frac{1}{z-w}
-\frac{1}{z-w}.
$$
This motivates us to introduce the expression
\begin{definition}
\label{definition-delta-function}
The {\it formal delta function} is
$$
\delta(z,w)=\sum_{k \in \mathbb{Z}}z^{-k-1}w^k \in 
\mathbb{C}[\![z,z^{-1},w,w^{-1}]\!].
$$
\end{definition}
Why delta function? It behaves like Dirac delta.
Recall that $\delta(x)$ is the 
{\it distribution} on $\mathbb{R}$ defined by
$\delta[f(x)]=f(0)$ for all test functions $f(x)$.
Every function $k(x)$ gives a distribution $D_k$.
$$
D_k[f]=\int_{-\infty}^\infty k(x)f(x)dx,
$$
$f \in C_c^\infty(\mathbb{R})$.

If $\delta$ were of the form $D_k$ (it's not)
it would have to look like 
[Picture, positive part of $y$ axis, all $x$ axis.

One can show that (it's a theorem by Plamelj)
$$
\delta(x)=\frac{1}{2\pi i}\lim_{\varepsilon \to 0_+} 
\left(\frac{1}{x-i \varepsilon}-\frac{1}{x-i \varepsilon}\right)
$$
as distributions (i.e. limit taken in ``distributional sense''.)

(So that's why we called the delta function that way.)

Denote by $i_{z,w}$ the ``expansion in positive powers of $w$''.
E.g. 
$$
i_{z,w}\frac{1}{z-w}=\sum_{k\geq 0}z^{-k-1}w^k,
$$
similarly,
$$
i_{z,w}\frac{1}{(z-w)^2}=\sum_{k \geq 0}kz^{-k-1}w^{k-1},
$$
$$
i_{z,w}(w^{-2})=w^{-2}.
$$
\begin{exercise}
\label{exercise-derivative-wrt-w}
So, in fact,
\begin{align*}
[h(z),h(w)]&=i_{z,w}\frac{1}{(z-w)^2}-i_{w,z}\frac{1}{(z-w)^2}
=\partial_w \delta(z,w).
\end{align*}
\end{exercise}

What exactly is $i_{z,w}$?

\medskip\noindent
{\bf Notation.}
\begin{align*}
\mathbb{C}[z]&\qquad \text{ring of polynomials}\\
\mathbb{C}[z,z^{-1}]&\qquad \text{ring of Laurent polynomials}\\
\mathbb{C}[\![z ]\!]&\qquad \text{ring of power series}\\
\mathbb{C}[\![z,z^{-1}]\!]&  \qquad \text{vector space (not ring!) of formal
distributions}\\
\mathbb{C}(\!(z)\!)&\qquad \text{field of Laurent series}
\end{align*}
where the last is $\sum_{n \geq N}fa_n z^n$ for some $N$.

Since $\mathbb{C}(\!(z)\!)$ is a field, $\mathbb{C}(\!(z)\!)(\!(w)\!)$ is
also a field.

There are natural inclusions
$$
\mathbb{C}[z,w] \to \mathbb{C}(\!(z)\!)(\!(w)\!) \to
\mathbb{C}[\![z^{\pm1},w^{\pm 1}]\!].
$$
Let $\mathbb{C}(z,w)$ denote the fraction field
of the domain $\mathbb{C}[z,w]$.
By the property of $\mathbb{C}(z,w)$, there exists an embedding
$$
\xymatrix{
\mathbb{C}[z,w]\ar[rr]\ar[dr]&  &  \mathbb{C}(\!(z)\!)(\!(w)\!)\\
&\mathbb{C}(z,w)\ar[ur]^{i_{z,w}}
}
$$
The following diagram does not commute: [diagram]

We computed
$$
[h(z),h(w)]=\partial_w \delta(z,w)
$$
We can similarly compute
\begin{align*}
h(z)h(w)&=\,:\!h(z)h(w)\!:\,+i_{z,w}\frac{1}{(z-w)^2}\\
h(w)h(z)&=\,:\!h(z)h(w)\!:\,+i_{w,z}\frac{1}{(z-w)^2}.
\end{align*}

\medskip\noindent
{\bf Notation.} We write $\partial_w=\frac{\partial }{\partial w}$ and
$\partial^{(j)}_w=\frac{1}{j!}\partial^j_w$.

\begin{lemma}
\label{lemma-elementary}
\begin{enumerate}
\item If we multiply the delta function with $(z-w)$ we get zero, that is,
$$
(z-w)\delta(z,w)=0.
$$
\item 
$$
i_{z,w}\frac{1}{(z-w)^{j+1}}-i_{w,z}\frac{1}{(z-w)^{j+1}}
=\partial_w^{(j)}\delta(z,w).
$$
\item $\forall j\geq 0$,
$$
(z-w)^{j+1}\partial_w^{(j)}\delta(z,w)=0.
$$
\item Whenever $m \leq j$,
$$
(z-w)^m\partial^{(j)}(z,w)=\partial_w^{(j-m)}\delta(z,w).
$$
\end{enumerate}
\end{lemma}

\begin{proof}

\end{proof}

\begin{remark}
\label{remark-like-usual-Dirac-delta}
All this is completely parallel
to the Dirac $\delta$-distribution $\delta(x)$.
$$
x\delta(x)=0,\qquad x\delta'(x)=\delta(x),\text{ etc.}, x^2\delta'(x)=0.
$$
\end{remark}

\section{The residue pairing}
\label{section-residue-pairing}

Let $f(z) \in \mathbb{C}[z,z^{-1}]$, which is a vector space
with basis $\{z^n:n\in\mathbb{Z}\}$.

An element of the dual vector space is a formal linear combination
$$
\sum_{n \in \mathbb{Z}}c_n\varphi_n,\qquad \text{where }
\varphi_n(z^k)=\begin{cases}
0\qquad &\text{if }k \neq n \\
1\qquad &\text{if }k=n
\end{cases}
$$
(no restriction on the $c_n \in \mathbb{C}$).

Identify $\sum c_n \varphi_n$ with 
$$
c(z)=\sum c_nz^{-n-1}\in \mathbb{C}[z^{\pm 1}
$$
so that $\varphi$ acts on $f(z)=\sum f_nz^n \in \mathbb{C}[z^{\pm 1}]$,
as 
$$
\varphi(f)=\sum_{n}c_nf_n=\text{Res}_zc(z)f(z)dz,
$$
where
\begin{definition}
\label{definition-residue}
If  $U$ is a vector space and $a(z)=\sum_{n}a_nz^n \in U[\![z^{\pm 1}]\!]$,
$$
\text{Res}_za(z)dz=a_{-1}
$$
\end{definition}

Let's record a few properties of $\text{Res}_z(\cdot)dz:=\text{Res}_z(\cdot)$.

\begin{lemma}
\label{lemma-properties-of-residues}
\begin{enumerate}
\item $\text{Res}_zf(z)\delta(z,w)=f(w)$.
\item $\text{Res}_zf(z)(\partial_zg(z))=-\text{Res}_(\partial_zf(z))fg(z)$.
\end{enumerate}
\end{lemma}

\begin{proof}
\begin{enumerate}
\item Straightforward computation.
\item Product rule, and uses that derivatives have no residues.
\end{enumerate}
\end{proof}

So, in our example, $H,h(z)$ we see that
$$
(z-w)^2[h(z),h(w)]=0,
$$
which is a nontrivial example: we really need to 
take the square, and also the bracket is not zero.

\medskip\noindent
\begin{definition}
\label{definition-mutually-local-quantum-fields}
Two quantum fields $a(z)$ and $b(z)$ on a vector space
$V$ are {\it mutually local} if there exists $N$ 
such that
$$
(z-w)^N[a(z),b(w)]=0.
$$
\end{definition}

\begin{remark}
\label{remark-motivation}
See  \cite[Chapter 1]{KVA} for physics motivation.
More generally, if $D=\sum_{m,n}D_{m,n}z^mw^n \in U[\![z^{\pm 1}, w^{\pm
1}]\!]$,
we call $D$ {\it local} if $(z-w)^ND=0$ for some $N$.
\end{remark}

\begin{proposition}
\label{proposition-}
Let $a(z),b(z)$ be a local pair of quantum fields on $V$.
Then 
\begin{equation}
\label{equation-1}
a(z)b(w)= :\!a(z)b(z)\!:+\sum_{j=0}^{N-1}c_j(w)
i_{z,w}\frac{1}{(z-w)^{j+1}}
\end{equation}
and
\begin{equation}
\label{equation-2}
b(w)a(z)=:\!a(z)b(z)\!:+\sum_{j=0}^{N-1}c_j(w)
i_{w,z}\frac{1}{(z-w)^{j+1}}
\end{equation}
In particular,
\begin{equation}
\label{equation-3}
[a(z),b(w)]=\sum_{j=0}^{N-1}c_j(w)\partial_w^{(j)}\delta(z,w).
\end{equation}
Furthermore
\begin{equation}
\label{equation-4}
c_j(w)=\text{Res}_z(z-w)^j[a(z),b(w)].
\end{equation}
\end{proposition}

\begin{proof}
First we prove \ref{equation-3} using \ref{equation-4}. 
\end{proof}

\begin{exercise}
\label{exercise-deduce-1-and-2-from-3}
Deduce \ref{equation-1} and  \ref{equation-2} from \ref{equation-3}.
\end{exercise}

\medskip\noindent
{\bf Notation.} If $a(w)$ and $b(w)$ are quantum fields on $V$,
we denote
$$
a(w)_{(j)}b(w)=\text{Res}_z(z-w)^j[a(z),b(w)]
$$
for $j \in \mathbb{Z}_{\geq 0}$.

\begin{example}
\label{example-}
On $H$, $[h(z),h(w)]=\partial_w\delta(z,w)I_H$.
So $\text{Res}_z\partial_w\delta(z,w)I_H=0$ and
$\text{Res}_z(z-w)\partial_w\delta(z,w)I_H=
\text{Res}_z\delta(z,w)I_H=I_H$.
\end{example}

Note that $I_H$ is a (very simple) quantum field.

The following definition generalizes the $j$-product to any
integer, possible negative.

\begin{definition}
\label{definition-nth-product}
For $n \in \mathbb{Z}$, and $a(w)$, $b(w)$ quantum fields,
we define the {\it $\text{n}^{\text{th}}$ product} $a(w)_{(n)}b(w)$ as
$$
a(w)_{(n)}b(w)=\text{Res}_z
[i_{z,w}(z-w)^na(z)b(w)-i_{w,z}(z-w)^nb(w)a(z)].
$$
\end{definition}

\begin{remark}
\label{remark-nth-product}
\begin{enumerate}
\item We recover the prior definition: if $n \geq 0$,
$$
i_{z,w}(z-w)^n=i_{w,z}(z-w)^n=\sum_{r=0}^n\binom{n}{r}z^{n-r}(-w)^r,
$$
a finite sum.
\item (Exercise.) If $n=1$, then
\begin{align*}
a(w)_{(-1)}b(w)&=a(w)_+b(w)+b(w)a(w)_-\\
&=:\! a(w)b(w)\!:
\end{align*}

\item (Exercise.) 
The more negative products are not something new:
for $k \geq 0$,
$$
a(w)_{(-k-1)}b(w)=:\!(\partial_w^{(k)}a(w))b(w)\!:
$$
\end{enumerate}
\end{remark}

We have actually already used the following proposition:

\begin{proposition}
\label{proposition-nth-product-is-quantum-field}
If $a(w),b(w)$ are quantum fields, then $a(w)_{(n)}b(w)$
is also a quantum field for all $n \in \mathbb{Z}$.
\end{proposition}

\begin{definition}
\label{definition-vertex-algebra}
A {\it vertex algebra} consists of a vector space $V$,
a set $\mathcal{F}$ of quantum fields on $V$,
a nonzero vector $|0\rangle\in V$,
and a linear map $T:V \to V$,
such that
\begin{enumerate}
\item $T|0\rangle=0$, and $[T,a(z)]=\partial_za(z)$ 
$\forall a(z) \in \mathcal{F}$.
\item $V$ is spanned by $a_{(n_1)}^{i_1},\ldots,a_{(n_s)}^{i_s}|0\rangle$,
where $a^{i_j}(z) \in \mathcal{F}$ (and 
$s(z)=\sum a_{(n)}z^{-n-1}$ always).
\item All pairs $a(z),b(z) \in \mathcal{F}$ are mutually local. 
(We saw (ref?) that this is equivalent to 
$[a(z),b(w)]=\sum_{j=0}^{N-1}c_j(w)\partial_w^{(j)}\delta(z,w)$ and
described the coefficients $c_j$, …)
\end{enumerate}
\end{definition}

We call $|0\rangle$ the {\it vacuum vector} and $T$ the {\it translation
operator}.

In fact, our Heisenberg example that we've been discussing
so far is an example:

\begin{example}
\label{example-Heisenberg-is-vertex-algebra}
$V=H=\mathbb{C}[x_1,x_2,\ldots]$,
$\mathcal{F}=\{h(z)\}$, $|0\rangle=1$, $T=?$,
is a vertex algebra.

\noindent
{\bf Answer 1.} Recall $L(z)=\frac{1}{2}:\!h(z)h(z)\!:=
\frac{1}{2}h(z)_{(-1)}h(z)$, $L(z)=\sum_{m \in \mathbb{Z}}L_mz^{-m-z}$.
In particular, $L_{-1}=\frac{1}{2}\sum_{k \in Z}h_kh_{-1-k}$.
Well, $T=L_{-1}$.

\noindent
{\bf Answer 2.} Given that $T$ must satisfy
$T1=0$, and $[T,h(z)]=\partial_zh(z)$, i.e.
$$
[T,h_n]=-nh_{n-1},
$$
and $H$ is generated from $1$ by $\{h_n|n\leq -1\}$,
the action of $T$ on $H$ (if well-defined) is
completely determined.
\end{example}

\begin{exercise}
\label{exercise-write-a-formula}
Write a formula for $T(x_1^{m_1}x_2^{m_2}\ldots x_s^{m_2})$.
\end{exercise}

\section{A second definition of vertex algebra}
\label{section-second-definition-of-vertex-algebra}

\noindent
Now we aim for a second definition of vertex algebras.

Let $(V,|0\rangle,T,\mathcal{F})$ be a vertex algebra.
Define
\begin{align*}
\tilde{\mathcal{F}}&=\{\text{quantum fields $a(z)$ on $V$}
|[T,a(Z)]=\partial_za(z)\}\\
\overline{\mathcal{F}}&=\bigcup_{k\geq 0}\mathcal{F}_k,\\
\mathcal{F}_0&=\{I_V\},\\
\mathcal{F}_k&=\{a(z)_{(n)}b(z)|a(z)\in \mathcal{F},b(z),\mathcal{F}_{k-1}\}\\
\mathcal{F}'&=\{b(z) \in \tilde{\mathcal{F}}|a(z),b(z)\text{ is local},
\forall  a(z) \in \mathcal{F}\}
\end{align*}
Where $I_V$ is the identity of $V$ considered as a quantum field.
The idea is that this is like taking a subalgebra and taking
the commutator over and over again.

\begin{lemma}
\label{lemma-simple-lemma1}
$a(z)_{(-1)}I_V=a(z)$.
\end{lemma}

\begin{proof}
Direct calculation.
\end{proof}

\begin{lemma}
\label{lemma-simple-lemma2}
$a(z)_{(-n-1)}I_V=\partial_z^{(n)}a(z)$.
\end{lemma}

\begin{proof}
Similar.
\end{proof}

\begin{lemma}[Dong]
\label{lemma-Dong}
Suppose $a(z),b(z)$ and $c(z)$ are mutually local in pairs.
Let $n \in \mathbb{Z}$. Then $a(z)_{(n)}b(z)$ and $c(z)$
is a local pair.
\end{lemma}

\begin{proof}
Done in lecture.
\end{proof}

Therefore
$$
\mathcal{F} \subset \overline{\mathcal{F}}\overset{\text{Dong}}{\subset}
\mathcal{F}'\subset \tilde{\mathcal{F}}
$$
\begin{remark}
\label{remark-Fbar-subset-Ftilde}
To be sure, we should check $\overline{\mathcal{F}}\subset \tilde{\mathcal{F}}$.
\end{remark}

F tilde is the translation invariant
\begin{exercise}
\label{exercise-Fbar-subset-Ftilde}
If $[T,a(z)]=\partial_za(z)$, $[T,b(z)]=\partial_zb(z)$,
then
$$
[T,a(z)_{(n)}b(z)]=\partial_z(a(z)_{(n)}b(z)).
$$
\end{exercise}

\begin{theorem}
\label{theorem-}
\begin{enumerate}
\item For any $a(z) \in \tilde{\mathcal{F}}$,
\label{item-vertex-algebra-second-definition-1}
\begin{align*}
a(z)|0\rangle&=v+z\cdot Tv+\frac{z^2}{2}T^2v+\ldots\\
&=e^{2T}\qquad (v\in V)
\end{align*}
Thus we define
\begin{align*}
s: \tilde{\mathcal{F}} &\longrightarrow V \\
a(z) &\longmapsto a(z)|0\rangle|_{z=0}
\end{align*}

\item 
\label{item-vertex-algebra-second-definition-2}
$$
s(z(z)_{(n)}b(z)=a_{(n)}s(b(z)).
$$
\item Let $\mathcal{G} \subset \tilde{\mathcal{F}}$ be
\label{item-vertex-algebra-second-definition-3}
such that $s(\mathcal{G})=V$, and suppose
$a(z)$ is local with all $b(z) \in \mathcal{G}$.
``If you commute with a large enough bunch of guys,
you are close enough to being zero.''
If $s(a(z))=0$, then $a(z)=0$.
\end{enumerate}
\end{theorem}

\begin{proof}
\begin{enumerate}
\item We need to prove $a(z)|0\rangle$ does not have negative
powers of $z$. So suppose it does, i.e. there is $n\geq 0$ such that
$a_{(n)}|0\rangle z^{-n-1}\neq 0$.

Idea: use translation invariance to pair $n$ and $-n$, and
then the fact that $a(z)$ is a quantum field to get some vanishing.

So first we translate and find that: 
$$
Tv(z)=Ta((z)|0\rangle=(Ta(z)-a(z)T)|0\rangle=\partial_z a(z)|0\rangle
$$ 
so that
\begin{equation}
\label{equation-star}
v_n=\frac{1}{n}Tv_{n-1},\qquad (n \neq 0).
\end{equation}
So, $v_n \neq 0$ for some $n<0 \implies v_{n-1}$ also not zero.
But we also know by $a(z)$ being a quantum field
that there exists $N$ such that $a_{(n)}|0\rangle=0$ for all $n \geq N$.
So, we'd have a contradiction.
So $v(z)=\sum_{n \geq 0}v_nz^n$.

Now Eq. \ref{equation-star} also implies
$$
v_1=Tv_0,v_0=\frac{1}{2}Tv_1,\ldots, v_n=\frac{1}{n!}T^nv_0.
$$
So $a(z)|0\rangle=e^{zT}v_0$ $(v_0 \in V)$.

\item Consider 
$$
a(w)_{(n)}b(w)|0\rangle=
\text{Res}_z(a(z)b(w)i_{z,w}(z-w)^n-
\underbrace{b(w)a(z)i_{w,z}(z-w)^n}_{=0}
$$ 
where that vanishing is because the $i_{w,z}$ expands the argument
in positive powers, and $b(w)a(z)$ also has only positive powers
since $a(z)|0\rangle$ also has only positive powers 
(and the residue picks the coefficient of the power  $-1$).
So we obtain
$$
=\text{Res}_za(z)b(w)i_{z,w}(z-w)^n.
$$
But
\begin{align*}
s(a(w)_{(n)}b(w))&=\left(
\text{Res}_zs(z)b(w)i_{z,w}(z-w)^n|0\rangle\right)|_{w=0}\\
&=\text{Res}_za(z)b(w)z^n|0\rangle|_{z=0}\\
&=\text{Res}_z z^n a(z)(s(b(w)))\\
&=\text{Res}_z z^n \sum_{k}a_{(k)}z^{-k-1}s(b)\\
&=a_{(n)}s(b).
\end{align*}

\item By locality, there exists $N$ such that
\begin{align*}
(z-w)^Na(z)b(w) |0\rangle&=(z-w)^Nb(w)a(z)|0\rangle\\
&=(z-w)^Nb(w)e^{2T}s(a)=0
\end{align*}
\begin{align*}
(z-w)^Na(z)b(w)|0\rangle |_{w=0}&=0\\
\implies z^Na(z)s(b)&=0\\
\implies a(z)v&=0\\
\implies a(z)&=0
\end{align*}
\end{enumerate}
\end{proof}

\medskip\noindent
{\bf Corollary.}
\begin{enumerate}
\item $S|_{\mathcal{F}'}$ is injective.
\item $S|_{\overline{\mathcal{F}}}$ is surjective.
\item $S|_{\mathcal{F}}$ is isomorphism $\overline{\mathcal{F}}\to V$.

So we define the inverse (linear) map $Y:V \to \overline{\mathcal{F}}$,
i.e. for all $a \in V$, $Y(a,z)$ denotes $s^{-1}(a) \in \overline{\mathcal{F}}$.

\item $(V,|0\rangle,T,\overline{\mathcal{F}})$ is a vertex algebra,
and
$$
Y(a_{(n)}b,z)=Y(a,z)_{(n)}Y(b,z)\qquad \forall a,b \in V.
$$
\end{enumerate}

So we have
$$
\xymatrix{
\mathcal{F}\ar[r]&\overline{\mathcal{F}}\ar@{->>}[d]\ar[r]&
\mathcal{F}'\ar@{^{(}->}[d]\ar[r]&\tilde{\mathcal{F}}\ar[d]^s\\
&  V\ar[r]^{\text{id}}& V\ar[r]^{\text{id}} &V
}
$$
\begin{proof}
\begin{enumerate}
\item Now we apply part \ref{item-vertex-algebra-second-definition-3}
 in the theorem to $a(z) \in \mathcal{F}'$,
$\mathcal{G}=\overline{\mathcal{F}}$.
If $s(a(z))=0$, then  $a(z)=0$. So  $s:\mathcal{F}' \to V$ is injective
(as in the diagram).

\item By iterating the property in the theorem that
$a_{(n)}s(b(z))=s(a(z)_{(n)}b(z))$ so we can take out ``one by one''
in the following product to obtain
$$
a^1_{(n_1)}\ldots a_{(n_s)}^s |0\rangle
=s(a^1(z)_{(n)}\ldots a^s(z)_{(n_s)}I_V
$$
This proves the double headed arrow in the diagram.

\item Now define $Y(-,z):V \to \overline{\mathcal{F}}$.
$$
s(Y(a,z)_{(n)}Y(b,z))=a_{(n)}s(Y(b,z))=a_{(n)}b.
$$
\item Then all the axioms in our definition of vertex algebra are
satisfied!
\end{enumerate}
\end{proof}

\begin{remark}
\label{remark-a-relation}
Let $(V,|0\rangle,T,\mathcal{F})$ be a vertex algebra.
$\overline{\mathcal{F}}$ and $Y$ as above.
$\forall a,b \in V$,
\begin{equation}
\label{equation-star2}
[Y(a,z),Y(b,w)]=\sum_{j=0}^{N-1}c_j(w)\partial_w^{(j)}\delta(z,w).
\end{equation}
$c_j(w)=Y(a,w)_{(j)}Y(b,w)=Y(a_{(j)}b,w)$.
\end{remark}

Which is like something we had written before.
But now we know more. Let us extract
the $z^{-m-1},w^{-n-1}$ coefficient of Eq. \ref{equation-star2}.
We obtain
$$
LHS=\sum_{m,n}[a_{(m)}z^{-m-1},b_{(n)}w^{-n-1}]=[a_{(m)},b_{(n)}]
$$
$$
RHS=\sum_{j}\left(\sum_{k}(a_{(j)}b)_{(k)}w^{-k-1}\right)
\left(\sum_{s}\binom{s}{j}z^{-s-1}w^{s-j}\right)
$$
The coefficient of $z^{-m-1}w^{-n-1}$ of RHS is, $s=m$,
$$
\sum_{j}\binom{m}{j}w^{m-j}(a_{(j)}b)_{(k)}w^{-k-1}
=\sum_{j}\binom{m}{j}(a_{(j)}b)_{(m+n-j)}
$$
So we put this as a proposition:
\begin{proposition}[Commutator formula]
\label{proposition-commutator-formula}
In a vertex algebra $(V,|0\rangle,T,Y)$, we have
$$
[a_{(m)},b_{(n)}]=\sum_{j \geq 0}\binom{m}{j}(a_{(j)}b)_{(m+n-j)}
\qquad \forall a,b \in V,\quad m,n\in \mathbb{Z}
$$
\end{proposition}

\begin{exercise}
\label{exercise-its-what-it-is}
Prove that in a vertex algebra
\begin{equation}
\label{equation-star3}
[Y(a,z)Y(b,w)i_{z,w}-Y(b,w)Y(a,z)i_{w,z}](z-w)^n
=\sum_{j \geq 0}Y(a_{(n+j)}b,w)\partial_w^{(j)}\delta(z,w).
\end{equation}
Hint. Prove that he left hand side is local.
\end{exercise}

By extracting coefficients of Eq. \ref{equation-star3}, we obtain
for all $a,b,c \in V$ and $m,n,k \in \mathbb{Z}$:
\begin{equation}
\label{equation-Borcherds-identity}
\begin{aligned}
&\sum_{j \geq 0}\binom{m}{j}(a_{(n+j)}b)_{(m+k-j)}c\\
&=\sum_{j \geq 0}(-1)^j \binom{n}{j}
\left(a_{(m+n-j)}b_{(k+j)}c-(-1)^nb_{(n+k-j)}a_{(m+j)}c\right)
\end{aligned}
\end{equation}

This is called {\it Borcherd's identity}, and is the key
ingredient in our second definition of vertex algebra
(see \cite[Proposition 4.8(b)]{VAFB}):

\begin{definition}
\label{definition-vertex-algebra2}
A {\it vertex algebra} is a vector space $V$,
a nonzero vector $|0\rangle\in V$,
and a set of bilinear products
$V \times V \to V$, $a,b \mapsto a_{(n)}b$, $n \in \mathbb{Z}$
such that
\begin{enumerate}
\item $\forall a,b \in V$ $\exists N$ such that $a_{(n)}b=0$
$\forall n \geq N$.
\item $\forall  a \in V$, $|0\rangle_{(n)}a=\delta_{n,-1}a$.
\item $\forall a \in V,$ $a_{(-1)}|0\rangle =a$ and $a_{(\geq 0)}|0\rangle=0$.
\item Equation \ref{equation-Borcherds-identity} holds
$\forall a,b,c \in V$, $m,n,k \in \mathbb{Z}$.
\end{enumerate}
\end{definition}

\section{Calculating vertex algebras}
\label{section-calculating-vertex-algebras}


We begin with some notation.

\begin{definition}
\label{definition-lambda-bracket}
Let $V$ be a vertex algebra and
$a,b \in V$.
We package the elements $a_{(0)}b,a_{(1)}b,\ldots$
into a series
$$
[a_{\lambda}b]=\sum_{j \geq 0}a_{(j)}b \frac{\lambda^j}{j!}
$$
called the {\it $\lambda$-bracket} or {\it operator product expansion (OPE)} 
of $a$ and $b$.
\end{definition}

Recall that elements in $V$ correspond to fields $Y(a,z)$ and $Y(b,z)$.
They are local, and the coefficients of their bracket are
$c_j(w)=Y(a_{(j)}b,w)$. So we put that information in the $\lambda$-bracket.

We also denote by $\,:\!ab\!:\,$ the vector correponding to the normally ordered
product $\,:\!Y(a,z)Y(b,z)\!:\,$. Again, by last time's theorem,
$\,:\!ab\!:\,=a_{(-1)}b$.

\begin{example}
\label{example-Heisenberg-is-vertex-algebra-with-definition2}
$V=H=\mathbb{C}[x_1,x_2,\ldots]$, $\mathcal{F}=\{h(z)\}$ where
$h(z)=\sum_{n \in \mathbb{Z}}z^{-n-1}$ (so in this example we are denoting
$h_n \equiv h_{(n)}$), where, as before,
$$
h_n=\begin{cases}
n\frac{\partial }{\partial x_n}\qquad &n>0 \\
x_n\qquad &n<0
\end{cases}
$$
Recall we completed $\mathcal{F}$ to $\overline{\mathcal{F}}$ 
and discovered
$$
\xymatrixrowsep{0.2 em}
\xymatrix{
V\ar[r]^{\simeq}&\overline{\mathcal{F}}\\
a(z)|0\rangle |_{z=0}&a(z)\ar@{|->}[l]^s\\
a \ar@{|->}[r]_Y&Y(a,z)
}
$$
For $I_V \in \overline{\mathcal{F}}$,
where
 \begin{align*}
I_V&=\sum I_{V(n)}z^{-n-1}\\
I_{V(n)}&=\begin{cases}
I_V\qquad &\text{if }n=-1 \\
0\qquad &\text{if }n \neq -1
\end{cases}
\end{align*}
we get $I_V |0\rangle|_{z=0}=|0\rangle$. So,
$$
Y(|0\rangle,z)=I_V
$$
This shows that the vacuum $|0\rangle$ corresponds to the identity.

Next $h(z)$ in our example. We have
\begin{align*}
h(z)|0\rangle&=\sum_{ n \in \mathbb{Z}}h_n 1z^{-n-1}\\
&=\sum_{ k \geq 1}x^kz^{k-1}+\sum_{k \geq 1}k\frac{\partial }{\partial x_k}1\\
\implies h(z)|0\rangle|_{z=0}&=x_1\\
\implies S(h(z))&=x_1\\
\implies Y(x,z)&=h(z).
\end{align*}
So, $x_1$ corresponds to the sort of ``generating field'' $h(z)$.

What about $x_2$? Well, $h(z)=h(z)_{(-1)}I_V$.
There was a lemma (maybe Remark \ref{remark-nth-product}?) that
$$
a(z)_{(-2)}I_V=\partial_za(z).
$$
So $\partial_zh(z) \in \overline{\mathcal{F}}$,
\begin{align*}
a(\partial_zh(z))&=\partial \sum_{k \geq 1}x_kz^{k-1}\Big|_{z=0}\\
&=\sum_{k\geq 1}(k-1)x_kz^{k-2}\Big|_{z=0}\\
&=x_2.
\end{align*}
So
$$
Y(x_{n+1},z)=\partial_z^{(n)}h(z).
$$
Continuing:
$$
Y(x_3,z)=\frac{1}{2}\partial_z^2h(z),
$$
and in general
$$
Y(x_{n+1},z)=\partial_z^{(n)}h(z).
$$
The next question is: what about $x_1^2$? 
The trick here is that $x_1$ is identified with $h$, so
\begin{align*}
Y(x_1^2,z)&=Y(x_1\cdot x_1,z)\\
&=Y(h_{(-1)}x_1,z)\\
&=Y(x_1,z)_{(-1)}Y(x,z)\\
&=\,:\!h(z)h(z)\!:\,.
\end{align*}

Recall that $L(z)=\frac{1}{2} \,:\!h(z)h(z)\!:\,$. We have claimed
(Exercise \ref{exercise-hard})
that $[L_m,L_n]=(m-n)L_{m+n}$ when $m,n,m+n \neq 0$
where
\begin{align*}
L(z)&=\sum_{m \in \mathbb{Z}}L_mz^{-m-2}\\
&=\sum_{n \in \mathbb{Z}}L_{(n)}z^{-n-1}.
\end{align*}

\medskip\noindent
What about the $\lambda$-bracket? Let's denote
$h=x_1$, (so $Y(h,z)=h(z)$, $L=\frac{1}{2}x_1^2$
and $Y(L,z)=L(z)$).

Well, long ago we computed that
\begin{align*}
[h(z),h(w)]&=\partial_w \delta(z,w)I_V\\
&=\sum_{j \geq 0}Y(h_{(j)}h,w)\partial_w^{(j)}\delta(z,w).
\end{align*}
Then
\begin{align*}
Y(h_{(0)}h,w)&=0\\
Y(h_{(1)}h,w)&=I_V\\
Y(h_{\geq 2)}h,w)&=0\\
\implies h_{(1)}h&=|0\rangle, \text{ and }\\
h_{(j)}h=0,\qquad j=0\text{ and }j\geq 2.
\end{align*}
So we see that
$$
[h_\lambda h]=\lambda |0\rangle.
$$

We often omit  ``$|0\rangle$'' from these computations,
as if it were ``1''.

So
$$
[h_\lambda h]=\lambda.
$$
\medskip\noindent
$[h_\lambda |0\rangle]=0=[|0\rangle_\lambda h]$ 
because $[h(z),I_V]=0$.
In fact $[x_\lambda |0\rangle]=[|0\rangle_\lambda x]=0$ for all $x \in V$.

\medskip\noindent
What about $h_{(0)}h$? Well, $h_{(0)}=0$ by definition of $h(z)$.
So $h_{(0)}h=0$. Next, $h_{(j)}=j\frac{\partial }{\partial x_j}$ for
$j>0$, so
$$
h_{(1)}h= \frac{\partial }{\partial x_1}(x_1)=1=|0\rangle.
$$
So $[h_\lambda h]=\lambda$ again.

What I really want is $[L_\lambda L]=$? Let's use
Borcherd's formula \ref{equation-Borcherds-identity}.

First let's compute $(h_{(-1)}h)_{(0)}L$, i.e. we
are putting $n=-1$, $m=0$ and $k=0$.

$$
[\text{missing computations}]
$$
\begin{exercise}
\label{exercise-conta}
Check $(h_{(-1)}h)_{(1)}h=2h$ and
$(h_{(-1)}h)_{\geq 2}h=0$.
Thus $[L_\lambda h]=Th+\lambda h$.
\end{exercise}
If we wanted, we could continue to calculate
$[L_\lambda L]$ by putting $c=\frac{1}{2}x_1^2$ above
instead of $c=x_1$.

We find
$$
[L_\lambda L]=\underbrace{TL}_{L_{(0)}L}
+\underbrace{2\lambda L}_{L_{(1)}L}
+\underbrace{\frac{\lambda^3}{12}|0\rangle}_{L_{(3)}L}.
$$
This means
\begin{equation}
\label{equation-looks-important}
[L(z),L(w)]=(\partial_wL(w))\delta(z,w)
+2L(w)\partial_w\delta(z,w)
+\frac{1}{12}\partial_w^3\delta(z,w)I_V.
\end{equation}
So we can extract coefficients:
$$
LHS=\sum_{m,n}[L_m,L_n]w^{-m-2}z^{-n-2}
$$
Coefficient of $w^{-m-2}z^{-n-2}$ on RHS is:
\begin{align*}
&\sum_{k}(-k-2)L_kw^{-k-3}\sum z^{-a-1}w^a\\
&+2\sum_{k}L_kw^{-k-2}\sum_{a}az^{-a-1}w^{a-1}
+\frac{1}{12}\sum_{a}a(a-1)(a-2)z^{-a-1}w^{a-3}.
\end{align*}
So actually we found
$$
[L_m,L_n]=(m-n)L_{m+n}+\frac{m^3-m}{12}\delta_{m,-n}I_V.
$$
The moral is: one tries to define $L=\frac{1}{2}h^2$ naively,
expecting $[L_m,L_n]=(m-n)L_{m+n}$.
Need to ``normally order/normalise'' to make $L$ 
well-defined, now $L=\frac{1}{2}\,:\!h h\!:\,$.
The ``cost'' is that the expected relation
$[L_m,L_n]=(m-n)L_{m+n}$ gets altered by an 
``anomaly'' $\frac{m^3-m}{12}I_V$.
\end{example}

Right, so we showed how to compute this using Bochner's
formula, but there's actually another way
using $\lambda$-bracket:

\begin{theorem}
\label{theorem-lambda-brackets}
Let $V$ be a vertex algebra, $a,b,c \in V$.
Then
\begin{align}
\label{equation-lambda-brackets}
[Ta_\lambda b]&=-\lambda[a_\lambda b]\\
[a_\lambda Tb]&=(T+\lambda)[a_\lambda b]\\
T(\,:\!ab\!:\,)&=\,:\!(Ta)b\!:\,+\,:\!a(Tb)\!:\,\\
[b_\lambda a]&=-[a_{-\lambda -T}b]\\
[a_\lambda \,:\!bc\!:\,]&=\,:\![a_\lambda b]c\!:\,+\,:\!b[a_\lambda c]\!:\,
+\int_0^\lambda [[a_\lambda b]_\mu c]d\mu\\
[a_\lambda[b_\mu c]]-[b_\mu [a_\lambda c]]&=[[a_\lambda b]_{\lambda+\mu}c].
\end{align}
\end{theorem}

\begin{proof}
For the first one use $\partial_z \delta(z,w)=-\partial_z \delta(z,w)$.

For the last one notice that
\begin{align*}
-[a_{-\lambda - T}b]&=\sum_{j}\frac{1}{j!}(-\lambda-T)^j(a_{(j)}b)
\end{align*}
if $[a_\lambda b] =\sum_{j}\frac{\lambda^j}{j!}b$.
\end{proof}

\begin{remark}
\label{remark-how-to-use}
By noting that $[a_\lambda b]=\text{Res}_ze^{\lambda z}Y(a,z)b$,
these identities can be proved pretty efficiently.
\end{remark}

That is,

\begin{exercise}
\label{exercise-use-the-5th}
Use the fifth equation to prove what we proved with Bochner's formula.
\end{exercise}

And another one:

\begin{exercise}
\label{exercise-}
Let $V=H=\mathbb{C}[x_1,x_2,\ldots]$ again.
Define $B=\frac{1}{2}\,:\!h h\!:\,+\beta Th$ with $\beta \in \mathbb{C}$.
Confirm that 
$$
[B_\lambda B]=TB+2\lambda B=\frac{1}{12}(1-12\beta^2)|0\rangle.
$$
\end{exercise}

\begin{definition}
\label{definition-Virasoro-Lie-algebra}
The {\it Virasoro Lie algebra} is
$$
\text{Vir}=\bigoplus_{n \in \mathbb{Z}}\mathbb{C}L_n \oplus \mathbb{C}C
$$
with Lie bracket
$$
[L_m,L_n]=(m-n)L_{m+n}+\frac{m^3-m}{12}\delta_{m,-n}C,\qquad [C,\text{Vir}]=0.
$$
\end{definition}
By the discussion above (all we've said so far!),
there is a representation $\rho$ of $\text{Vir}$ in $H$ 
given by
$$
\rho(\underbrace{L_n}_{\substack{\text{as an abstract} \\ 
\text{object in Vir}}})
=\underbrace{L_n}_{\substack{\text{as a complicated} \\ \text{operator}}},
\qquad \rho(C)=I_H.
$$
Also $H$ carries a representation $\rho_\beta$ of $\text{Vir}$,
$$
\rho_\beta(L_n)=B_n,\qquad \rho_\beta(C)=(1-12\beta^2)I_V
$$
If $(M,\rho)$ is a representation of $\text{Vir}$, in which 
 $\rho(C)=c\cdot I_M$ for some scalar $c$, we say $M$ has a
{\it central charge} $c$.

Looks like we have a second example of a vertex algebra.
Consider $V=H$, $|0\rangle=1$, $T=T$ from before, but this time put
$F=\{B(z)\}$. Then all the axioms of the first definition of vertex
algebra are satisfied, except the second: 
$B_{(n_1)}B_{(n_2)}\ldots B_{(n_s)}|0\rangle$
might not span all of $V=H$.
So take $V=\text{span}\{\text{these monomials}\}\subset H$.
One can check that $T(V) \subset V$, and
$B(z)$ is a quantum field on $V$.
So $(V,1,T,\{B(z)\})$ is a vertex algebra, called the 
{\it Virasoro vertex algebra}.

\section{The charged free fermions: a vertex superalgebra}
\label{section-charges-free-fermions}

Also known as:
\begin{itemize}
\item The Clifford (vertex) algebra.
\item The Dirac sea.
\item The bc system.
\end{itemize}

First we consider a vector
superspace with basis $\varphi$ and $\varphi^*$
$$
\mathfrak{a}=\mathbb{C}\varphi +\mathbb{C} \varphi^*
$$
(where $\varphi$ and $\varphi^*$ are odd,
so this is a O,2-dimensional superspace).

(A vector superspace is a $\mathbb{Z}/2$-graded vector space,
i.e. a vector space split in two pieces,
$V=V_0\oplus V_1$, which we call even and odd.)

We consider a bilinear form
\begin{align*}
\left<\cdot,\cdot\right>: \mathfrak{a}\times \mathfrak{a}
&\longrightarrow  \mathbb{C}\\
\left<\varphi^*,\varphi\right> &=1\\
\left<\varphi,\varphi^*\right>&=1\text{ (why? see below)}
\end{align*}
Now consider
$$
\tilde{\mathfrak{a}}=\underbrace{t^{1/2}\mathfrak{a}[t,t^{-1}]}_{\text{odd}}
\oplus \underbrace{\mathbb{C}K}_{\text{even}}.
$$
with Lie bracket
\begin{align*}
[at^m,b^n]&=\delta_{m,-n}\left<a,b\right>K,\\
[K,\tilde{\mathfrak{a}}]&=0.
\end{align*}
(Notice the small difference from the
Heisenberg case: there is no $m$ before the  $\delta$!)

To see why $\left<\varphi,\varphi^*\right>=1$,
notice that in a Lie superalgebra we always want
$[x,y]=(-1)(-1)^{p(x)p(y)}[y,x]$ 
where $p$ denotes the parity.
Since both  $at^m$ and $bt^n$ are odd,
we have $[at^m,bt^n]=[bt^n,at^m]$.
Then apply the definition of bracket.

Since $a,b$ odd here,
we say $\left<a,b\right>=\left<b,a\right>$ means
$\left<\cdot,\cdot\right>$ is skew-super symmetric.

\begin{definition}
\label{definition-supersymmetric}
A bilinear form
$$
(\cdot,\cdot):U \times U \to \mathbb{C}
$$
is
{\it supersymmetric} if  $(b,a)=(-1)^{p(a)p(b)}(a,b)$,
and {\it skew-supersymmetric} if
 $(b,a)=-(-1)^{p(a)p(b)}(a,b)$.
\end{definition}

\begin{exercise}
\label{exercise-Lie-superalgebra}
Invent the definition of Lie superalgebra,
and confirm that if $U=U_0 \oplus U_1$ 
is a vector superspace,
$\text{End}(U)$ is a Lie superalgebra
with $[X,Y]:=XY-(-1)^{p(X)p(Y)}YX$.
\end{exercise}

\medskip\noindent
Let's build a Fock-type representation of $\tilde{\mathfrak{a}}$.

Construction 1.
$$
\tilde{\mathfrak{a}_+}=
\bigoplus_{n>0}t^n\mathfrak{a}\oplus\mathbb{C}K,
\qquad (n \in \frac{1}{2}+\mathbb{Z},\text{ recall})
$$
$\tilde{\mathfrak{a}_+}\subset \tilde{\mathfrak{a}}$ is
a superalgebra.

Consider $U(\tilde{\mathfrak{a}})$
and $U(\tilde{\mathfrak{a}})\subset U(\tilde{\mathfrak{a}})$.

Recall that the PWB theorem says
that $U(\mathfrak{g})$ ``looks like''
polynomials on $\mathfrak{g}$.

When $\mathfrak{g}$ is pure even,
this says:
take $\{a_1,a_1,\ldots\}$ a basis of $\mathfrak{g}$,
then
$$
\{a_{i_1}^{m_1},a_{i_2}^{m_2}\ldots a_{i_s}^{m_s}:
i_1\leq i_2\leq \ldots\leq i_s,m_j \geq 1\}.
$$
For $\mathfrak{g}=\mathfrak{g}_0 \oplus \mathfrak{g}_1$
super Lie algebra,
the statement is similar,
only now, we take each $a^i$ homogeneous
($\in \mathfrak{g}_0$ or $\mathfrak{g}_1$):
$$
\{a_{i_1}^{m_1}a_{i_2}^{m_2}\ldots a_{i_s}^{m_s},
i_1\leq i_2 \leq \ldots \leq i_s, m_j\geq 1,
\text{ if }a_{i_j}\text{ odd, }m_j=1\}.
$$
The point is that if we put an odd guy
twice it becomes one.

Why? Because in $U(\mathfrak{g})$, $X \in \mathfrak{g}_1$ should
satisfy $X X + X X=[X,X]=0$.
So  $X^2=0$. So we only allow
odd basis vectors to appear 0 or 1 times each.

\medskip\noindent
Dfine $F=U(\tilde{\mathfrak{a}})\otimes_{U(\tilde{\mathfrak{a}}_+)}
\mathbb{C}|0\rangle$,
where $at^n\cdot|0\rangle$ for all $n>\frac{1}{2}$, and
$K|0\rangle=|0\rangle$.

[Picture of $F$]

We can introduce a bi-grading of $F$:
$$
F=\bigoplus_{\substack{c \in \mathbb{Z} \\ \Delta \in \frac{1}{2}\mathbb{Z}_+}}
F_\Delta^c
$$
where, for a monomial
$$
\varphi^*_{-n}\varphi^*_{-n_2}\ldots \varphi_{-n_s}^*
\varphi_{-m},\varphi_{-m_2}\ldots \varphi_{-m_t}|0\rangle
$$
we define its {\it energy} by
$\Delta=\sum_in_i+\sum_jm_j$ 
and its {\it charge} by $c=s-t$.

The point is that $F$ is an infinite-dimensional
vector space, but we get a reasonable mental
picture of what it looks like.

What is $\dim F_\Delta^c$? Let's write…

\medskip\noindent
So we have a vector superspace $F$,
and an action on $F$ of $\tilde{\mathfrak{a}}$.
Let's build some quantum fields!

There are going to be two: $\varphi(z)$ 
and $\varphi^*(z)$.
$$
\varphi(z)=\sum_{n \in \frac{1}{2}+\mathbb{Z}}\varphi_nz^{-n-\frac{1}{2}}
$$
(Notice the exponent on $z$ is an integer!)
$$
\varphi^* (z)=\sum_{n \in \frac{1}{2}+\mathbb{Z}}
\varphi^*_n z^{-n-\frac{1}{2}}.
$$
Now let's compute $[\varphi^*(z),\varphi(w)]$.

\begin{align*}
[\varphi^*(z),\varphi(w)]&=\sum_{m,n \in \frac{1}{2}+\mathbb{Z}}
[\varphi^*_m,\varphi_n]z^{-m-\frac{1}{2}}w^{-n-\frac{1}{2}}\\
&=\sum_{n \in \frac{1}{2}+\mathbb{Z}}Kz^{n-\frac{1}{2}}w^{-n-\frac{1}{2}}\\
&=\sum_{\substack{r \in \mathbb{Z} \\ r=n-\frac{1}{2}}}z^rw^{-r-1}\\
&=\delta(z,w).
\end{align*}
So $F,|0\rangle,\mathcal{F}=\{\varphi(z),\varphi^*(z)\}$,
$T:F\to F$, is a vertex superalgebra.
Here $T:F \to F$ has to satisfy
$T|0\rangle=0$ and $[T,\varphi(z)]=\partial_z\varphi(z)$,
\begin{align*}
\sum [T,\varphi_n]z^{-n-\frac{1}{2}}&=
\sum (-n-\frac{1}{2})\varphi_n z^{-n-\frac{3}{2}}\\
&=\sum (-k+\frac{1}{2})\varphi_{k-1}z^{-k-\frac{1}{2}}
\end{align*}
after putting $n=k-1$. So
$$
[T,\varphi_n]=-(n-\frac{1}{2})\varphi_{n-1}.
$$
Inductively, this determines
how $T$ acts on $F$.

\medskip\noindent
In $\lambda$-bracket notation, this just says
$$
[\varphi^* _\lambda\varphi]=|0\rangle.
$$
Skew-symmetry says $[b_\lambda a]=-(-1)^{p(a)p(b)}[a_{-\lambda -T}b]$.

For example,
\begin{align*}
[h_\lambda h]&=\lambda |0\rangle,\\
[h_\lambda h]&=-[h_{-\lambda-T}h]=-(-\lambda-T)|0\rangle\\
&=T\lambda |0\rangle.
\end{align*}
In this case $[\varphi_\lambda \varphi^* ]=+|0\rangle$ too.

Notice $\sum \varphi_n z^{-n-\frac{1}{2}}=
\sum \varphi_{(m)}z^{-m-1}$.

So
\begin{align*}
\varphi_{(m)}&=\varphi_{m-\frac{1}{2}}\text{ and}\\
\varphi^*_{(m)}&=\varphi_{m-\frac{1}{2}}.
\end{align*}
So
\begin{align*}
\,:\!\varphi^*\varphi\!:\,&=\varphi_{(-1)}^*\varphi_{(-1)}|0\rangle\\
&=\varphi_{-\frac{1}{2}}^*\varphi_{-\frac{1}{2}}|0\rangle.
\end{align*}
I.e.
$$
\varphi=\varphi_{(-1)}|0\rangle=\varphi_{-\frac{1}{2}}|0\rangle
$$
Now we can put the former picture but with the
associated operators using the
second definition of vertex algebra: [Picture]

Let's compute some brackets: [lots of computations]

So,
$$
[\alpha_\lambda \alpha]=\lambda |0\rangle.
$$
Just like $[h_\lambda h]=\lambda |0\rangle$.
This relation is the basis of the 
``boson-fermion correspondence'', i.e.
consider the subspace $U \subset F$ defined as
 $$
U=\text{span}\{\alpha_{n_1}\alpha_{n_2},\ldots,\alpha_{n_s}|0\rangle
:n_{i} \in \mathbb{Z}\}.
$$

We claim that since $[T,\alpha(z)]=\partial_z \alpha(z)$,
$[T,\alpha_n]=-n\alpha_{n-1}$.

So $T(U) \subset U$. Put $\mathcal{F}_1=\{\alpha(z)\}$.
Then $(U,|0\rangle,T|_{U},\{\alpha(z)\})$ is a vertex algebra
(an honest one, not super).

\begin{proposition}
\label{proposition-isomorphic-to-Heisenberg}
$U$ is isomorphic to the Heisenberg
vertex algebra. (In particular,
$U \simeq \mathbb{C}[x_1,x_2,\ldots]$
as a vector space.)
\end{proposition}

\begin{proof}
Next time.
\end{proof}

Since $[\alpha_0,\varphi_n]=-\varphi_n$,
$[\alpha_0,\varphi_m^*]=\varphi_m^*$,
and $\alpha_0 |0\rangle=0$, in fact the
charge of a monomial is exactly the
eigenvalue of $\alpha_0$ acting on it.

\begin{align*}
\alpha_0\cdot\varphi^*_{-m}\varphi^*_{-m_2}\varphi_{-n}|0\rangle
&=[\alpha_0,\varphi^*_{-m},\varphi^*_{-m_2},\varphi_{-n}]|0\rangle\\
&=\underbrace{(+1+1-1)}_{\text{charge}}
\varphi_{-m_1}^*\varphi_{-m_2}\varphi_{-n}|0\rangle.
\end{align*}
From $[\alpha_\lambda \alpha]=\lambda |0\rangle$,
we get
$$
[\alpha_m,\alpha_n]=m\delta_{m,-n}I_F\text{ (as for $h$)}
$$
So $[\alpha_0,\alpha_n]=0$ for all $n \in \mathbb{Z}$.
Thus  $\alpha_0 |_{ U}=0$ and thus $U \subset F^{(0)}$.

\begin{proposition}
\label{proposition-U-is-F0}
$U=F^{(0)}$.
\end{proposition}

\begin{proof}
Next time.
\end{proof}

\medskip\noindent
Let's take two copies of $F$,
i.e. $F_2=F \otimes F$ 
with fields $\varphi^1(z),\varphi^2(z),\varphi^{1*}(z),\varphi^{2*}(z)$
$$
[\varphi^{i*}_{\lambda}\varphi^j]=\delta_{ij}.
$$
Basis of $F_2$ is
$$
\varphi_{-n_1}^1\ldots \varphi_{-n_2}^1\varphi_{-m_1}^2\ldots
\varphi_{-m_t}^2\varphi^{*-1}_{-p_1}\ldots
\varphi_{-p_u}^{*-1}\varphi_{-q_1}^{*2}\ldots\varphi_{-q_v}^{*2}|0\rangle.
$$
Let $\alpha^{ij}=\,:\!\varphi^{j*}\varphi^i\!:\,$.
$$
[\alpha^{ij}_\lambda \alpha^{k\ell}]=?
$$
(certainly $[\alpha^{ii}_\lambda \alpha^{ii}]=\lambda |0\rangle$.)
In general
$$
[\varphi^k_\lambda \alpha^{ij}]=\text{computation}=\delta_{ki}\varphi^j.
$$
Similarly
$$
[\varphi^{k*}_\lambda \alpha^{ij}=-\delta_{kj}\varphi^{i*}.
$$
\begin{align*}
[\alpha^{ij}_\lambda \varphi^k]&=-\delta_{ik}\varphi^j\\
[\alpha^{ij}_\lambda \varphi^{k*}]&=+\delta_{j k}\varphi^{i*}.
\end{align*}

We would like to consider
$$
F_n=F^{\otimes n}=F \otimes \ldots \otimes F
$$
where on the $i$-th factor we have $\varphi_i,\varphi^*_i$.

Then we have relations among the generators:
$$
[\varphi^i_\lambda \varphi_j^* ]=[\varphi^* _j\lambda\varphi_i]
=\delta_{ij}|0\rangle
$$
Today let's define
$$
\alpha_{ij}=\,:\!\varphi_i \varphi^*_j\!:\,
$$
We notice that
\begin{itemize}
\item the $\varphi_i$ behave like $e_i$,
\item the $\alpha_{ij}$ behave like $E_{ij}$,
\item the $\varphi_i^*$ behave like $e_i^*$.
\end{itemize}

$$
\text{[Computations of some $\lambda$-brackets]}
$$

Recall, the $E_{ij}$ span a Lie algebra: $\mathfrak{gl}_n$.
It has a representation on $\mathbb{C}^n=\left<e_1,\ldots,e_n\right>$ 
by $E_{ij}e_k=\delta_{ik}e_i$,
and on $(\mathbb{C}^n)^*$ we have
$$
[\text{computations}]
$$
$$
E_{ij}e_k^* =-\delta_{ki}e_j^*.
$$
Let $A \in \mathfrak{gl}_n$. Let's write
$$
\alpha^A=\sum_{i,j}a_{ij}\alpha_{ij}\in F_n
$$
We'd like to compute $[\alpha^A_\lambda \alpha^B]$.

Some computations done in lecture are the proof of

\begin{theorem}
\label{theorem-alpha-is-like-matrices}
For $\alpha_{ij}=\,:\!\varphi_i \varphi_j^*\!:\, \in F_n$,
and $\alpha^A$ as above,
$$
[\alpha^A_\lambda\alpha^B]=\alpha^{[A,B]}
+\lambda\text{Tr}(AB)|0\rangle.
$$
\end{theorem}

Which says that $\alpha^A$ behaves like matrices,
but with that correction term.

\medskip\noindent
Nex, let $\mathfrak{g}\subset \mathfrak{gl}_n$ 
be a Lie subalgebra.
For $A,B \in \mathfrak{g}$, $[A,B] \in \mathfrak{g}$ 
also, and so the set
$$
\mathcal{F}=\{\alpha^A:A \in \mathfrak{g} \cup \{|0\rangle\}\}
$$
is ``closed under $\lambda$-brackets''.

More precisely, for
$$
F_n \supset V=\text{span}\{\alpha^{A_1}_{(n_1)}\ldots\alpha^{A_s}_{(n_s)}:
n_i \in \mathbb{Z}, A_i \in \mathfrak{g}\},
$$
with $|0\rangle=|0\rangle$, $T=T$ and
$\mathcal{F}=\{\alpha^A(z):A \in \mathfrak{g}\}\cup \{I\}$ 
is a vertex algebra.

\section{Universal affine vertex algebra}
\label{section-universal-affine-vertex-algebra}

Recall the construction of the affine vertex algebra,
Definition \ref{definition-affine-Lie-algebra}.

Let $(M,\rho)$ be a representation of $\hat{\mathfrak{g}}$.

For $a \in \mathfrak{g}$, define
\begin{equation}
\label{equation-quantum-fields-for-universal-vertex-algebra}
a^M(z)=\sum_{n \in \mathbb{Z}}\rho(at^n)z^{-n-1}
\in\text{End}(M)[\![z^{\pm 1}]\!].
\end{equation}
\begin{definition}
\label{definition-smooth-g-module}
A {\it smooth $\hat{\mathfrak{g}}$-module}
is a $\hat{\mathfrak{g}}$-module $(M,\rho)$ 
such that for each $m \in M$ there is $N \in \mathbb{Z}$ 
such that $\rho(at^n)m=0$ for all
$a \in \mathfrak{g}$ and $n \geq N$.
\end{definition}

Notice that on a smooth module $M$,
the fields $a^M(z)$ are quantum fields.

We may calculate:
\begin{align*}
[a^m(z),b^m(w)]&=\sum_{m,n}[\rho(at^m),\rho(bt^n)]z^{-m-1}w^{-n-1}\\
&=\sum_{m,n}z^{-m-1}w^{-n-1}
([a,b]t^{m+n}+m\delta_{m,-n}(a,b)\rho(K))\\
&=\sum_{m,n}([a,b]t^{m+n}w^{-(m+n)-1})z^{-m-1}w^m
+\sum_{m,n}z^{-m-1}w^{-n-1}\delta_{m,-n}(a,b)\rho(K)\\
&=[a,b]^m(w)\delta(z,w)
+(a,b)\partial_w\delta(z,w)\rho(K).
\end{align*}

\noindent
Now suppose the $K$ acts by some constant, i.e.
$\rho(K)=k I_M$.
Then our quantum fields $a^M(z)$ are
mutually local, with exponent 2, i.e.
$(z-w)^2[a^M(z),b^M(w)]=0$.

\medskip\noindent
As a special case, we may take
$M$ to be a sort of ``Fock space'':
$$
\hat{\mathfrak{g}}_+=\mathfrak{g}[t]\oplus \mathbb{C}K\subset
\hat{\mathfrak{g}}.
$$
Let $\hat{\mathfrak{g}}_+$ 
act on $\mathbb{C} |0\rangle$ by
\begin{align*}
at^m |0\rangle&=0 \qquad \forall m \geq 0,\\
K\cdot |0\rangle&=k |0\rangle\qquad  (\text{$k \in \mathbb{C}$ called {\it level}}).
\end{align*}
Consider
$$
V^k(\mathfrak{g})=U(\hat{\mathfrak{g}}) \otimes_{U(\hat{\mathfrak{g}}_+)}
\mathbb{C}|0\rangle.
$$

\begin{remark}
\label{remark-Heisenberg-is-a-special-case-of-smooth-construction}
$H=\mathbb{C}[x_1,x_2,\ldots]$ is an example of this construction with
$\mathfrak{g}$ one-dimensional and $(h,h)=1$.
\end{remark}

\begin{exercise}
\label{exercise-Vk-is-smooth}
$V^k(\mathfrak{g})$ is a smooth  $\hat{\mathfrak{g}}$-module,
in which $K \mapsto  k \text{Id}$.
\end{exercise}

\begin{proof}
To prove  $V^k(\mathfrak{g})$ is smooth
we need to show that for every
formal power series of endomorphisms of
$V^k(\mathfrak{g})$ of the form Equation
\ref{equation-quantum-fields-for-universal-vertex-algebra},
the coefficient operators vanish at every $v$ for sufficiently
large $n$. But to define these
power series we need to find a copy
of  $\hat{\mathfrak{g}}$ inside $V^k(\mathfrak{g})$.
\end{proof}

The set $\mathcal{F}=\left\{a(z)=\sum_{n \in \mathbb{Z}}
(at)^nz^{-n-1}:a \in \mathfrak{g}\right\}$ 
are mutually local quantum fields.

Define $T:V^k(\mathfrak{g})\mathbb{y} V^k(\mathfrak{g})$ 
by the relation $T |0\rangle=0$ 
and $[T,at^m]=-mat^{m-1}$.
$V^k(\mathfrak{g})$ is a vertex algebra
called the {\it universal affine vertex algebra} 
of level $k$ associated with $\mathfrak{g}$.

[Picture of $V^k(\mathfrak{g})$ for $\mathfrak{g}=\mathfrak{sl}_2$.]

We have a bigrading, vertical grading $\Delta$ (energy) is
$$
\Delta(a^1_{(-n_1)}a^2_{(-n_2)}\ldots a^s_{(-n_s)}|0\rangle
=n_1+n_2+\ldots+n_s.
$$

Notice that for $a \in \mathfrak{g}$, we have
\begin{align*}
\mathcal{F}\ni a(z)&\overset{s}{\mapsto }
a(z)|0\rangle |_{z=0}\\
&=\sum_{m}at^m |0\rangle z^{-m-1}\Big|_{z=0}\\
&=(at^{-1})|0\rangle+(at^{-2})z|0\rangle+\ldots\\
&=at^{-1} |0\rangle.
\end{align*}
Thus we can think of
$\{a t^{-1} |0\rangle:a \in \mathfrak{g}\}\subset V^k(\mathfrak{g})$ 
as a ``copy'' of $\mathfrak{g}$ inside $V^k(\mathfrak{g})$.
Let's {\bf abuse notation} and write $a$ for $at^{-1}|0\rangle$.

Then $at^{-2}|0\rangle=Ta$, also
$(at^{-1})(bt^{-1})|0\rangle=\,:\!ab\!:\,$, etc.
$e=et^{-1}|0\rangle=e_{(-1)}|0\rangle$, $\Delta(e)=1$.

In fact $\Delta(a)=1$ for all $a \in \mathfrak{g}$,
$\Delta(Ta)=2$,
$\Delta(\,:\!ab\!:\,)=2$, etc.

In this example, i.e. $\mathfrak{g}=\mathfrak{sl}_2$,
$\mathfrak{sl}_2$ is itself a $\mathbb{Z}$-graded Lie algebra,
\begin{align*}
\begin{aligned}
w(E)&=2\\
W(H)&=0\\
w(F)&=-2
\end{aligned}
\qquad 
\begin{aligned}
[H,E]&=2E\\
[H,H]&=0\\
[H,F]&=-2F.
\end{aligned}
\end{align*}

(That is, $\mathfrak{g}=\bigoplus_{n \in \mathbb{Z}}\mathfrak{g}_n$,
$[\mathfrak{g}_m,\mathfrak{g}_n]=\mathfrak{g}_{m+n}$.)
$w=$ eigenvalue of $\text{ad}(H)$.
This induces a $\mathbb{Z}$-grading on $V^k(\mathfrak{sl}_2)$,
compatible, i.e.
$$
w(a^1_{(-n_1)}\ldots a^s_{(-n_s)}|0\rangle=
2\#(E)-2\#(F).
$$

\medskip\noindent
As for the character,
\begin{align*}
\chi(q,u)&=\sum_{\Delta,w}\dim V^k(\mathfrak{g})_\Delta^w q^\Delta u^w\\
&=1+q(u^2+1+u^{-2})
+q^2(u^4+2u^2+2+2u^{-2}+u^{-4}+\ldots
\end{align*}
Then by the generating function argument we have discussed
before,
$$
\chi(q,u)=\prod_{n=1}^\infty \frac{1}
{(1-u^2q^n)(1-q^n)(1-u^{-2}q^n)}.
$$
Can discard $u$ to get vertical grading
$$
\chi(q)=\prod_{n=1}^\infty \frac{1}{(1-q^n)^3}.
$$

\medskip\noindent
[Missing: we changed a little the definition of $V^k(M)$;
now it also depends on a bilinear form $B$.]

Here's another example:

\begin{example}
\label{example-fermions-are-universal-vertex-algebra}
$\mathfrak{g}=\mathfrak{gl}_n$, with $B(X,Y)=\text{Tr}(XY)$,
and $k=1$.
\end{example}

\begin{remark}
\label{remark-rescaling-the-Killing-form-and-Coxeter-number}
In general $V^1(\mathfrak{g},kB)=V^k(\mathfrak{g},B)$.
If $\mathfrak{g}$ is finite-dimensional simple, we 
typically take $B(a,b)=\frac{1}{2 h^\vee}\kappa(a,b)$ 
where $\kappa$ is the Killing form. (This $B$ 
has the property that $B(\theta,\theta)=2$
for {\bf long} roots $\theta \in \Delta \subset \mathfrak{h}^*$.)
(In fact, in a simple f.d. there's
all invariant forms are proportional.)
Then we write this vertex algebra
as $V^k(\mathfrak{g})$ without specifying $B$.
\end{remark}

So perhaps that's why last time we didn't put $B$.

\medskip\noindent
Back to the Fermion algebra $F_n$, and now
denoting $J$ instead of $\alpha$,
we built fields
$\{J^A:A \in \mathfrak{gl}_n\}$ with $\lambda$-bracket
$[J^A_\lambda J^B]=J^{[A,B]}+\lambda\text{Tr}(AB)|0\rangle$.
This suggests a relation with $V^1(\mathfrak{gl}_n,B)$,
where $B(X,Y)=\text{Tr}(X,Y)$.

Consider $\mathcal{F}=\{J^A(z):A \in \mathfrak{gl}_n\}\subset \mathbb{F}_{F_n}
\cong F_n$.
Let $V=\text{span}\{J^{A_1}_{(n_1)}\ldots J^{A_s}_{(n_s)}|0\rangle:
A_i \in \mathfrak{gl}_n,n_i \in \mathbb{Z}\}\subset F_n$.

Then $(V,\mathcal{F},T|_{V},|0\rangle)$ is a vertex algebra.
$V \subset F_n$. Notice that $V \neq F^n$
since $V$ consists only of even fields,
indeed, $V=\left<\,:\!\varphi_i \varphi_j^*\!:\,\right>$.

Here $[T,\varphi_{(n)}]=-n\varphi_{(n-1)}$.
$$
T(\varphi^{i_1}_{(n_1)}\ldots\varphi^{i_s}_{(n_s)}|0\rangle)
=-\sum_{j=1}^s n_j\varphi_{(n_1)}^{i_1}
\ldots vo_{(n_j-1)}^{i_j}\ldots
\varphi_{(n_s)}^{i_s}|0\rangle.
$$
Does $V=F^{(0)}_n$ then?

Let's examine $n=1$ first. $\mathfrak{g}=\mathbb{C}1$,
$B(1,1)=1$, $k=1$. We just remarked
that $V^1(\mathfrak{g},B)=H$ is 
Heisenberg. And $F_1=F=\left<\varphi,\varphi^*\right>$ 
which we have drawn previously.
We also computed
the character as an infinite product.

\medskip\noindent
We have $F^{(0)} \ni J = \,:\!\varphi \varphi^*\!:\,$ 
with $\lambda$-bracket relation $[J_\lambda J]=\lambda |0\rangle$.
Recall $J(z)=\sum_{n \in \mathbb{Z}}J_{(n)}z^{-n-1}=
\sum_{n \in \mathbb{Z}}J_n z^{-n-1}$.
The $\lambda$-bracket relation implies
\begin{align*}
[J(z),J(w)]&=\partial_w \delta(z,w)I\\
\implies [J_m,J_n]&=m \delta_{m,-n}I.
\end{align*}
This implies that $F^{(0)}$ is a representation
of the oscillator Lie algebra
$\hat{\mathfrak{a}}=\bigoplus_{m \in \mathbb{Z}}\mathbb{C} h_n \oplus
\mathbb{C}K$,
in which $h_m \mapsto  J_m$, $k \mapsto  I$ and $h_m |0\rangle$ 
for all $m \geq 0$.

\begin{proposition}
\label{proposition-F0-isomorphic-to-polynomial-representations}
As representations of $\mathfrak{a}$,
$F^{(0)}\simeq H=\mathbb{C}[x_1,x_2,\ldots]$.
\end{proposition}

\begin{proof}
Using $H \simeq
U(\hat{\mathfrak{a}})\otimes_{U(\hat{\mathfrak{a}_+})}\mathbb{C}1$,
by its universal property, there exists a morphism of
 $\hat{\mathfrak{a}}$-representations
$f: H \to F^{(0)}$, such that $f(1)=|0\rangle$.

By Exercise \ref{exercise-H-is-irreducible}
we know $H$ is irreducible, so
$f:H \to F^{(0)}$ is injective.
Is it an isomorphism?
Consider  $\tilde{F}=F^{(0)}/f(H)$.
We want to prove $\tilde{F}=\{0\}$.
The trick is to consider  $L=\frac{1}{2}\,:\!J J\!:\,$.

We have seen that 
$$
F^{(m)}=\{v \in F: J_0v=mv\}
$$
(since $[J_\lambda \varphi]=-\varphi$ and
$[J_\lambda \varphi^*]=+\varphi^*$,
$[J_0,\varphi_n]=-\varphi_n$).

Write $L(z)=\sum_{n \in \mathbb{Z}}L_nz^{-n-2}$,
then $L_0=\frac{1}{2}J_0^2+\sum_{m>0}J_{-m}J_m$.
This implies (for example) that $L_0|0\rangle=0$.

One may compute
\begin{align*}
[L_\lambda \varphi]&=T\varphi+\frac{1}{2}\lambda\varphi\\
[L_\lambda\varphi^* ]&=T\varphi^* +\frac{1}{2}\lambda \varphi^*.
\end{align*}

\noindent
If you expand these in terms of coefficients,
you find
$[L_0,\varphi_n]=-n\varphi_n$,
$[L_0,\varphi_n^*]=-n\varphi_n^*$.

From these relations we conclude that
$\Delta(\text{monomial})=L_0$-eigenvalue
(monomial), i.e.,
the (charge, energy)-grading is the
eigenspace grading by $(J_0,L_0)$.
Suppose $\tilde{F}\neq 0$.
Then $\exists \overline{v} \in \tilde{F}$ for which
$J_m \overline{v}=0$ for all $m>0$.
Indeed, by Lemma (?) the  $\mathbb{Z}_+$-grading
of $F^{(0)}$ is inherited by $\tilde{F}$.
Since $|0\rangle \in f(H)$,
$\tilde{F}=\bigoplus_{\Delta \geq  N}\tilde{F}_{\Delta}$ 
for some $N>0$. Let $\overline{v} \in \tilde{F}_N$,
$\overline{v}\neq 0$.
For $m>0$, $J_m \overline{v} \in \tilde{F}_{N-m}=0$.

Key point: $J_0 \overline{v}$, because
$\tilde{F}$ is quotient of $F^{(0)}$.
Hence $L_0\overline{v}=0$.
But $L_0=\Delta$, and we know the only element of $F^{(0)}$ 
with $\Delta=0$ is $|0\rangle$.
This contradiction implies $\tilde{F}=0$,
hence $F^{(0)}=f(H) \simeq H$.
\end{proof}

In the process we saw that
$\Delta$ coincides with $L_0$,
where $L=\frac{1}{2}\,:\!J J\!:\,$,
and $J=f(h)$. So consider
$L=\frac{1}{2}\,:\!h h_i\!:\,$.

We have $[L_\lambda h]=Th+\lambda h$
so $[L_0,h_n]=-nh_n$ in particular,
and 
\begin{align*}
L_0(h_{-n_1},h_{-n_2},\ldots,h_{-n_s}|0\rangle&=
L_0(x_{n_1}x_{n_2}\ldots x_{n_s}|0\rangle)
&=\left(\sum_{j}n_j x_{n_1}\ldots x_{n_s}|0\rangle\right)
\end{align*}

\noindent
Using this we obtain
 $$
\chi_{F^{(0)}}(q)=\sum_{\Delta}\dim(F^{(0)}_{\Delta})q^{\Delta}
=\prod_{m=1}^{\infty}\frac{1}{1-q^m}.
$$

In $F^{(m)}$, let us denote

$$
|m\rangle=\begin{cases}
\varphi_{-1/2}\varphi_{-3/2}\varphi_{-5/2}\ldots
\varphi_{-\frac{2(-m)-1}{2}}|\rangle\qquad &\text{if }m<0 \\
\varphi^*_{-1/2}\varphi^*_{3/2}\ldots
\varphi^*_{-\frac{2m-1}{2}}\qquad &\text{if }m>0
\end{cases}
$$

We observe that 
$\Delta(|m\rangle)=\frac{m^2}{2}$ 
and $F^{(m)}_{m^2/2}=\mathbb{C} |m\rangle$.

\begin{proposition}
\label{proposition-isomorphic-representations-for-all-m}
As an $\hat{\mathfrak{a}}$-module,
$F^{(m)}\simeq H^m$, and is irreducible.
\end{proposition}

\begin{proof}
Same as above.
\end{proof}

This gives a formula
$$
\chi_{F^{(m)}}(q)=\sum_{\Delta}\dim F^{(m)}_\Delta q^\Delta
=q^{m/2}\prod_{k=1}^\infty \frac{1}{1-q^k}.
$$
As a corollary, we obtain again
Jacobi's triple product formula. (Again!)

$$
\prod_{m=1}^\infty(1+yq^{m-1/2})(1+y^{-1}q^{m-1/2})
=\prod_{k=1}^\infty\frac{1}{1-q^k}
\left(\sum_{n \in \mathbb{Z}}y^nq^{n^2/2}\right).
$$

\section{Another presentation the charged free Fermions}
\label{section-another-presentation-of-fermions}

The idea is to consider $X = \bigoplus_{i \in \mathbb{Z}} \mathbb{C} e_i$,
a countably infinite dimensional space,
and define
\begin{equation}
\label{equation-semi-inifinite}
\Lambda^{\infty/2}=
\left\{\substack{\text{span of symbols of the form} \\ 
e_{i_0}\wedge e_{i_1}\wedge e_{i_1} \wedge e_{i_3}\wedge\ldots\\
\text{where }\exists N\text{ s.t. }\forall n \geq  N,
i_{n+1}=i_n+1}\right\}\Big/
\substack{\text{relation that} \\ e_i\wedge e_j=- e_j \wedge e_i\\
\text{``wherever it occurs''}}.
\end{equation}
That is, the indices can dance around as they like 
but at some point they will become
consecutive.
Clearly a basis of $\Lambda^{\infty/2}$ is given 
by those ``semi-infinite monomials''
for which 
$i_0 < i_1< i_2<\ldots$.

For any semi infinite monomial
$\underline{e}=e_{i_0}\wedge e_{i_1}\wedge \ldots$
there exists a number $m$ such that
$i_j=-m+j$ for all  $j \gg 0$.
This number is called the {\it charge} of $\underline{e}$.

We have a decomposition in vector spaces
$$
\Lambda^{\infty/2}=\bigoplus_{m \in \mathbb{Z}}\Lambda^{\infty/2,(m)}
$$
called {\it charge decomposition}.

Let's introduce some operators in  $\Lambda^{\infty/2}$:
\begin{align*}
\varphi_{(n)}: \Lambda^{\infty/2} &\longrightarrow \Lambda^{\infty/2} \\
\varphi_{(n)}(\underline{e}) &= e_n \wedge \underline{e} 
\end{align*}
i.e. we just put $e_n$ at the beginning of the 
monomial.

Next
\begin{align*}
\varphi_{(n)}^*: \Lambda^{\infty/2} &\longrightarrow \Lambda^{\infty/2} \\
\varphi^*_{(n)} & =\sum_{k \geq 0}(-1)^k \delta_{n,i_k}
e_{i_0}\wedge e_{i_1}\wedge \ldots \wedge
\underbrace{\widehat{e_{i_k}}}_{\text{remove this}}\wedge \ldots
\end{align*}
so in analogy, we remove this term.
The $(-1)^k$ accounts for moving around the unwanted
term to the beginning of the monomial.

\begin{exercise}
\label{exercise-something-like}
Something like
$$
\varphi_{(m)}\varphi^*_{(n)}
+\varphi_{(n)}^*\varphi_{(m)}=
\delta_{m,+n}I_{\Lambda^{\infty/2}}
$$
\end{exercise}

Let's introduce some quantum fields now:

$$
\varphi(w)=\sum_{ n \in \mathbb{Z}}\varphi_{(n)}w^{-n-1}
$$
which vanishes for very large $n$ because
we eventually get to the ``consecutive'' region,
and
$$
\varphi^*(w)=\sum_{ n \in \mathbb{Z}}\varphi^*_{(n)}w^{n}
$$
which vanishes for very negative $n$ since the
star operators are defined to give zero
if the $e_n$ is not found in the monomial.

Notice that the convention  $\varphi^*(w)=\sum \varphi^*_{(n)}w^n$,
instead of $\sum \varphi^*_{(n)}w^{-n}$ is so that
$\varphi^*(w)$ is a quantum field
(indeed, by our convention on how we write quantum fields,
see Definition \ref{definition-quantum-field}).
The convention $\varphi^*(w)=\sum \varphi^*_{(n)}w^n$ 
instead of, say, $\sum \varphi_{(n)}^* w^{n+1}$
is so that the equation in 
Exercise \ref{exercise-something-like}
turns into a nice relation
$$
[\varphi(z),\varphi^*(z)]=\delta(z,w)I,
$$
(i.e. $[\varphi_\lambda \varphi^* ]=|0\rangle$, just like in the
charged fermions $F^{\text{ch}}$!).

\begin{exercise}
\label{exercise-relations-for-these-fields}
These fields will match with our previous
$\varphi,\varphi^*$ as
\begin{align*}
\sum \varphi_{(n)}z^{-n-1}&=\sum \varphi_n z^{-n-1/2} 
: \varphi_n=\varphi_{n-1/2}\\
\sum \varphi_{(n)}^*z^n&=\sum \varphi_n^* z^{-n-1/2}
: \varphi_n^*=\varphi_i
\end{align*}
\end{exercise}

\medskip\noindent
The space $\Lambda^{\infty/2}$ has a super-structure
with parity $\Lambda^{\infty/2,(m)}$ = the parity of $m$.
Setting
$|0\rangle=e_0 \wedge e_1 \wedge e_2 \ldots$,
$\mathcal{F}=\{\varphi(z),\varphi^*(z)\}$,
$T$ what it needs to be,
we get a vertex superalgebra.
In fact,
$$
F^{\text{ch}}=U(\hat{\mathfrak{a}})\otimes_{U(\hat{\mathfrak{a}_+})}
\mathbb{C}|0\rangle
\xrightarrow{\simeq}\Lambda^{\infty/2}
$$
is an isomorphism of vertex algebras.
Indeed, if $n_j,m_k \geq 1$,
\begin{align*}
&\varphi_{(n-1)}\varphi_{(-n_2)}\ldots\varphi_{(-n_s)}
\varphi^*_{(m_1)}\ldots \varphi^*_{(m_t)}|0\rangle
&=\pm e_{-n_1}\wedge e\ldots \wedge e_{-n_s}
\wedge \underbrace{(e_0 \wedge e_1 \wedge \ldots)
}_{\substack{\text{but with} \\ e_{m_1}\ldots e_{m_t}\\
\text{missing}}}
\end{align*}

\noindent
But these two pictures are bases of $F^{\text{ch}}$ and $\Lambda^{\infty/2}$,
so we have our linear isomorphism
$F^{\text{ch}} \to \Lambda^{\infty/2}$.
Just need to check carefully $\varphi$ and $\varphi^*$ 
are compatible with it.

\medskip\noindent
Pauli exclusion principle. In an ensemble
state of fermions,
two cannot occupy the same state,
(so they are modelled by odd variables
like ``$e_n$'' such that $e_n \wedge e_n=0$.)

Electron waves should obey 
``quantized'' wave-equation,
which is something like
\begin{align*}
\partial_t^2 \psi&=(- \overline{h}^2 \nabla+m)\psi\\
\partial_t \psi&=\sqrt{-\overline{h}\nabla+m}\psi.
\end{align*}

\noindent
A solution to this is, instead of
$$
\sqrt{\partial_{x x}+m},
$$
try to define
$$
\sqrt{(\partial_{x x}+m)I_4}
$$
where $I_4$ is the identity $4 \times 4 $ matrix.
Then the ``square root'' of $-\overline{h}^2 \nabla +m$
becomes a matrix valued differential operator,
denoted sometimes as $\not \partial + \gamma$,
where $\gamma$ is an explicit $4 \times 4$ matrix.
In $\partial_t \psi=\ldots$, $\psi$ has become
a vector-valued function on space,
with a splitting in spin up and spin down parts
of the electron wavefunction, and also an
``unphysical'' part. The latter
can be interpreted as the positrons.

Problem: the Dirac equation has positive and negative
energy solutions.

\medskip\noindent
Let's examine the neutral part
of $\Lambda^{\infty/2(0)}$.
Consider the element
$$
\underline{e}=e_{-4}\wedge e_{-2}\wedge e_{-1}
\wedge e_0 \wedge e_1 \wedge e_4 \wedge e_5
\wedge\underbrace{ e_7 \wedge e_8 \wedge e_9\wedge\ldots
}_{\text{consecutive part}}
$$
The successive differences are
$$
2\quad 1 \quad  1\quad 1 \quad 3 \quad 1 \quad 2 \quad 1
\quad  1 \quad  \ldots
$$
Since the sequence will stabilize at 1,
we might as well subtract 1 and obtain the finite
sequence 
$$
(1\quad 0\quad 0\quad 0\quad 2\quad 0\quad 1)
$$
In fact, you could reconstruct $\underline{e}$ 
from this list, and knowing that
$\text{charge}(\underline{e})=0$.

Form the partial sums
$$
1000201 \to 4333311
$$
these numbers are non-increasing,
so define uniquely a partition of some integer
(in this case 18), 
and if we compare with
$$
\underline{e}=\pm \varphi_{-4}\varphi_{-2}\varphi_{-1}
\varphi^*_2\varphi_3^*\varphi_6^*|0\rangle
$$
which has energy
$$
\Delta=(4-1/2)+(2-1/2)+(1-1/2)
+(2+1/2)+(3+1/2)+(6+1/2)=18.
$$

\noindent
We denote by $\underline{e}_\lambda$ 
the semi-infinite monomial of charge 0 given by
this procedure.

\medskip\noindent
So we have a basis
$\{\underline{e}_\lambda|\lambda\text{ integer partitions}\}$
of $F^{(0)}\simeq H = \mathbb{C}[x_1,x_2,x_3,\ldots]$,
which also has the basis
$\{\underline{x}_\lambda=x_1^{\lambda_1}\ldots x_5^{\lambda_5}|
\lambda \text{ integer partitions}\}$
where $\lambda=(1^{\lambda_1},2^{\lambda_2},\ldots,s^{\lambda_s})$,
that is, $1$ appears $\lambda_1$ times and so on.
We do {\bf not} have $\underline{e}_\lambda=\underline{x}_\lambda$!

\section{Schur polynomials}
\label{section-schur-polynomials}

The Schur polynomials are given by
the exponential generating function of $\sum z^kx_k$.
More precisely,

\begin{definition}
\label{definition-schur-polynomial}
We set  $S_k(\underline{x})$ by
$$
\sum_{k \geq 0}z^k S_k(\underline{x})
=\text{exp}\left(\sum_{k \geq 1}z^k x_k\right).
$$
\end{definition}

For a partition
$\lambda=(1^{\lambda_1}2^{\lambda_2}\ldots k^{\lambda_k})$,
define
$$
S_\lambda(\underline{x})
=\det
\begin{pmatrix}
S_{\lambda_1}& S_{\lambda_1+1}&\cdots &  S_{\lambda_1+k-1}\\
S_{\lambda_2-1}& S_{\lambda_2}&\cdots & \\
\vdots &  &  &  \vdots \\
S_{\lambda_k-k+1}&  &  &  S_{\lambda_k}
\end{pmatrix}
$$

Recall we defined $X=\bigoplus_{i \in \mathbb{Z}}\mathbb{C}e_i$
and $\Lambda^{\infty/2}=\left<e_{i_0}\wedge\ldots\right>$.
Let $g:X \to X$ be an invertible endomorphism.
We would like to 
define an endomorphism
\begin{align*}
R(g): \Lambda^{\infty/2} &\longrightarrow \Lambda^{\infty/2} \\
R(g)(e_{i_0}\wedge e_{i_1}\wedge\ldots) &=
(ge_{i_0})\wedge(ge_{i_1})\wedge \ldots 
\end{align*}
For some $g$, $\varepsilon g$, $g(e_n)=e_{-n}$,
$R(g)$ does not make sense
(or does not send  $\Lambda^{\infty/2}\to \Lambda^{\infty/2}$).

As a note, if $X$ were finite-dimensional,
say $X=\left<e_1,\ldots,e_n\right>$,
then $R(g):\Lambda^{k+1}X \to \Lambda^{k+1}X$
has matrix entry
$$
(e_{i_0}\wedge e_{i_1}\wedge\ldots\wedge e_{i_k})
\to(e_{j_0}\wedge e_{j_1} \wedge \ldots \wedge e_{j_k}),
$$
(with strictly increasing indices on both sides,
up to a sign maybe)
given by the determinant of the $(k+1)\times(k+1)$ 
matrix given by selecting the rows
$i_0,i_1,\ldots,i_k$, and the columns
$j_0,j_1,\ldots,j_k$ of the matrix of $g$.

\medskip\noindent
For our $X$ and $\Lambda^{\infty/2}$,
$R(g)$ makes sense if $g$ is such that 
$$
g(e_i)-e_i \in \text{span} \{ e_{>i}\}\qquad \forall i.
$$

\begin{proposition}
\label{proposition-schur-polynomials}
$\underline{e}_\lambda=S_\lambda(\underline{x})$
where 
\end{proposition}

\begin{proof}
Write $\underline{e}_\lambda=P(x)$.
We wish to show $P(x)=S_\lambda(x)$.
Introduce new variables $y_1,y_2,\ldots$ and
consider
$$
F(y)=\text{exp}
\left(\sum_{k>0}y_k\frac{\partial }{\partial x_k}\right)P(x)\Big|_{x=0}
$$
First we observe that
$$
F(y)=P(x_1+y_1,x_2+y_2,\ldots)|_{x=0}=P(x+y)|_{x=0}=P(y)
$$
since in general exponentiaing a differential operator
gives shifting by the coefficient, i.e.
$e^{a \frac{\partial }{\partial t}}f(t)=f(t+a)$.

Considering  
$$
P(x) \in \mathbb{C}[x_1,x_2,\ldots]=H\simeq F^{(0)},
$$
observe that for $k>0$,
\begin{align*}
\frac{\partial }{\partial x_k}&=h_k
=(\,:\!\varphi \varphi^*\!:\,)_k
=\sum_{i \in \mathbb{Z}}\varphi_{k+1}\varphi^*_i
\end{align*}

\noindent
i.e. it's a sum of ``remove $e_i$'' and ``insert $e_{k+i}$''.

Denote
\begin{align*}
\Lambda_k: X &\longrightarrow X \\
\Lambda_k(e_n) &=e_{n+k}\qquad  \forall n \in \mathbb{Z}
\end{align*}

\noindent
$R(\Lambda_k)=\frac{\partial }{\partial x_k}$,
since $\Lambda^{\infty/2(0)}\xrightarrow{\simeq}H$.

Therefore
$$
F(y)=R \text{exp}\left(\sum_{k>0}y_k \Lambda_k\right)
\underline{e}_\lambda\Big|_{\text{coef. in }|0\rangle}.
$$
Notice that $R \text{exp}(\Lambda_k)$ is of the form
$g(e_i)-e_i$.

Finally, notice that $\Lambda_k=\Lambda_1^k$,
so
\begin{align*}
&R \text{exp}\left(\sum_{k>0}y_k \Lambda_k\right)
\underline{e}_\lambda\Big|_{\text{coef. in }|0\rangle}\\
&=R \text{exp}\left(\sum y_k \Lambda_1^k\right)\underline{e}_\lambda\\
&=R(\left(S_k \Lambda_k\right)\underline{e}_\lambda.
\end{align*}
\end{proof}


\section{The Tate extension and the Japanese cocycle}
\label{section-tate-extension-and-japanese-cocycle}

\noindent
Recall $X=\bigoplus_{n \in \mathbb{Z}}\mathbb{C}e_n$
and $\Lambda^{\infty/2}$.
(You can be floppy and think that $\Lambda^{\infty/2}$ 
is the exterior power of $X$,
though that's not completely right.)
Define
$$
\mathfrak{gl}_\infty
=\left\{(a_{ij}):\substack{i,j \in \mathbb{Z},a_{ij}\in \mathbb{C} \\ 
\text{all but finitely many of the $a_{ij}$ vanish}}\right\},
$$
add and multiply as usual.

$\text{GL}_\infty=\{I+(a_{ij}):a_{ij}\in\mathfrak{gl}_\infty\}$,
with $I=(I_{ij})$ and $I_{ij}=\delta_{ij}$.
A typical element of $\mathfrak{gl}_\infty$ 
is $E_{ij}$ with $E_{ij}(e_k)=\delta_{jk}e_i$.

Last time we used shift operators
$\Lambda_k:e_n\mapsto e_{n+k}$ for all $n$.
These are {\bf not} in $\mathfrak{gl}_\infty$,
but {\bf are} in 
$$
\widetilde{\mathfrak{gl}_\infty}
=\left\{(a_{ij}):\substack{\exists  N s.t. a_{ij}=0 \\ \text{ whenever }
|i-j|>N}\right\}.
$$
Then $\Lambda_k=\sum E_{i+k,k}\in \widetilde{\mathfrak{gl}_\infty}$.

\begin{remark}
\label{remark-gltilde-is-Lie-algebra}
$\widetilde{\mathfrak{gl}_\infty}$ is an associative
Lie algebra (hence a Lie algebra with commutator).
This is because the condition of finiteness in the definition
excludes the possibility of infinite sums.
\end{remark}


We have a represenation $r$ of $\mathfrak{gl}_\infty$ 
on $\Lambda^{\infty/2}$ by
$$
r:E_{ij}\mapsto \varphi_i\varphi_j^*
$$
But this doesn't extend to $\widetilde{\mathfrak{gl}_\infty}$.
For instance, $r(\Lambda_0)=\sum_{j \in \mathbb{Z}}\varphi_{-j}\varphi^*_j$ 
diverges.

A ``solution'' is to use normal order,
so $r(\Lambda_0)=\sum_{j \in \mathbb{Z}}\,:\!\varphi_{-j}\varphi^*_j\!:\,$,
is now well-defined, but $r$ is no longer a representation.

\medskip\noindent
Today: more conceptual point of view.
Consider the vector space $\mathbb{C}(\!(t)\!)=X$.
(Which is {\it uncountably} infinite-dimensional.)
Give $X$ a linear topology
with a base of open neighbourhoods
of $0$ being $t^N\mathbb{C}[\![t]\!]$
for $N \in \mathbb{Z}$.
The idea is that
$t,t^2,t^3,\ldots$ ``tends to $0$''
in this topology.

\begin{definition}
\label{definition-tate}
A {\it Tate vector space} is a linearly
topologised vector space $X$ and a set $\mathcal{L}$ 
of linear subspaces $L \subset X$ 
(called {\it lattices}) such that
\begin{enumerate}
\item (Separated.) Any neighbourhood of $0$ contains
a lattice.

\item (Exhaustive.) Every $x \in X$
is contained in some lattice.

\item (Commensurable.) For all $L_1,L_2 \in \mathcal{L}$,
$L_1 \cap L_2$ has finite codimension
in $L_1$ (and in $L_2$). (This says
that any two lattices cannot be
``infinitely far apart''.)

\item (Complete.) For all $L_1,L_2 \in \mathcal{L}$,
all vector subspaces 
$L_1 \cap L_2 \subset S \subset L_1+L_2$
then $S \in \mathcal{L}$.

\item (Another completeness.) By the universal property of limit,
we know there exists a map
$X \to \lim_{\substack{L \in \mathcal{L} \\ L \to 0}} X/L$.
We ask this is an isomorphism.
\end{enumerate}
\end{definition}

\begin{example}
\label{example-tate-vector-space}
\begin{enumerate}
\item 
Laurent series is an example of a Tate vector space.
Let $X=\mathbb{C}(\!(t)\!)$ with
 $$
\mathcal{L}=\left\{L\subset X:\exists N\text{ s.t. }
t^N \mathbb{C}[\![t]\!] \subset L \subset
t^{-N}\mathbb{C}[\![t]\!]\right\}.
$$
We can also say that $\mathcal{L}$ is the
unique structure such that $\mathcal{L} \ni \mathbb{C}[\![t]\!]$.

\item If $\mathcal{L}=\{0\}$,
then $\mathcal{L}=\{L \subset X | \dim(L)<\infty\}$.

\item If $\mathcal{L}\ni X$, then
$\mathcal{L}=\{L \subset X|\dim(X/L)<\infty\}$.
\end{enumerate}
\end{example}

\noindent
Since we introduced a topology on $X$,
we can consider the continuous endomorphisms
$\text{End}_{\text{cont}}(X)$.
Let's denote throughout this section
 $$
\text{End}(X)=\{f \in \text{End}_{\text{cont}}(X)
:\exists U,V \in \mathcal{L}, f(U)\subset V\}.
$$
Relative to the ``basis''
$\{t^n|n \in \mathbb{Z}\}$,
the matrix of $f \in \text{End}(X)$ 
looks like
$$
\begin{pmatrix}
*&0\\ 
*&*
\end{pmatrix}
\begin{pmatrix}
0\\
*
\end{pmatrix}
$$
since the vectors in $V\subset t^m\mathbb{C}[\![t]\!]$
have zeroes before a certain index $n$.

\medskip\noindent
\begin{align*}
\text{End}_c(X)&=\{f \in \text{End}(X)| \exists  V \in \mathcal{L}
\text{ s.t. }f(X) \subset V\}
=\left\{\begin{pmatrix}
0&0\\ 
*&*
\end{pmatrix}\right\}\\
\text{End}_d(X)&=\{f \in \text{End}(X)|\exists U \in \mathcal{L}
\text{ s.t. }f(U)=0\}
=\left\{\begin{pmatrix}
*&0\\ 
*&0
\end{pmatrix}\right\}\\
\text{End}_f(X)&=\text{End}_c(X) \cap \text{End}_d(X)
=\left\{\begin{pmatrix}
0&0\\ 
*&0
\end{pmatrix}\right\}.
\end{align*}

\begin{remark}
\label{remark-trace-in-End}
For $f \in \text{End}_f(X)$,
the trace $\text{Tr}(f) \in \mathbb{C}$
is well-defined because
the intersection of the diagonal
with the lower-left part of any
matrix in $\text{End}_f(X)$ is finite.
For $\text{End}_c$ and $\text{End}_d$
trace is not well-defined.
\end{remark}

\noindent
We introduce the map

\begin{align*}
p:\text{End}_c(X) \oplus \text{End}_d(X)  &\longrightarrow \text{End}(X)\to  0\\
(f,g) &\longmapsto f+g
\end{align*}

\noindent
which is clearly surjective since we can put
$$
\begin{pmatrix}
A&0\\ 
B&C
\end{pmatrix}=\begin{pmatrix}
A&0\\ 
B&0
\end{pmatrix}+
\begin{pmatrix}
0&0\\ 
0&D
\end{pmatrix}.
$$
We can complete this to a short exact sequence 
(of vector spaces)
by putting
\begin{align*}
i:\text{End}_f(X)  &\longrightarrow \text{End}_c \oplus \text{End}_d \\
h &\longmapsto (h,-h).
\end{align*}

\noindent
Considering the trace $\text{Tr}:\text{End}_f(X) \to \mathbb{C}$,
we can form the pushout $L$ in the
category of
{\bf vector spaces}
$$
\xymatrix{
0\ar[r]&\text{End}_f\ar[r]\ar[d]_{\text{Tr}}\ar@{}[dr]|-{\ulcorner}&
\text{End}_c(X) \oplus \text{End}_d(X)\ar[d]\ar[r]&
\text{End}(X)\ar[r]&0\\
&\mathbb{C}\ar[r]& L
}
$$
Concretely,
$$
L=\frac{(\text{End}_c(X) \oplus \text{End}_d(X))\oplus \mathbb{C}}
{\left<(h,-h)=(0,0,\text{Tr}(h))|
\forall  h \in \text{End}_f(X)\right>}.
$$
Notice that the map $i$
is {\bf not} a Lie algebra map:
for this it would have to be a Lie algebra map
in both entries, which is true in the first entry
but not on the second.
Meanwhile, $p$ {\it is} a morphism of Lie algebras.
We could correct $i$ to map $h\mapsto  (h,h)$ 
and then change $p$ to be $\beta-\gamma$,
but then $p$ would stop being a Lie algebra morphism.
So this is not a short exact sequence of Lie algebras;
indeed it's not sensible to think of
short exact sequences of Lie algebras
since Lie algebras do not form an Abelian category.

But it is a short exact sequence of vector spaces
and we can form its exact sequence pushout by the following
exercise. (Also see Stacks Project tag
\href{https://stacks.math.columbia.edu/tag/010I}{010I}.)

\begin{exercise}
\label{exercise-pushout}
Let
$$
\xymatrix{
0\ar[r]&A\ar[r]&B\ar[r]&C\ar[r]&0
}
$$
be a short exact sequence of vector spaces
and $t:A \to K$ a linear map of vector spaces.
Let $X$ be the pushout
$$
\xymatrix{
A\ar[r]^i\ar[d]_t\ar@{}[dr]|-{\ulcorner}&B\ar[d]\\
K\ar[r]&X.
}
$$
Explicitly,
$$
X=\frac{K \oplus B}{\left<(t(a),0)-(0,i(a))|a \in A\right>}.
$$
Show that there exists a short exact sequence
 $$
\xymatrix{
0\ar[r]&K\ar[r]&X\ar[r]&C\ar[r]&0
}
$$
such that
$$
\xymatrix{
0\ar[r]&A\ar[r]\ar[d]_{t}\ar@{}[dr]|-{\ulcorner}&
B\ar[d]\ar[r]&
C\ar[r]\ar[d]^{\text{id}}&0\\
0\ar[r]&K\ar[r]& X\ar[r]& C\ar[r]&0
}
$$
commutes.
\end{exercise}

\begin{proof}
To define a map $X \to C$ we first notice
that all we have to do is define the map on
$K \oplus B$ at points not coming from $A$,
i.e. whose entries are not of the form
$(i(a),t(a))$ for $a \in A$.
Indeed, those are cancelled by the pushout definition
as a quotient. Further, we already have a map $\varphi:B \to C$
defined on elements not of the form $i(a)$ for $a \in A$ 
by exactness of the given short exact sequence.
Then we must define $(k,b) \mapsto \varphi(b)$
for the diagram to commute.

The resulting exact sequence is exact once
we know that $K \to B$ in the pushout
is given by $k \mapsto (k,0) \text{mod }\sim$.
\end{proof}

Then we obtain
$$
\xymatrix{
0\ar[r]&\text{End}_f\ar[r]\ar[d]_{\text{Tr}}\ar@{}[dr]|-{\ulcorner}&
\text{End}_c(X) \oplus \text{End}_d(X)\ar[d]\ar[r]&
\text{End}(X)\ar[r]\ar[d]^{=}&0\\
0 \ar[r]&\mathbb{C}\ar[r]& L\ar[r]& \text{End}(X)\ar[r]&0
}
$$
\medskip\noindent
Notice that the exact sequence
$$
\xymatrix{
0\ar[r]&\text{End}_f\ar[r]^i
&\text{End}_d \oplus \text{End}_f\ar[r]^p
&\text{End}\ar[r]&0
}
$$
is a bit more than 
just a short exact sequence of vector spaces.
Notice that $\text{End}_d,\text{End}_c \subset \text{End}$
are ideals.
Indeed,
if $f \in \text{End}_c$ and $g \in \text{End}$,
then $f \circ g \in \text{End}_c$ obviously,
$f(X) \subset V$ so $g \circ f (X) \subset g(V)$,
continuity of $g$
(plus axioms of Tate vector space)
implies that there exists $\widetilde{V} \in \mathcal{L}$
such that $g(V) \subset \widetilde{V}$.

\begin{exercise}
\label{exercise-spell-this-out}
Spell this out.
\end{exercise}

So $g \circ f \in \text{End}_c$.

\begin{exercise}
\label{exercise-ideal-too}
$\text{End}_d \subset \text{End}$ is an ideal too.
\end{exercise}

So $\text{End}_c, \text{End}_d$ are $\text{End}$-modules
(as associative algebras and as Lie algebras),
and
$$
\xymatrix{
0\ar[r]&\text{End}_f\ar[r]&\text{End}_d \oplus \text{End}_c\ar[r]&
\text{End}\ar[r]&0
}
$$
is a short exact sequence of End-modules.

\medskip\noindent
Let $\mathfrak{g}$ be a Lie algebra, $E$ a $\mathfrak{g}$-module
with $E \xrightarrow{p}\mathfrak{g}$ surjective
$\mathfrak{g}$-module morphism.
Consider
$$
\xymatrix{
0\ar[r]&\mathfrak{a}\ar[r]^i&E\ar[r]^p&\mathfrak{g}\ar[r]&0
}
$$
i.e. $\mathfrak{a}=\Ker(p)$.

Then one obtains a symmetric bilinear form
defined by
$$
(a,b)=p(a)b+p(b)a.
$$
\begin{exercise}
\label{exercise-bilinear-form-extension}
This form is (1) symmetric and 
(2) $\mathfrak{g}$-invariant.
\end{exercise}

\begin{exercise}
\label{exercise-central-extension}
Check that the data above,
satisfying $(\cdot,\cdot)=0$
is the same as a central extension of $\mathfrak{g}$ 
by $\mathfrak{a}$,
i.e. Lie bracket $[\cdot,\cdot]:E \times E \to E$
compatible with $[\cdot,\cdot]$ on $\mathfrak{g}$ 
such that $\mathfrak{a}\subset E$
is central.
{\bf Hint.} Set $[a,b]^E=p(a)b$.
\end{exercise}

\noindent
As a particular case of this,
if we have
\begin{itemize}
\item $\mathfrak{g}$ a Lie algebra,
\item $\mathfrak{a}_1, \mathfrak{a}_2 \subset \mathfrak{g}$
two ideals such that $\mathfrak{g}=\mathfrak{a}_1 + \mathfrak{a}_2$,
\item setting $\mathfrak{a}_0=\mathfrak{a}_1 \cap \mathfrak{a}_2$,
a linear map $\mathfrak{a}_0 \xrightarrow{T}K$
such that $T([x_1,x_2])=0$ for all
$x_1 \in \mathfrak{a}_1$ and $x_2 \in \mathfrak{a}_2$.
\end{itemize}

\noindent
Then we can form
$$
\xymatrix{
0\ar[r]&\mathfrak{a}_0\ar[d]_T\ar[r]^i
&\mathfrak{a}_1 \oplus \mathfrak{a}_2\ar[d]\ar[r]^p
&\mathfrak{g}\ar[r]\ar[d]^{\text{id}}&0\\
0\ar[r]& K\ar[r]& X\ar[r]&\mathfrak{g}\ar[r]&0
}
$$
\noindent
with pushout at level of vector spaces
and $i:\alpha \mapsto (\alpha,-\alpha)$ 
and $p:(\beta,\gamma)\mapsto \beta+\gamma$.

\begin{exercise}
\label{exercise-central-extension}
Then $X$ will become a Lie algebra
with $K$ central and
$\mathfrak{a}_1 \oplus \mathfrak{a}_2 \to X$
a map of Lie algebras.
\end{exercise}

\noindent
The main point of this construction
is to use $T([x_1,x_2])$
to confirm that
$$
T(p(a)b+p(b)a)=0\qquad \forall a,b \in \mathfrak{a}_1 \oplus \mathfrak{a}_2.
$$
Indeed, write $a=(a_1,a_2)$ and $b=(b_1,b_2)$.
Then
\begin{align*}
&T(([a_1,a_2,b_1],[a_1+a_2,b_2])+([b_1+b_2,b_1],[b_1+b_2,a_2])\\
&=T([a_1,b_1]+[a_2,b_1]+[b_1,a_1]+[b_2,a_1],
[a_1,b_2]+[a_2,b_2]+[b_1,a_2]+[b_2,a_1])\\
&=T(i(\underbrace{[a_2,b_1]}_{\in[\mathfrak{a}_1,\mathfrak{a}_2]}+
\underbrace{[b_2,a_1]}_{\in[\mathfrak{a}_2,\mathfrak{a}_1]}))\\
&=0\qquad \text{by hypothesis.}
\end{align*}

\medskip\noindent
We apply this, in particular, to
$$
\mathfrak{g}=\text{End}(X)
\qquad \mathfrak{a}_1=\text{End}_d(X)
\qquad \mathfrak{a}_2=\text{End}_c(X)
\qquad \mathfrak{a}_0=\text{End}_f(X)
$$
$$
X \text{ our Tate vector space}\qquad 
T \text{ trace}.
$$

\noindent
For the construction above to work
we still have to check that
$$
\text{Tr}([A_d,A_c])=0
$$
whenever $\text{Ad} \in \text{End}_d$ and
$A_c \in \text{End}_c$.
You would think this is obvious,
but it isn't.
(I.e., $\text{Tr}(AB-BA)=0$ for $A,B \in \text{End}(\text{finite-dimensional
vector space})$.)

Let us sketch the proof.
Let $f \in \text{End}_c$ and $f(X) \subset V$ 
($V \in \mathcal{L}$),
and $g \in \text{End}_d$ and $g(U)=0$
($U \in \mathcal{L}$).
Then
$$
X \xrightarrow{f}\underbrace{f(X)}_{\subset V}\xrightarrow{g}
\underbrace{gf(X)}_{\subset g(V)}.
$$
And
$$
X \xrightarrow{g}g(X) \to \underbrace{fg(X)}_{\subset V}.
$$
So $\text{Im}[f,g] \subset V+g(V)$
So $[f,g](U \cap f^{-1}(U))=0$.
$$
\underbrace{f^{-1}g^{-1}(0)}_{\subset f^{-1}(U)}
\xrightarrow{f}\underbrace{g^{-1}(0)}
_{\subset U}\xrightarrow{g}0
$$
and 
$$
\underbrace{g^{-1}f^{-1}(U)}_{\subset U}
\xrightarrow{g}f^{-1}(0)\xrightarrow{f}0.
$$

\noindent
Now the idea is to argue that
$$
\text{Tr}[f,g]=\text{Tr}_Q[f,g],
$$
where
$$
Q=(V+g(V))/(U\cap f^{-1}(U))
$$
is a finite-dimensional vector space.
But on finite dimensional vector spaces
the trace of commutator vanishes.

\medskip\noindent
You might imagine that $\text{Tr}[f,g]=0$
whenever $[f,g]\in \text{End}_f(X)$,
but this is false.

\begin{example}
\label{example-trace-of-commutator-not-vanishing}
Let $A \subset \text{End} (X)$ be a commutative subalgebra.
(For instance, if $X= \mathbb{C}((t))$,
then $f(t) \in \mathbb{C}((t))$
we have $\mu_f \in \text{End}(X)$
and $\mu_f(g)=fg$.)
Then I claim, if $f,g \in A$,
$f=f_c+f_d$,  $g=g_c +g_d$,
that $[f_c,g_c] \in \text{End}_f$.
Obviously  $[f_c,g_c] \in \text{End}_c$,
but also
\begin{align*}
[f_c,g_c]&=[f-f_d,g-g_d]\\
&=\underbrace{[f,g]}_{=0}
\underbrace{-[f,g_d]-[f_d,g]+[f_d,g_d]}_
{\substack{\in\text{End}_d \text{ because }\\\text{End}_d \overset{\text{ideal}}
{\subset} \text{End}}}.
\end{align*}

\noindent
I claim that $\text{Tr}[f_c,g_c]$ might not vanish.

In fact let $X=\mathbb{C}((t))$,
$f=\mu_{t^{-2}}$, $g=\mu_{t^2}$ 
(or with any $N \geq 0$ in place of 2).

To fix $f_c,g_c$, lwt's make the following
choice:
 \begin{align*}
\pi: X &\longrightarrow X \\
\pi(t^n) &= \delta_{n\geq 0}t^n. 
\end{align*}

\noindent
Then set $f_c=\pi \circ f$, etc.
Let's compute $[f_c,g_c]$.
[Picture]. We obtain $\text{Tr}[f_c,g_c]=2$.
\end{example}

\noindent
The next proposition is
``Tate's definition of the residue''.
Tate was trying to generalize the Residue Theorem,
i.e. that $\sum_{p \in C}\text{Res}_p \omega=0$ 
for points on a curve $C$ and a differential form $\omega$.

\begin{proposition}
\label{proposition-trace}
For any choice of splittings,
$f=f_c+f_d$, etc, and for all $f,g \in \mathbb{C}((t))$,
$$
\text{Tr}[f_c,g_c]=\text{Res}_tf\cdot dg.
$$
\end{proposition}

\section{Representing the endomorphisms algebra on the charged fermions}
\label{section-end-rep-fermions}

We want to represent $\text{End}(X)$ on $ \Lambda^{\infty/2}$.
We start presenting the naive idea.
Let $x \in X$ and $\varphi \in X^*$.
We already have
$$
\rho(x)=x \wedge(-) \in \text{End}(\Lambda^{\infty/2})
$$
and
$$
\rho(\varphi)=\sum_{j=0}^\infty(-1)^j
\varphi(x_{i_j})x_{i_0}\wedge x_{i_1}\wedge\ldots\wedge \widehat{x_{i_j}}
\wedge \ldots.
$$

\noindent
We already saw that
$\rho(\hat{x}_i)\rho(\hat{\varphi}_j)+\rho(\hat{\varphi}_j)\rho(\hat{x}_i)
=\delta_{ij}I$
(here I'm identifying
$\hat{x}_i \equiv t^i \in \mathbb{C}((t))=X$,
 $\varphi_i \in X^*$ is
$\hat{\varphi}_i (\sum c_jt^j)=c_j$).
See Exercise \ref{exercise-something-like}.

If $f \in \text{End}_d$, we can think of $f$ as
$$
f=\sum_{i=0}^a x_i \otimes \varphi_i,
$$
where $\varphi_i\to 0$ as $i \to \infty$.

Here $x_i \to 0$ means
$\forall  N \geq 0$ $\exists n_0$ such that
$x_n \in t^N \mathbb{C}[[t]]$ for all $n\geq  n_0$.
And $\varphi_i \to 0$ means $\forall  N \geq 0$ $\exists n_0$
such that
$\varphi_n(t^{-N}\mathbb{C}[[t]])=0$ for all $n\geq n_0$.

One can confirm that for $f \in \text{End}_d$,
$$
\rho_d(f):=\sum_i\rho(x_i)\rho(\varphi_i)
$$
acts a finite sum,
when applied to any fixed vector of
$\Lambda^{\infty/2}$.
So
$$
\rho_d:\text{End}_d \to \text{End}(\Lambda^{\infty/2}X)
$$
is well defined.

For  $\text{End}_c \ni f$, we can write
$$
f=\sum_i x_i \otimes \varphi_i,
$$
where $x_i \to 0$.
Now $\rho_d(f)$ makes no sense, but
$$
\rho_c(f):=\sum_{i=0}^\infty\rho(\varphi_i)\rho(x_i)
$$
does.

\begin{exercise}
\label{exercise-representation-of-end}
Confirm that $\rho_d: \text{End}_d \to \text{End}(\Lambda^{\infty/2})$ 
and $\rho_c:\text{End}_c \to \text{End}(\Lambda^{\infty/2}X)$
are morphisms of Lie algebras.
\end{exercise}

\noindent
(Neither of these morphisms work at the
level of associative algebras.)

\medskip\noindent
We notice that,
for $f \in \text{End}_f(X)$,
$$
\rho_d(f)-\rho_c(f)=\text{Tr}(f).
$$
This means 
$$
\text{End}_d \oplus \text{End}_c \xrightarrow{(\rho_d,\rho_c)}
\text{End}(\Lambda^{\infty/2}X)
$$
descends to a morphism
$$
\xymatrix{
\text{End}_d \oplus \text{End}_c\ar[r]^{(\rho_d,\rho_c)}\ar[d]
&\text{End}(\Lambda^{\infty/2}X)\\
\mathfrak{gl}^\flat (X).\ar[ur]_\rho
}
$$

\begin{theorem}
\label{theorem-tate}
Let $X$ be a Tate vector space.
There exists a natural representation
of $\mathfrak{gl}^\flat(X)$ on $\Lambda^{\infty/2}(X)$.
\end{theorem}

\noindent
Next time we'll apply this to the case
$X$ itself is already a Lie algebra!

\section{The 26-dimensionality of the universe}
\label{section-26-dimensionality-universe}

Last time: $X$ a Tate vector space (for us $X=\mathbb{C}((t))$).
We say that $\text{End}(X)=\text{End}_c(X)+\text{End}_d(X)$
comes with a canonical central extension
(as a Lie algebra
$$
\xymatrix{
0\ar[r]&\mathbb{C}\ar[r]&
\mathfrak{gl}(X)^\flat\ar[r]&
\text{End}(X)\ar[r]&0
}
$$
with
$$
\mathfrak{gl}(X)^\flat=
\frac{\text{End}_c \oplus \text{End}_d \oplus \mathbb{C}}{
\left<(h,-h,0)=(0,0,\text{Tr}(h))|h \in \text{End}_f(X)\right>},
$$
and there is a canonical representation of 
$fl(X)^\flat$ on the semi-infinite wedge space
$\Lambda^{\infty/2}(X)=\left<i_{i_0}\wedge e_{i_1}\wedge\ldots\right>$ 
defined by
\begin{equation}
\label{equation-rep}
\begin{aligned}
\rho_d(\underbrace{\sum_ix_i\varphi_i}_{\in\text{End}_d?})&=
\sum_i\rho(x_i)\rho(\varphi_i)\\
\rho_c(\underbrace{\sum_ix_i\varphi_i}_{\in \text{End}_c})&=
-\sum_i\rho(\varphi_i)\rho(x_i),
\end{aligned}
\end{equation}
where
$$
\rho(x)=x\wedge(-),\qquad 
\rho(\varphi)=
\sum_{j=0}^\infty(-1)^j \varphi(e_{i_j})
e_{i_0}\wedge e_{i_1}\wedge \ldots \wedge \widehat{e_{i_j}}\wedge\ldots
$$


\noindent
Now suppose $X$ itself were a Lie algebra.

\begin{example}
\label{example-with-X-lie-algebra}
$X=\mathbb{C}((t))$ as above, but we identify
$t^m \rightsquigarrow L_m$ in Vir @ $c=0$.
So  $[t^m,t^n]=(m-n)t^{m+n}$.
To avoid confusion, let's write $t^m$ as $L_m$ in fact.
In such situation, we have a linear map
$\text{ad}:X \to \text{End}(X)$.

We can pull back $\mathfrak{gl}(X)^\flat$ 
$$
\xymatrix{
0\ar[r]&\mathbb{C}\ar[r]
&\mathfrak{gl}(X)^\flat\ar[r]^\pi
&\text{End}(X)\ar[r]&0\\
&& \hat{X}\ar[r]\ar[u]& X\ar[u]^{\text{ad}}.
}
$$
Explicitly,
$$
\hat{X}=
\{(x,A) \in X \oplus \mathfrak{gl}(X)^\flat
|\text{ad}(X)=\pi(A) \text{ in }\text{End}(X)\}.
$$
\end{example}

\begin{exercise}
\label{exercise-pushout2}
Similarly to Exercise \ref{exercise-pushout},
show $\hat{X}$ fits into a sequence
$$
\xymatrix{
0\ar[r]&\mathbb{C}\ar[r]&\hat{X}\ar[r]&X\ar[r]&0.
}
$$
\end{exercise}
So we get a (canonical!) central extension of $X$:
$$
\xymatrix{
0\ar[r]&\mathbb{C}\ar[d]^{\text{id}}\ar[r]
&\mathfrak{gl}(X)^\flat\ar[r]^\pi
&\text{End}(X)\ar[r]&0\\
0\ar[r]&\mathbb{C}\ar[r]&\hat{X}\ar[u]\ar[r]& X\ar[u]^{\text{ad}}\ar[r]&0
}
$$
For $X=\text{Der}(\mathbb{C}[t^{\pm 1}]=$ centerless Vir,
we will find the canonical central extension is
Vir  @ $c=-26$. (i.e. charge is  $-26$.)

\noindent
What might be amazing here is that any infinite-dimensional
Lie algebra has a central extension --- just by being infinite-dimensional.

\medskip\noindent
We'll exploit
$$
\Lambda^{\infty/2}(X)
=\left<L_{m_0}\wedge L_{m_1}\wedge L_{m_2}\wedge\ldots\right>.
$$
We have quantum fields
\begin{align*}
\varphi(w)&=\sum_n\varphi_nw^{-n-1},\qquad 
\varphi=L_n \wedge(-),\\
\varphi^* (w)&=\sum_n \varphi_n^* w^n,\qquad 
\varphi_n^* (\underline{L})=
\sum(-1)^j\varphi(L_{i_j})L_{i_0}\wedge L_{i_1}\wedge\ldots
\end{align*}

\noindent
Now for 
$$
L_m \in X,\qquad  L_m :L_n \mapsto  (m-n)L_{m+n},
$$
$$
\text{ad}(L_m)=\underbrace{\sum_{n \in \mathbb{Z}}(m-n) L_{m+n}L_n^*}
_{\in \text{End}_c + \text{End}_d}.
$$
To represent $\text{ad}(L_m)$ on $\Lambda^{\infty/2}$ 
we have to split $\text{ad}(L_m)$ into pieces
in $\text{End}_d$ and $\text{End}_c$ and
send each part to their corresponding pieces
according to Equation \ref{equation-rep}.

\medskip\noindent
Let's work at the level of fields.

\begin{align*}
L(w)&=\sum_m \rho(\text{ad}(L_m)) w^{-m-2}\\
&=\sum_{m,n}(m-n)\rho(L_{m+n}L_n^*)w^{-m-2}\\
&=\sum_{m,n}(m-n)\,:\!\varphi_{m+n}\varphi^*_n\!:\,w^{-m-2}\\
&=\sum_{m,n}(m-n)\,:\!(\varphi_{m+n}w^{-(m+n)-?})
(\varphi_n^*w^{+n+?}\!:\,
\end{align*}
where
$$
\rho(L_{m+n}L_n^* =\begin{cases}
\rho(L_{m+n})\rho(L_n^*)\qquad &\text{when $n\ll 0$} \\
-\rho(L^*_n)\rho(L_{m+n})\qquad &\text{when }n\gg 0.
\end{cases}
$$
Notice that
\begin{align*}
\partial_w\varphi(w)&=\partial_w \sum \varphi_{m+n}w^{-m+nj}\\
&=-\sum(m+n)\varphi_{m+n}w^{-(m+n)-1}\\
&=\sum n \varphi_n^* w^{n-1}
\end{align*}

\noindent
since $m-n=(m+n)-2n$,
so it seems we should consider
$$
-\,:\!(\partial \varphi)\varphi^*\!:\,
-2\,:\!\varphi(\partial \varphi^*)\!:\,k
$$

\medskip\noindent
So, we have a vertex superalgebra
$V=\Lambda^{\infty/2}$, with quantum fields
$\varphi$ and $\varphi^*$, OPE relation
$[\varphi_\lambda \varphi^*]=1$.

We are defining a field
$$
L=-\,:\!(\partial \varphi)\varphi^*:\,
-2\,:\!\varphi(\partial \varphi^*)\!:\,,
$$
(which is a quantum field, $L(w)=\sum_m L_mw^{-m-2}$),
adn we want to know/check
$$
[L_m,L_n]=(m-n)L_{m+n}+\delta_{m,-n}\frac{m^3-m}{12}CI_{\Lambda^{\infty/2}}.
$$
So, what's $c$? Let's do it.

\begin{itemize}
\item (Method 1.) Brute force.
\item (Method 2.) Use mathematica (Thielman's package).
\item (Method 3.) Recall $\alpha=\,:\!\varphi \varphi^*\!:\,$,
satisfies $[\alpha_\lambda \alpha]=\lambda$ and
$L^0=\frac{1}{2}\,:\!\alpha \alpha\!:\,$
is Virasoro @ $c=1$.
\end{itemize}
$$
[L^0_\lambda L^0]-TL^0+2\lambda L^0+\frac{\lambda^3}{12}.
$$
\begin{align*}
L^0&=\frac{1}{2}\,:\!\alpha \alpha\!:\,\\
&=\frac{1}{2}
\,:\!(\,:\!\varphi \varphi^*\!:\,)(\,:\!\varphi \varphi^*\!:\,)\!:\,\\
&=\ldots\\
&=\frac{1}{2}(\,:\!(T\varphi)\varphi^*\!:\,+\,:\!\varphi(T\varphi^*)\!:\,.
\end{align*}

How to see this?
Recall Borcherds identity (Equation \ref{equation-Borcherds-identity}):
\begin{align*}
&\sum_{j \geq 0}\binom{m}{j}(a_{(n+j)}b)_{(m+k-j)}c\\
&=\sum_{j \geq 0}(-1)^j \binom{n}{j}
(a_{(a+m-j)}b_{(k+j)}c-(-1)^nb_{(n+k-j)}a_{(m+j)}c.
\end{align*}
So put
$$
\begin{matrix}
a=\varphi & m=0\\
b=\varphi^*  & n=-1\\
c=\,:\!\varphi \varphi ^*\!:\,& k=-1.
\end{matrix}
$$

Then
$$
LHS=(a_{(-1)}b)_{(-1)}c=\,:\!(\,:\!\varphi\varphi^*\!:\,)
(\,:\!\varphi\varphi^*\!:\,)\!:\,
$$
and
$$
RHS=\sum_{j \geq 0}(\varphi_{(-i-j)}\varphi^*_{(-1+j)}\varphi_{(-1)}\varphi^*
+\varphi^*_{(-2-j)}\varphi_{(j)}\varphi_{(-1)}\varphi^*).
$$
$$
\text{[Picture]}
$$
$$
RHS=\varphi_{(-1)}\varphi^*_{(-1)}\alpha+\varphi_{(-2)}\varphi^*_{(0)}\alpha
+\varphi^*_{(-2)}\varphi_{(0)}\alpha.
$$

Note:
$$
\varphi_{(0)}\alpha=-\alpha_{(0)}\varphi=+\varphi.
$$
In general
$$
b_{(0)}a=-\sum_{j\geq 0}\frac{1}{j!}T^j(a_{(j)}b)
=-a_{(0)}b+T(\text{stuff}).
$$

\begin{remark}
\label{remark-quotient}
Recall (ref?) that if $V$ is any vertex algebra,
$V/TV$, $[\overline{a},\overline{b}]=a_{(0)}b$,
is a Lie algebra.
\end{remark}

\noindent
So,
$$
RHS=\varphi_{(-1)}\varphi^*_{(-1)}\alpha
-\varphi_{(-2)}\varphi^*+\varphi^*_{(-2)}\varphi.
$$
Now, since in general
$$
b_{(n)}a=-(-1)^{p(a)p(b)}\sum_{j \geq 0}\frac{(-1)^j}{j!}
T^j(a_{(n+j)}b,
$$
then
$$
\varphi^*_{(-2)}\varphi=\sum_{j\geq 0}\frac{(-1)^j}{j!}
T^j(\varphi_{(-2+j)}\varphi^*.
$$
{\bf But this led to mistaken calculations.}
I was trying to do the following: we know that
$\alpha=\,:\!\varphi \varphi^*\!:\,$ satisfies
$[\alpha_\lambda \alpha]=\lambda$,
and $L^0=\frac{1}{2}\,:\!\alpha \alpha\!:\,$ is
$\text{Vir}[L^0_\lambda L^0]=TL^0+2\lambda L^0+\frac{\lambda^3}{12}$
($c=1$).
Also, if $B=L^0+kT_\alpha$ then
$$
[B_\lambda B]=TB+2\lambda B+\frac{\lambda^3}{12}c_k,\qquad 
c_k=1-12k^2.
$$
Writing $B$ in terms of $vp,\varphi^*$,
one gets \underline{something} like
$$
B=b\,:\!(T\varphi)\varphi^*\!:\,
+(1-b)\,:\!\varphi(T\varphi^*)\!:\,.
$$
The correct answer is: if 
$L=-\,:\!(T\varphi)\varphi^*\!:\,-2\,:\!\varphi(T\varphi^*)\!:\,$,
we may verify that
$$
[L_\lambda L]=TL+2\lambda L- \frac{26}{12}\lambda^3.
$$

\medskip\noindent
In summary, today we did the following.
For $\varphi, \varphi^*$ odd, $[\varphi_\lambda \varphi^*]=1$,
we define the operator
$$
L=-\,:\!(T\varphi)\varphi^*\!:\,=2\,:\!\varphi(T\varphi^*)\!:\,.
$$
Then compute and find out that
 $$
[L_\lambda L]=TL+2\lambda L+\frac{c}{12}\lambda^3,
$$
where $c=-26$.

That is, after computing the central extension
of the Virasoro algebra, we turn to the
vertex algebra language to find that the central
charge is $-26$.

Even more explicitly: by the Tate vector space construction
we have the central extension
$$
\xymatrix{
0\ar[r]&\mathbb{C}C\ar[r]&\mathfrak{gl}(X)^\flat\ar[r]&\mathfrak{gl}(X)\ar[r]&0
}
$$
where $W=\mathbb{C}((t))$ is the Witt algebra,
with bracket $[L_m,L_n]=(m-n)L_{m+n}$.

And then we do the pullback in the following way:
$$
\xymatrix{
0\ar[r]&\mathbb{C}K\ar[d]^{\text{id}}\ar[r]
&\mathfrak{gl}(W)^\flat\ar[r]^\pi
&\text{End}(X)\ar[r]&0\\
0\ar[r]&\mathbb{C}K\ar[r]&W \oplus \mathbb{C} K\ar[u]\ar[r]
& W\ar[u]^{\text{ad}}\ar[r]&0
}
$$
Then we get a representation in which $K$ goes to the identity,
namely
$$
\mathfrak{gl}(X)^\flat \mathbb{y} \Lambda^{\infty/2},
\qquad K \mapsto \text{Id}.
$$
So, the vertex algebra language allows us to compute
the central charge of the new algebra we obtained,
$W \oplus \mathbb{C}K$,
and realise it's $-26$. So the bracket in the new algebra is
 $$
[L_m,L_n]=(m-n)L_{m+n}+\frac{m^3-m}{12}(-26)K.
$$

\section{Lattice Vertex algebras}
\label{section-lattices}

\begin{definition}
\label{definition-lattice}
A {\it lattice} (for us) is a discrete subgroup $L \subset \mathbb{R}^n$,
$L \simeq \mathbb{Z}^n$, and such that $(\alpha,\beta) \in \mathbb{Z}$ 
for all $\alpha, \beta \in L$,
where $(\cdot,\cdot):\mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}$ 
is the standard bilinear form
$((u_1,\ldots,u_n),(v_1,\ldots,v_n))=\sum u_iv_i$.
\end{definition}

\noindent
In particular, $L$ contains a basis of the 
ambient space $\mathbb{R}^n$.

\begin{example}
\label{example-lattices}
\begin{enumerate}
\item $\mathbb{Z}^n \subset \mathbb{R}^n$ is a lattice.
\item $A_2$, the root lattice of $\mathfrak{sl}_3$, is a lattice.
Recall this looks like a triangular tiling with
$(\alpha_1,\alpha_1)=2$, $(\alpha_2,\alpha_2)=2$ 
and $(\alpha_1,\alpha_2)=-1$, which in says
that the angle between $\alpha_1$ and $\alpha_2$ is $120$ degrees. 
\end{enumerate}
\end{example}

\begin{definition}
\label{definition-even-lattice}
A lattice is called {\it even} if $(\alpha,\alpha)\in 2 \mathbb{Z}$ 
for all $\alpha \in L$.
\end{definition}

\noindent
(That is, the product of every element with {\it itself} is even,
not that $(\alpha,\beta)\in 2 \mathbb{Z}$ for all $\alpha,\beta \in L$.)

So $A_2$ is even. In fact, whenever the basis elements
are even, say $(\alpha,\alpha),(\beta,\beta)\in 2\mathbb{Z}$,
then the lattice is even since
$(\alpha \pm \beta,\alpha \pm \beta)=(\alpha,\alpha)
\pm 2(\alpha,\beta)+(\beta,\beta) \in 2\mathbb{Z}$ too.

\begin{definition}
\label{definition-dual-lattice}
The {\it dual} of $L$ is 
$$
L^\vee=\{ x \in \mathbb{R}^n|(x,\alpha) \in \mathbb{Z}\forall \alpha \in L\}.
$$
\end{definition}

\noindent
Clearly $L \subset L^\vee$.
But $L^\vee$ might be strictly larger.

\begin{exercise}
\label{exercise-discriminant}
$L^\vee/L$ is a finite group.
\end{exercise}

\noindent
Notice that for  $\gamma,\delta \in L^\vee$
it might happen that $(\gamma,\delta) \not\in \mathbb{Z}$.

For $L=A_2$ we find that
$$
L^\vee = A_2 \cup (\omega+A_2) \cup  (2\omega + A_2).
$$
So $L^\vee/L \simeq \mathbb{Z}/3$ as groups.

For $L = \mathbb{Z}^n$, we have $L^\vee=\mathbb{Z}^n=L$, that is,
$\mathbb{Z}^n$ is self dual.
On the other hand $\mathbb{Z}^n$ is not even.

Are there any other even self-dual lattices
(other than $\{0\}$)?

The simplest nontrivial example is
$$
E_8=\{(x_1,x_2,\ldots,x_8) \in \mathbb{Z}^8 \cup (\frac{1}{2}+\mathbb{Z})^8|
\sum_{i=1}^8 \equiv 0 \text{mod }2\}.
$$

\begin{lemma}
\label{lemma-e8}
$E_8$ is even and self-dual.
\end{lemma}

\begin{theorem}
\label{theorem-self-dual-lattices}
\begin{enumerate}
\item If $L \subset \mathbb{R}^n$ is even and self dual,
then $8|n$

\item If, also, $n=8$, then $L \simeq E_8$.
\end{enumerate}
\end{theorem}

\begin{remark}
\label{remark-discriminant-form}
Let $L$ be an even lattice.
On the group $D=L^\vee/L$ we define
\begin{align*}
q: D &\longrightarrow \mathbb{Q}/\mathbb{Z} \\
q(a) &=(\alpha,\alpha)/2 \text{ mod }\mathbb{Z}.
\end{align*}

\noindent
Then $q$ is a well-defined quadratic form.

Indeed, for $\beta \in L$,
$$
q(\alpha+\beta)=\frac{(\alpha+\beta,\alpha+\beta)}{2}
=\underbrace{\frac{(\alpha,\alpha)}{2}}_{=q(\alpha)}
+\underbrace{\frac{2(\alpha,\beta)}{2}}_{\in \mathbb{Z}}
+\underbrace{\frac{(\beta,\beta)}{2}}_{\in \mathbb{Z}}.
$$
We call $(D,q)$ the {\it discriminant form} of $L$.
\end{remark}

\medskip\noindent
Now we explain the neighbour construction/orbifold.
Let $L$ be a self-dual even lattice.
Let $\phi:L \to \mathbb{Z}/2$ a homomorphism
(i.e. if $\{e_1,\ldots,e_n\}$ is a basis of $L$,
set $\phi(e_i)=\varepsilon_i \in \{0,1\}$
and $\phi(\sum m_i e_i)=\sum m_i \varepsilon_i \text{ mod }2$.

Assume $\phi$ is nontrivial and surjective, so that its kernel
$L_0 = \Ker \phi \subset L$ has index 2.
That is, $L/L_0 \simeq \mathbb{Z}/2$.

Now we have $L_0 \underbrace{\subset }_{\text{index 2}}L 
= L^\vee \underbrace{\subset}_{\substack{\text{index 2} \\ \text{exercise}}}
L_0^\vee$.

\begin{remark}
\label{remark-discriminant-iso}
$D=L_0^\vee/L_0 \simeq \mathbb{Z}/2\times\mathbb{Z}/2$.
\end{remark}

\noindent
Why? If $\omega \in L_0^\vee$, then $2\omega$… Exercise.

What about $(D,q)$? I claim there are two possibilities
(up to $\simeq$):
\begin{equation}
\label{equation-cases}
\begin{pmatrix}
0&0\\ 
0&1/2
\end{pmatrix}\qquad 
\begin{pmatrix}
0&1/4\\ 
0&3/4
\end{pmatrix}
\end{equation}

\noindent
Exercise.

Suppose (by choice of $\phi$) we are in the first case.
Then $L=L_0 \cup  (\alpha+L_0)$, $q(\beta)=0$, i.e.
$(\beta,\beta)\equiv 0 \text{ mod }2$,
$$
\begin{pmatrix}
L_0&\beta+L_0\\ 
\alpha+L_0&\gamma+L_0
\end{pmatrix}.
$$
Define $L^{\text{orb}(\phi)}=L_0 \cup  (\beta+L_0)$.

\begin{lemma}
\label{lemma-even-lattice}
$L^{\text{orb}(\phi)}$ is an even lattice.
\end{lemma}

\begin{proof}
Exercise. Idea: $(L_0,L_0) \subset \mathbb{Z}$ and 
$(L_0,\beta+L_0)\subset \mathbb{Z}$ by definition.
\end{proof}

\noindent
For $\beta,\beta' \in \beta+L_0$,
\begin{align*}
(\beta',\beta)&=(\beta+\alpha,\beta),\qquad \alpha \in L_0\\
&=\underbrace{(\beta,\beta)}_{\in \mathbb{Z}}
+\underbrace{(\alpha,\beta)}_{\in \mathbb{Z}} \in \mathbb{Z}
\end{align*}

\noindent
Also, $(L^{\text{orb}(\phi)})^\vee=L^{\text{orb}(\phi)}$.
Indeed
$$
L_0 \underbrace{\subset}_{\text{index 2}}L^{\text{orb}(\phi)}
\underbrace{\subset}_{\text{by above}}
(L^{\text{orb}(\phi)})^\vee
\underbrace{\subset}_{\text{index 2}}
L_0^\vee.
$$

\begin{theorem}[Niemer]
\label{theorem-niemer}
If we consider the set $\Gamma_n$ of all
even self-dual lattices of rank $n$ ($8|n$)
as a graph, with edge whenever there
exists an operation $L \to L^{\text{orb}(\phi)}$,
then $\Gamma_n$ is connected for all $n$.
\end{theorem}

\begin{remark}
\label{remark-reverse-orbifold}
There is a reverse orbifold construction.
\end{remark}

\noindent
Let $L$ be even self dual, $L=L_0 \cup  L_1$, and
$$
\begin{pmatrix}
L_0&L_+\\ 
L_1&L_-
\end{pmatrix}
$$
$L_0^\vee=L_0 \cup  L_1 \cup  L_+ \cup  L_-$,
say $L_+$ is $q(\alpha)=0$ for all $alp \in L_+$
and $q(\beta)=1/2$ for all $\beta \in L_-$
since we are fixed in the first case of
Equation \ref{equation-cases}.

Define
\begin{align*}
\psi: L^{\text{orb}(\phi)} &\longrightarrow \mathbb{Z}/2 \\
 \psi(\alpha)&=
\begin{cases}
0\qquad \text{for }\alpha \in L_0& \\
1\qquad &\text{for }\alpha \in L_+.
\end{cases}
\end{align*}

\noindent
By definition,
 $\Ker(\psi)=(L^{\text{orb}(\phi)})_0=L_0 \subset L^{\text{orb}(\phi)}$.
So $(L^{\text{orb}(\phi)})_0^\vee=L_0^\vee$
and the discriminant form $(L^{\text{orb}(\phi)})_0^\vee/L^{\text{orb}(\phi)}_0$
brecovers the same picture.
$$
(L^{\text{orb}(\phi)})^{\text{orb}(\phi)}=L.
$$
$$
\begin{matrix}
L
\underbrace{0}_{L^{\text{orb}(\phi)}_0=L_0} & 0 & M\\
0&1/2
\end{matrix}
$$
\begin{definition}
\label{definition-root-system-lattice}
Let $L \subset \mathbb{R}^n$ be an even lattice.
The {\it root system} of $L$ is
$$
\Delta(L)=\{\alpha \in L|(\alpha,\alpha)=2\}.
$$
\end{definition}

\begin{proposition}
\label{proposition-root-systems-lattice-lie-algebras}
The root system of an even lattice is a root systems.
\end{proposition}

\begin{example}
\label{example-e8-root-system}
The root system of $E_8$ (the lattice)
is $E_8$ (the root system).
\end{example}

\noindent
If $\Delta(L_1) \not \simeq \Delta(L_2)$
then $L_1\not\simeq L_2$.

In fact, in $\mathbb{R}^{16}$ there exists 
two even self-dual lattices,
with root systems $E_8 \oplus E_8$ and $D_{16}$.

For rank 24, there exist (coincidentally) 24 even self-dual lattices
called  {\it Neimeier lattices}.
They are constructed as a graph going from one another
by applying the orbifold construction on different homomorphisms $\phi$.
Eventually the graph looks like this:
$$
\xymatrix{
\bullet \ar@{-}[dr]\\
& A_1^{24}\ar@{-}[r]& \Lambda\\
\bullet \ar@{-}[ur]
}
$$
where $\Lambda$ is the {\it Leech lattice}, which has {\it empty} root system,
that is, $\Lambda$ contains $0$, and no vectors of norm $2$,
and 196560 (?) vectors of squared norm 4.

\medskip\noindent
There is something called the Siegel mass formula.
Consider the orthogonal group of a lattice, namely
\begin{align*}
\text{Aut}(L)&=\{g \in \text{GL}_n(\mathbb{R})
|(g \alpha,g \beta)=(\alpha,\beta)\forall \alpha,\beta \in L\text{ and }
g(L) \subset L\}\\
&=\{g \in O_n(\mathbb{R})|g(L) \subset L\},
\end{align*}
which is a finite group.

Then
$$
\sum_{L \in \Gamma_n}\frac{1}{\# \text{Aut}(L)}
=\frac{|B_{n/2}|}{n}
\prod_{1 \leq j \leq  n/2}\frac{|B_{2j}|}{4j}
$$
where $B_k$ is a Bernoulli number.
(See Wikipedia page for Neimeier lattice.)

\bibliography{my}
\bibliographystyle{amsalpha}

\end{document}
